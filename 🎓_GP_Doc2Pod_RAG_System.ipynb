{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5f637298f2c546b6a1dd21837a034101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6022724b999476599b298335232ae97",
              "IPY_MODEL_c934af9f331647a998505362455c5258",
              "IPY_MODEL_fa3be298f2af4270bc623db1284b9ef5"
            ],
            "layout": "IPY_MODEL_135cedf96b694abeb470235f86e490b6"
          }
        },
        "e6022724b999476599b298335232ae97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a270d107d8d5446cb1bad5409686a8a4",
            "placeholder": "​",
            "style": "IPY_MODEL_1e476d2d34a145539022089c35b6b98c",
            "value": "OCR Processing: 100%"
          }
        },
        "c934af9f331647a998505362455c5258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d96c1ede45846369157fb9d787eb434",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a5aefb723d34be6a7644b66439bb04d",
            "value": 52
          }
        },
        "fa3be298f2af4270bc623db1284b9ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e7db62220e245b0b31b3b18801ec451",
            "placeholder": "​",
            "style": "IPY_MODEL_58f10a2b3f5d49a68ef3fe744d58e44a",
            "value": " 52/52 [04:27&lt;00:00,  3.54s/page, Found 2 blocks]"
          }
        },
        "135cedf96b694abeb470235f86e490b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a270d107d8d5446cb1bad5409686a8a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e476d2d34a145539022089c35b6b98c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d96c1ede45846369157fb9d787eb434": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a5aefb723d34be6a7644b66439bb04d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e7db62220e245b0b31b3b18801ec451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58f10a2b3f5d49a68ef3fe744d58e44a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e96aec7d4404ccf88e4853305660278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24aeb80fde0d47f2bf212628986c003a",
              "IPY_MODEL_3aee4aa157544dd9ae031d59358d33f9",
              "IPY_MODEL_397bfd88c19b4c1695ee52f872b82285"
            ],
            "layout": "IPY_MODEL_d07983c0685842149754ac0e19dee79a"
          }
        },
        "24aeb80fde0d47f2bf212628986c003a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b06a40d23a441a4b3af4431830d0d4e",
            "placeholder": "​",
            "style": "IPY_MODEL_fa8c99c554be430081fb61014b9e6397",
            "value": "Download complete: "
          }
        },
        "3aee4aa157544dd9ae031d59358d33f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d84a8c7b73b84bfe9fbc5e22ac5cf660",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3f949dbc1804f31adb96866d9efe71b",
            "value": 0
          }
        },
        "397bfd88c19b4c1695ee52f872b82285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fc176a5e42d46ac92579f38367b811a",
            "placeholder": "​",
            "style": "IPY_MODEL_50f049228a95402ebb552af7bf5a08ad",
            "value": " 0.00/0.00 [00:00&lt;?, ?B/s]"
          }
        },
        "d07983c0685842149754ac0e19dee79a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b06a40d23a441a4b3af4431830d0d4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa8c99c554be430081fb61014b9e6397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d84a8c7b73b84bfe9fbc5e22ac5cf660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e3f949dbc1804f31adb96866d9efe71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fc176a5e42d46ac92579f38367b811a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f049228a95402ebb552af7bf5a08ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82a541e637194841add605fb68f806d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96df8f986fb94aa3b4fca927557bef4f",
              "IPY_MODEL_d5c8118c2fce4e2d8e7000c240634680",
              "IPY_MODEL_3fcdd149afe0442ca1567dfbcc6e1d2e"
            ],
            "layout": "IPY_MODEL_0425d60545c54a63a8a94ce47e82f1bc"
          }
        },
        "96df8f986fb94aa3b4fca927557bef4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c30c38f6417445bbb65892f8cb5dab9b",
            "placeholder": "​",
            "style": "IPY_MODEL_199cfeda6b17440ca7c5bb20f75252d7",
            "value": "Fetching 2 files: 100%"
          }
        },
        "d5c8118c2fce4e2d8e7000c240634680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccd671a41ccf41ccb11990713d0dddb7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37ed7a6ec3064500a516ed55ece600e5",
            "value": 2
          }
        },
        "3fcdd149afe0442ca1567dfbcc6e1d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64de2fd1cf364e8daf1c834ea7038464",
            "placeholder": "​",
            "style": "IPY_MODEL_bee58a943c8746698d6d774cbd1adbd0",
            "value": " 2/2 [00:00&lt;00:00, 115.60it/s]"
          }
        },
        "0425d60545c54a63a8a94ce47e82f1bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c30c38f6417445bbb65892f8cb5dab9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "199cfeda6b17440ca7c5bb20f75252d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccd671a41ccf41ccb11990713d0dddb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37ed7a6ec3064500a516ed55ece600e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64de2fd1cf364e8daf1c834ea7038464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bee58a943c8746698d6d774cbd1adbd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "744f333f39ac4706bbb373c40ca0b154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4be3471a6d2b4f7ab2ddbaa2a11fc83f",
              "IPY_MODEL_ca19229eba914c5089e53fe167a46bfb",
              "IPY_MODEL_8e0cf06771ab48a385c723b2e2a33c9c"
            ],
            "layout": "IPY_MODEL_7db7318e026741d2a1a276dee188eb8d"
          }
        },
        "4be3471a6d2b4f7ab2ddbaa2a11fc83f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94f1b43c035b45e1b10b509195627bde",
            "placeholder": "​",
            "style": "IPY_MODEL_7d3a661a7b794cedbe40cadd79727eb2",
            "value": "Loading weights: 100%"
          }
        },
        "ca19229eba914c5089e53fe167a46bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95e4b70126f144388ff9dfad56b20909",
            "max": 713,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67bf802e46404b0c99c508b2cd4b6176",
            "value": 713
          }
        },
        "8e0cf06771ab48a385c723b2e2a33c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c860b51ae81479784867899e317fd96",
            "placeholder": "​",
            "style": "IPY_MODEL_71ae794d053845689156add111564b68",
            "value": " 713/713 [00:37&lt;00:00, 46.25it/s, Materializing param=model.visual.pos_embed.weight]"
          }
        },
        "7db7318e026741d2a1a276dee188eb8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94f1b43c035b45e1b10b509195627bde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d3a661a7b794cedbe40cadd79727eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95e4b70126f144388ff9dfad56b20909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67bf802e46404b0c99c508b2cd4b6176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c860b51ae81479784867899e317fd96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71ae794d053845689156add111564b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9287d35cde5f41bd8d4fdd9221e82f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53bd0236e74e4ed5b8fe217066862ba6",
              "IPY_MODEL_8b27ad740d8146deb191979bd8f97422",
              "IPY_MODEL_6ea2328e88f24706833259fc7b75b1d2"
            ],
            "layout": "IPY_MODEL_8d657f800bad4bcc997e120689f3fc35"
          }
        },
        "53bd0236e74e4ed5b8fe217066862ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c36c0be09ab941c79ed30a3e8d59e2e4",
            "placeholder": "​",
            "style": "IPY_MODEL_6176399058734064a0f0637c65f720b2",
            "value": "Loading weights: 100%"
          }
        },
        "8b27ad740d8146deb191979bd8f97422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a094891fd86a40f6b87a24279ad55542",
            "max": 391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5629b52fa11940afaeb57b7f635d9905",
            "value": 391
          }
        },
        "6ea2328e88f24706833259fc7b75b1d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_426e584062f24f6aaa36dda30cc2a038",
            "placeholder": "​",
            "style": "IPY_MODEL_f8a35a7e81dc49c78f0bbc5bb3ba3f21",
            "value": " 391/391 [00:00&lt;00:00, 700.63it/s, Materializing param=pooler.dense.weight]"
          }
        },
        "8d657f800bad4bcc997e120689f3fc35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c36c0be09ab941c79ed30a3e8d59e2e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6176399058734064a0f0637c65f720b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a094891fd86a40f6b87a24279ad55542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5629b52fa11940afaeb57b7f635d9905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "426e584062f24f6aaa36dda30cc2a038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8a35a7e81dc49c78f0bbc5bb3ba3f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "977920af30c64cd188395b133902c564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4610273977654a6a9d2ccc739fb0841a",
              "IPY_MODEL_0730cd35e28d48c197ce9ac36293ede6",
              "IPY_MODEL_597e645814044bc3a55a8d0b6c36e217"
            ],
            "layout": "IPY_MODEL_0551b91958464167a40c7eef93a79bcb"
          }
        },
        "4610273977654a6a9d2ccc739fb0841a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9246b773b0da4e6db2e34489533fa46f",
            "placeholder": "​",
            "style": "IPY_MODEL_90f70438b29e40f2974d9f815bf413ea",
            "value": "Embedding: 100%"
          }
        },
        "0730cd35e28d48c197ce9ac36293ede6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6767349e15ec4ddaac2f01b1060dad9a",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea584677ad0040cf8cf9ab646bb08184",
            "value": 28
          }
        },
        "597e645814044bc3a55a8d0b6c36e217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_068ef808c4394d348d1b396e993ebc19",
            "placeholder": "​",
            "style": "IPY_MODEL_ecf105622d5a4debbd651c69e0f9a253",
            "value": " 28/28 [00:01&lt;00:00, 17.86it/s]"
          }
        },
        "0551b91958464167a40c7eef93a79bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9246b773b0da4e6db2e34489533fa46f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90f70438b29e40f2974d9f815bf413ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6767349e15ec4ddaac2f01b1060dad9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea584677ad0040cf8cf9ab646bb08184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "068ef808c4394d348d1b396e993ebc19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecf105622d5a4debbd651c69e0f9a253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca09977144434588a514f9cd98b0315a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bebc006a8c454c0eb84840cca7b77ae1",
              "IPY_MODEL_c83075028304419ebc6547c88a3c7bd6",
              "IPY_MODEL_da41467e96cd45fe8ef84b2a69b6eceb"
            ],
            "layout": "IPY_MODEL_92b23b90269e4f91b32cfe0477dcf6f3"
          }
        },
        "bebc006a8c454c0eb84840cca7b77ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b2eb4c521d44241b3d0fb450840e2f4",
            "placeholder": "​",
            "style": "IPY_MODEL_bb80f27563b042188e445b583547d714",
            "value": "Loading weights: 100%"
          }
        },
        "c83075028304419ebc6547c88a3c7bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1913d73aeb8f4def826f9ac2d1c054fb",
            "max": 391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e753fdc0a4d4fc190228152ee7531ad",
            "value": 391
          }
        },
        "da41467e96cd45fe8ef84b2a69b6eceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf3e8bce6a8345e1af50d24a6abf5574",
            "placeholder": "​",
            "style": "IPY_MODEL_eb53449ddcdc4ecfa3b19b774e697ab7",
            "value": " 391/391 [00:00&lt;00:00, 651.30it/s, Materializing param=pooler.dense.weight]"
          }
        },
        "92b23b90269e4f91b32cfe0477dcf6f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b2eb4c521d44241b3d0fb450840e2f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb80f27563b042188e445b583547d714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1913d73aeb8f4def826f9ac2d1c054fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e753fdc0a4d4fc190228152ee7531ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf3e8bce6a8345e1af50d24a6abf5574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb53449ddcdc4ecfa3b19b774e697ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b1b15b865d64b80a0d1677460334ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cadc9429702403b93b93e3e361c2789",
              "IPY_MODEL_671346f0ae3944cea257c8e1b0cffec8",
              "IPY_MODEL_4e9553c85a3d4b19aee82690a61cf5c5"
            ],
            "layout": "IPY_MODEL_cde9acebc9ef4ad4be26a5b9df2b26d7"
          }
        },
        "9cadc9429702403b93b93e3e361c2789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5e61f5c628348bbb5664c21c89e6e1d",
            "placeholder": "​",
            "style": "IPY_MODEL_a48ecea303db4d73964cfb08b551574e",
            "value": "Loading weights: 100%"
          }
        },
        "671346f0ae3944cea257c8e1b0cffec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1887790148d7439796fd8201eb3c9aa4",
            "max": 398,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7701445692264caf89649c979d9938d1",
            "value": 398
          }
        },
        "4e9553c85a3d4b19aee82690a61cf5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_888f72e1199f4c6aa0666def8579b882",
            "placeholder": "​",
            "style": "IPY_MODEL_55a409c301a141d8bee655fbc05c6c6e",
            "value": " 398/398 [00:33&lt;00:00, 12.10it/s, Materializing param=model.norm.weight]"
          }
        },
        "cde9acebc9ef4ad4be26a5b9df2b26d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5e61f5c628348bbb5664c21c89e6e1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a48ecea303db4d73964cfb08b551574e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1887790148d7439796fd8201eb3c9aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7701445692264caf89649c979d9938d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "888f72e1199f4c6aa0666def8579b882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55a409c301a141d8bee655fbc05c6c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohammed-Atef2004/ASK-project/blob/master/%F0%9F%8E%93_GP_Doc2Pod_RAG_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🚑 Emergency Fix: Force NumPy & Pandas Compatibility\n",
        "# @markdown Run this cell immediately after \"Restart Session\".\n",
        "# @markdown It reinstalls both NumPy and Pandas to ensure they match.\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"🔄 Fixing dependencies... (This takes ~30 seconds)\")\n",
        "\n",
        "# 1. Uninstall existing conflicting versions\n",
        "os.system(\"pip uninstall -y numpy pandas\")\n",
        "\n",
        "# 2. Install compatible versions\n",
        "# We force NumPy < 2.0 and let pip find a Pandas version that matches it.\n",
        "os.system(\"pip install \\\"numpy<2.0\\\" pandas\")\n",
        "\n",
        "# 3. Verify\n",
        "import numpy\n",
        "import pandas\n",
        "print(f\"✅ NumPy Version: {numpy.__version__}\")\n",
        "print(f\"✅ Pandas Version: {pandas.__version__}\")\n",
        "\n",
        "if numpy.__version__.startswith(\"2\"):\n",
        "    print(\"❌ ERROR: NumPy is still 2.x. Please Restart Session and try again.\")\n",
        "else:\n",
        "    print(\"👉 Success! Now run the rest of the notebook.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "7ozknHpLR9pO",
        "outputId": "9b6e71d4-75e8-4bfd-feae-cb54ac3ed660",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Fixing dependencies... (This takes ~30 seconds)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2482844298.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 3. Verify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✅ NumPy Version: {numpy.__version__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✅ Pandas Version: {pandas.__version__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     ) from _err\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m from pandas._config import (\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mget_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mset_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_config/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"set_option\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m ]\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdates\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m from pandas._config.config import (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_stack_level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_typing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m|\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0;34m|\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m     \u001b[0;34m|\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBitGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;34m|\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qtixlkyBZv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7c0e5ba-20fa-4b4e-a57a-bff1e7b532cf",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 121852 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.12_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.12) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.12) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "/usr/bin/pdfinfo\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 GB\u001b[0m \u001b[31m671.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m541.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m655.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m846.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 MB\u001b[0m \u001b[31m871.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.9.0+cu128 requires nvidia-cublas-cu12==12.8.4.1; platform_system == \"Linux\", but you have nvidia-cublas-cu12 12.6.4.1 which is incompatible.\n",
            "torch 2.9.0+cu128 requires nvidia-cuda-cupti-cu12==12.8.90; platform_system == \"Linux\", but you have nvidia-cuda-cupti-cu12 12.6.80 which is incompatible.\n",
            "torch 2.9.0+cu128 requires nvidia-cuda-nvrtc-cu12==12.8.93; platform_system == \"Linux\", but you have nvidia-cuda-nvrtc-cu12 12.6.77 which is incompatible.\n",
            "torch 2.9.0+cu128 requires nvidia-cuda-runtime-cu12==12.8.90; platform_system == \"Linux\", but you have nvidia-cuda-runtime-cu12 12.6.77 which is incompatible.\n",
            "torch 2.9.0+cu128 requires nvidia-cudnn-cu12==9.10.2.21; platform_system == \"Linux\", but you have nvidia-cudnn-cu12 9.5.1.17 which is incompatible.\n",
            "torch 2.9.0+cu128 requires nvidia-cufft-cu12==11.3.3.83; platform_system == \"Linux\", but you have nvidia-cufft-cu12 11.3.0.4 which is incompatible.\n",
            "torch 2.9.0+cu128 requires nvidia-cufile-cu12==1.13.1.3; platform_system == \"Linux\", but you have nvidia-cufile-cu12 1.11.1.6 which is incompatible.\n",
            "torch 2.9.0+cu128 requires nvidia-curand-cu12==10.3.9.90; platform_system == \"Linux\", but you have nvidia-curand-cu12 10.3.7.77 which is incompatible.\n",
            "torch 2.9.0+cu128 requires nvidia-cusolver-cu12==11.7.3.90; platform_system == \"Linux\", but you have nvidia-cusolver-cu12 11.7.1.2 which is incompatible.\n",
            "torch 2.9.0+cu128 requires nvidia-cusparse-cu12==12.5.8.93; platform_system == \"Linux\", but you have nvidia-cusparse-cu12 12.5.4.2 which is incompatible.\n",
            "torch 2.9.0+cu128 requires nvidia-cusparselt-cu12==0.7.1; platform_system == \"Linux\", but you have nvidia-cusparselt-cu12 0.6.3 which is incompatible.\n",
            "torch 2.9.0+cu128 requires nvidia-nccl-cu12==2.27.5; platform_system == \"Linux\", but you have nvidia-nccl-cu12 2.25.1 which is incompatible.\n",
            "torch 2.9.0+cu128 requires nvidia-nvjitlink-cu12==12.8.93; platform_system == \"Linux\", but you have nvidia-nvjitlink-cu12 12.6.85 which is incompatible.\n",
            "torch 2.9.0+cu128 requires nvidia-nvtx-cu12==12.8.90; platform_system == \"Linux\", but you have nvidia-nvtx-cu12 12.6.77 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.2/55.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.2/55.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.9/458.9 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.4/395.4 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.2/978.2 kB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.6/300.6 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.7/385.7 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "langgraph-prebuilt 1.0.7 requires langchain-core>=1.0.0, but you have langchain-core 0.3.83 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.3/803.3 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-openai 0.3.35 requires langchain-core<1.0.0,>=0.3.78, but you have langchain-core 0.1.23 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-cublas-cu12==12.6.4.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-cuda-cupti-cu12==12.6.80; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.8.90 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-cuda-nvrtc-cu12==12.6.77; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.8.93 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-cuda-runtime-cu12==12.6.77; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.8.90 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-cudnn-cu12==9.5.1.17; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.10.2.21 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-cufft-cu12==11.3.0.4; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-cufile-cu12==1.11.1.6; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufile-cu12 1.13.1.3 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-curand-cu12==10.3.7.77; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-cusolver-cu12==11.7.1.2; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-cusparse-cu12==12.5.4.2; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-cusparselt-cu12==0.6.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparselt-cu12 0.7.1 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-nccl-cu12==2.25.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.27.5 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-nvjitlink-cu12==12.6.85; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-nvtx-cu12==12.6.77; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvtx-cu12 12.8.90 which is incompatible.\n",
            "langchain-text-splitters 0.3.11 requires langchain-core<2.0.0,>=0.3.75, but you have langchain-core 0.1.23 which is incompatible.\n",
            "xarray 2025.12.0 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "google-adk 1.24.0 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "langgraph-checkpoint 4.0.0 requires langchain-core>=0.2.38, but you have langchain-core 0.1.23 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "wheel 0.46.3 requires packaging>=24.0, but you have packaging 23.2 which is incompatible.\n",
            "google-cloud-bigquery 3.40.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "langgraph-prebuilt 1.0.7 requires langchain-core>=1.0.0, but you have langchain-core 0.1.23 which is incompatible.\n",
            "opencv-python-headless 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "db-dtypes 1.5.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m200.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m233.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m159.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m139.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.8/296.8 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 MB\u001b[0m \u001b[31m145.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m230.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m251.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.0/824.0 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-cudnn-cu12==9.5.1.17; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.10.2.21 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-cusparselt-cu12==0.6.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparselt-cu12 0.7.1 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-nccl-cu12==2.25.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.28.9 which is incompatible.\n",
            "fastai 2.8.6 requires torch<2.10,>=1.10, but you have torch 2.11.0.dev20260107+cu126 which is incompatible.\n",
            "cuda-python 12.9.5 requires cuda-bindings~=12.9.5, but you have cuda-bindings 12.9.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m126.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-core 0.1.23 requires packaging<24.0,>=23.2, but you have packaging 26.0 which is incompatible.\n",
            "langchain-text-splitters 0.3.11 requires langchain-core<2.0.0,>=0.3.75, but you have langchain-core 0.1.23 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "google-adk 1.24.0 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "fastai 2.8.6 requires torch<2.10,>=1.10, but you have torch 2.11.0.dev20260107+cu126 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "langgraph-checkpoint 4.0.0 requires langchain-core>=0.2.38, but you have langchain-core 0.1.23 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.38.0 requires opentelemetry-exporter-otlp-proto-common==1.38.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.38.0 requires opentelemetry-proto==1.38.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.38.0 requires opentelemetry-sdk~=1.38.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "langgraph-prebuilt 1.0.7 requires langchain-core>=1.0.0, but you have langchain-core 0.1.23 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-cudnn-cu12==9.5.1.17; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.10.2.21 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-cusparselt-cu12==0.6.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparselt-cu12 0.7.1 which is incompatible.\n",
            "paddlepaddle-gpu 3.2.1 requires nvidia-nccl-cu12==2.25.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.28.9 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "fastai 2.8.6 requires torch<2.10,>=1.10, but you have torch 2.11.0.dev20260107+cu126 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m✅ Step 1 Complete: All dependencies installed.\n"
          ]
        }
      ],
      "source": [
        "# @title 🛠️ Step 1: Install Dependencies & System Tools\n",
        "# @markdown This installs OCR tools (PaddlePaddle), Vector Database (Chroma), and AI models.\n",
        "# @markdown **Note:** This installs specific nightly builds of PyTorch. It may take 3-5 minutes.\n",
        "\n",
        "# System Tools (Required for PDF conversion)\n",
        "!apt-get update -qq\n",
        "!apt-get install -y poppler-utils -qq\n",
        "!which pdfinfo  # Verify installation\n",
        "\n",
        "# PaddleOCR (for extracting text/tables)\n",
        "!pip install paddlepaddle-gpu==3.2.1 -i https://www.paddlepaddle.org.cn/packages/stable/cu126/ -q\n",
        "!pip install paddlex==3.3.12 \"paddleocr[all]\" -q\n",
        "\n",
        "# Utils (PDF handling, Regex, etc.)\n",
        "!pip install langchain==0.0.354 pdf2image sentence-transformers regex uuid beautifulsoup4 pylatexenc -q\n",
        "\n",
        "# PyTorch (Nightly Build )\n",
        "!pip install torch==2.11.0.dev20260107+cu126 torchvision==0.25.0.dev20260107+cu126 torchaudio==2.11.0.dev20260107+cu126 --index-url https://download.pytorch.org/whl/nightly/cu126 -q\n",
        "!pip install transformers accelerate --upgrade -q\n",
        "\n",
        "# Vision Language Model Utils\n",
        "!pip install qwen-vl-utils -q\n",
        "\n",
        "# Vector Database & Data Handling\n",
        "!pip install chromadb pandas -q\n",
        "\n",
        "# Numpy Fix (Uninstall/Reinstall to prevent version conflicts)\n",
        "!pip uninstall -y numpy -q\n",
        "!pip install numpy==1.26.4 -q\n",
        "\n",
        "print(\"✅ Step 1 Complete: All dependencies installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 📚 Step 2: Import Libraries\n",
        "# @markdown We import standard tools, OCR engines, and AI models here.\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import uuid\n",
        "import html\n",
        "import json\n",
        "import glob\n",
        "import time\n",
        "import torch\n",
        "import paddle\n",
        "import tempfile\n",
        "import pandas as pd\n",
        "import chromadb\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Any, List, Dict\n",
        "from io import StringIO\n",
        "from pathlib import Path\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# AI & Vision Import\n",
        "from qwen_vl_utils import process_vision_info\n",
        "from paddleocr import PPStructureV3, PaddleOCRVL\n",
        "from pylatexenc.latex2text import LatexNodes2Text\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pdf2image import convert_from_path, pdfinfo_from_path\n",
        "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor, AutoModelForCausalLM, AutoTokenizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "print(\"✅ Step 2 Complete: Libraries loaded successfully.\")"
      ],
      "metadata": {
        "id": "q1khJelSD7ux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1df518-dd3f-48e1-c514-d9b259c0ef81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/paddle/utils/cpp_extension/extension_utils.py:718: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
            "  warnings.warn(warning_message)\n",
            "\u001b[33mChecking connectivity to the model hosters, this may take a while. To bypass this check, set `DISABLE_MODEL_SOURCE_CHECK` to `True`.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Step 2 Complete: Libraries loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 📂 Step 3: Mount Drive & Configure Unified Workspace\n",
        "# @markdown We set up a comprehensive directory structure to handle the full pipeline:\n",
        "# @markdown PDF -> Images -> OCR JSON -> Embeddings -> ChromaDB -> Podcast Audio.\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define Root Path\n",
        "BASE_DIR = Path(\"/content/drive/MyDrive/Doc2Pod_System\")\n",
        "\n",
        "# Define Sub-Directories\n",
        "DATA_DIR = BASE_DIR / \"Data\"\n",
        "PDF_DIR = DATA_DIR / \"pdfs\"                    # Raw PDFs go here\n",
        "IMAGE_DIR = DATA_DIR / \"images\"                # Extracted images from slides\n",
        "JSON_DIR = DATA_DIR / \"json\"                   # Raw OCR output (per page)\n",
        "UNIFIED_DIR = DATA_DIR / \"unified_json\"        # Cleaned/Merged text chunks\n",
        "EMBEDDING_DIR = DATA_DIR / \"embedding_inputs\"  # Pre-processed data for Vector DB\n",
        "DB_DIR = DATA_DIR / \"chroma_db\"                # The Vector Database (Chroma)\n",
        "OUTPUT_DIR = BASE_DIR / \"episodes\"             # Final Scripts & Audio files\n",
        "\n",
        "# 4. Create All Directories\n",
        "folders_to_create = [\n",
        "    BASE_DIR, DATA_DIR, PDF_DIR, IMAGE_DIR, JSON_DIR,\n",
        "    UNIFIED_DIR, EMBEDDING_DIR, DB_DIR, OUTPUT_DIR\n",
        "]\n",
        "\n",
        "for d in folders_to_create:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"✅ Workspace Ready at: {BASE_DIR}\")\n",
        "print(f\"   📂 Data Folder:     {DATA_DIR}\")\n",
        "print(f\"       ├── Input PDFs: {PDF_DIR.name}\")\n",
        "print(f\"       ├── Vector DB:  {DB_DIR.name}\")\n",
        "print(f\"       └── Images:     {IMAGE_DIR.name}\")\n",
        "print(f\"   🎙️ Final Output:    {OUTPUT_DIR}\")\n",
        "\n",
        "print(\"✅ Step 3 Complete: Drive mounted successfully\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "W6Qa2wXaEOHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd53c286-dd3f-4c50-ed82-eae6f5e40d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Workspace Ready at: /content/drive/MyDrive/Doc2Pod_System\n",
            "   📂 Data Folder:     /content/drive/MyDrive/Doc2Pod_System/Data\n",
            "       ├── Input PDFs: pdfs\n",
            "       ├── Vector DB:  chroma_db\n",
            "       └── Images:     images\n",
            "   🎙️ Final Output:    /content/drive/MyDrive/Doc2Pod_System/episodes\n",
            "✅ Step 3 Complete: Drive mounted successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🧠 Step 4: Model Managers (Lazy Loading)\n",
        "# @markdown Defines functions to load PaddleOCR and Qwen-VL only when needed to save GPU memory.\n",
        "\n",
        "def load_PaddleOCRVL():\n",
        "    \"\"\"Initializes the PaddleOCR pipeline for text & layout detection.\"\"\"\n",
        "\n",
        "    device = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"[*] Loading PaddleOCR on {device}...\")\n",
        "\n",
        "    pipeline = PaddleOCRVL(\n",
        "        device=device,\n",
        "        use_layout_detection=True,\n",
        "        format_block_content=True,\n",
        "        use_chart_recognition=True\n",
        "    )\n",
        "    return pipeline\n",
        "\n",
        "\n",
        "def load_qwen3_vl_model():\n",
        "    \"\"\"Loads Qwen3-VL (4B) for describing images and charts.\"\"\"\n",
        "\n",
        "    print(\"[*] Loading Qwen3-VL (Vision Model)...\")\n",
        "    model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
        "        \"Qwen/Qwen3-VL-4B-Instruct\",\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    processor = AutoProcessor.from_pretrained(\n",
        "        \"Qwen/Qwen3-VL-4B-Instruct\",\n",
        "        min_pixels=256*28*28,\n",
        "        max_pixels=768*28*28,\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    model.eval()\n",
        "    return model, processor\n",
        "\n",
        "\n",
        "def load_qwen3_thinking_model():\n",
        "    \"\"\"Loads Qwen3-4B-Thinking for script generation.\"\"\"\n",
        "    print(\"[*] Loading Qwen3-4B-Thinking...\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        \"Qwen/Qwen3-4B-Thinking-2507\",\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        \"Qwen/Qwen3-4B-Thinking-2507\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    return model, tokenizer\n",
        "\n",
        "class LazyPipelineManager:\n",
        "    \"\"\"Manages models so they aren't loaded until the exact moment they are needed.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self._vl_pipeline = None\n",
        "        self._vl_loaded = False\n",
        "        self._qwen3_vl = None\n",
        "        self._processor = None\n",
        "        self._qwen3_vl_loaded = False\n",
        "        self._qwen3_thinking = None\n",
        "        self._thinking_tokenizer = None\n",
        "        self._thinking_loaded = False\n",
        "\n",
        "    def get_vl_pipeline(self):\n",
        "        if not self._vl_loaded:\n",
        "            self._vl_pipeline = load_PaddleOCRVL()\n",
        "            self._vl_loaded = True\n",
        "        return self._vl_pipeline\n",
        "\n",
        "    def get_qwen3_vl_model(self):\n",
        "        if not self._qwen3_vl_loaded:\n",
        "            self._qwen3_vl, self._processor = load_qwen3_vl_model()\n",
        "            self._qwen3_vl_loaded = True\n",
        "        return self._qwen3_vl, self._processor\n",
        "\n",
        "    def get_qwen3_thinking_model(self):\n",
        "        if not self._thinking_loaded:\n",
        "            self._qwen3_thinking, self._thinking_tokenizer = load_qwen3_thinking_model()\n",
        "            self._thinking_loaded = True\n",
        "        return self._qwen3_thinking, self._thinking_tokenizer\n",
        "\n",
        "    def unload_all(self):\n",
        "        \"\"\"Explicitly unloads all currently loaded models and clears GPU cache.\"\"\"\n",
        "        print(\"[*] Unloading all models from GPU...\")\n",
        "        if self._vl_pipeline:\n",
        "            del self._vl_pipeline\n",
        "            self._vl_pipeline = None\n",
        "            self._vl_loaded = False\n",
        "\n",
        "        if self._qwen3_vl:\n",
        "            del self._qwen3_vl\n",
        "            self._qwen3_vl = None\n",
        "            del self._processor\n",
        "            self._processor = None\n",
        "            self._qwen3_vl_loaded = False\n",
        "\n",
        "        if self._qwen3_thinking:\n",
        "            del self._qwen3_thinking\n",
        "            self._qwen3_thinking = None\n",
        "            del self._thinking_tokenizer\n",
        "            self._thinking_tokenizer = None\n",
        "            self._thinking_loaded = False\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        print(\"[*] GPU memory cleared.\")\n",
        "\n",
        "print(\"✅ Step 4 Complete: Model Managers defined.\")\n"
      ],
      "metadata": {
        "id": "6PcbFSOHHVZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eefc899d-00c3-465e-8aac-032aa17be3b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Step 4 Complete: Model Managers defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🧹 Step 5: Text Cleaning & Normalization Utils\n",
        "# @markdown Helper functions to clean code snippets, convert HTML tables to text, and fix LaTeX formatting.\n",
        "\n",
        "# Constants for LaTeX normalization\n",
        "SUPERSCRIPTS = {\"0\": \"⁰\", \"1\": \"¹\", \"2\": \"²\", \"3\": \"³\", \"4\": \"⁴\", \"5\": \"⁵\", \"6\": \"⁶\", \"7\": \"⁷\", \"8\": \"⁸\", \"9\": \"⁹\", \"+\": \"⁺\", \"-\": \"⁻\", \"=\": \"⁼\", \"T\": \"ᵀ\", \"n\": \"ⁿ\", \"i\": \"ⁱ\"}\n",
        "SUBSCRIPTS = {\"0\": \"₀\", \"1\": \"₁\", \"2\": \"₂\", \"3\": \"₃\", \"4\": \"₄\", \"5\": \"₅\", \"6\": \"₆\", \"7\": \"₇\", \"8\": \"₈\", \"9\": \"₉\", \"i\": \"ᵢ\", \"j\": \"ⱼ\", \"k\": \"ₖ\", \"n\": \"ₙ\"}\n",
        "\n",
        "def normalize_code(raw_code):\n",
        "    \"\"\"Cleans up OCR errors common in code blocks (e.g. '0' vs 'O').\"\"\"\n",
        "\n",
        "    if not raw_code.strip():\n",
        "       return \"Code snippet: [empty]\"\n",
        "\n",
        "    lines = raw_code.split('\\n')\n",
        "    cleaned_lines = []\n",
        "\n",
        "    for line in lines:\n",
        "        stripped = line.rstrip()\n",
        "        stripped = re.sub(r'\\bO\\b', '0', stripped)\n",
        "        stripped = re.sub(r'\\b[lI]\\b', '1', stripped)\n",
        "        stripped = re.sub(r'\\bS\\b(?=\\d)', '5', stripped)\n",
        "        stripped = re.sub(r'! =', '!=', stripped)\n",
        "        stripped = re.sub(r'< =', '<=', stripped)\n",
        "        stripped = re.sub(r'> =', '>=', stripped)\n",
        "        cleaned_lines.append(stripped)\n",
        "\n",
        "    normalized = '\\n'.join(cleaned_lines).strip()\n",
        "\n",
        "    if not normalized:\n",
        "       return \"Code snippet: [unrecognized content]\"\n",
        "\n",
        "    return f\"Code snippet:\\n{normalized}\"\n",
        "\n",
        "\n",
        "def html_table_to_text(html_table):\n",
        "    \"\"\"Parses HTML tables returned by PaddleOCR into pipe-separated text.\"\"\"\n",
        "\n",
        "    soup = BeautifulSoup(html_table, \"html.parser\")\n",
        "    table = soup.find(\"table\")\n",
        "\n",
        "    if not table:\n",
        "       return \"Table\"\n",
        "\n",
        "    grid, rowspan_map = [], {}\n",
        "    for tr in table.find_all(\"tr\"):\n",
        "        row, col_idx = [], 0\n",
        "        while col_idx in rowspan_map:\n",
        "            row.append(rowspan_map[col_idx][\"text\"])\n",
        "            rowspan_map[col_idx][\"rows\"] -= 1\n",
        "            if rowspan_map[col_idx][\"rows\"] == 0:\n",
        "               del rowspan_map[col_idx]\n",
        "            col_idx += 1\n",
        "        for cell in tr.find_all([\"td\", \"th\"], recursive=False):\n",
        "            text = cell.get_text(\" \", strip=True) or \"—\"\n",
        "            text = latex_to_unicode(text)\n",
        "            colspan = int(cell.get(\"colspan\", 1))\n",
        "            rowspan = int(cell.get(\"rowspan\", 1))\n",
        "            for _ in range(colspan):\n",
        "                row.append(text)\n",
        "                if rowspan > 1:\n",
        "                   rowspan_map[col_idx] = {\"text\": text, \"rows\": rowspan - 1}\n",
        "                col_idx += 1\n",
        "        grid.append(row)\n",
        "    max_cols = max(len(r) for r in grid)\n",
        "    for r in grid: r.extend([\"\"] * (max_cols - len(r)))\n",
        "    lines = []\n",
        "    for row in grid:\n",
        "        if any(cell.strip() for cell in row):\n",
        "           lines.append(\" | \".join(row))\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def normalize_latex(text):\n",
        "    \"\"\"Basic cleanup for LaTeX strings.\"\"\"\n",
        "\n",
        "    text = re.sub(r\"\\${1,2}\", \"\", text)\n",
        "    text = text.replace(\"\\\\\\\\\", \"\\\\\")\n",
        "    text = re.sub(r\"\\\\quad|\\\\qquad|\\\\,\", \" \", text)\n",
        "    text = re.sub(r\"\\\\begin\\{.*?\\}|\\\\end\\{.*?\\}\", \"\", text)\n",
        "    text = re.sub(r\"\\b[clr]{1,3}\\b\", \"\", text)\n",
        "    return text\n",
        "\n",
        "def latex_to_unicode(text):\n",
        "    \"\"\"Converts LaTeX math symbols to their Unicode equivalents for better readability.\"\"\"\n",
        "    if not text:\n",
        "      return text\n",
        "    text = normalize_latex(text)\n",
        "    try:\n",
        "       text = LatexNodes2Text().latex_to_text(text)\n",
        "    except Exception:\n",
        "       pass\n",
        "\n",
        "    replacements = {\n",
        "        r\"\\\\theta\": \"θ\", r\"\\\\alpha\": \"α\", r\"\\\\beta\": \"β\", r\"\\\\gamma\": \"γ\",\n",
        "        r\"\\\\lambda\": \"λ\", r\"\\\\mu\": \"μ\", r\"\\\\sigma\": \"σ\", r\"\\\\pi\": \"π\",\n",
        "        r\"\\\\geq\": \"≥\", r\"\\\\leq\": \"≤\", r\"\\\\neq\": \"≠\", r\"\\\\approx\": \"≈\",\n",
        "        r\"\\\\pm\": \"±\", r\"\\\\cdot\": \"·\", r\"\\\\times\": \"×\", r\"\\\\rightarrow\": \"→\", r\"\\\\infty\": \"∞\"\n",
        "    }\n",
        "    for k, v in replacements.items():\n",
        "        text = re.sub(k, v, text)\n",
        "\n",
        "    # Handle superscripts/subscripts\n",
        "    text = re.sub(r\"\\^\\{([^}]+)\\}\",lambda m: \"\".join(SUPERSCRIPTS.get(c, c) for c in m.group(1)),text)\n",
        "    text = re.sub(r\"\\^\\(([^)]+)\\)\",lambda m: \"\".join(SUPERSCRIPTS.get(c, c) for c in m.group(1)),text)\n",
        "    text = re.sub(r\"_\\{([^}]+)\\}\",lambda m: \"\".join(SUBSCRIPTS.get(c, c) for c in m.group(1)),text)\n",
        "    text = re.sub(r\"\\^([0-9Tni+\\-=])\",lambda m: SUPERSCRIPTS.get(m.group(1), m.group(1)),text)\n",
        "    text = re.sub(r\"_([0-9ijkn])\",lambda m: SUBSCRIPTS.get(m.group(1), m.group(1)),text)\n",
        "    text = re.sub(r\"\\\\[a-zA-Z]+\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "def is_personal_info(text):\n",
        "    \"\"\"Detect admin/link-only content to exclude from chunks.\"\"\"\n",
        "    if not text.strip():\n",
        "        return False\n",
        "\n",
        "    lower_text = text.lower()\n",
        "\n",
        "    # ❌ Admin content\n",
        "    admin_keywords = [\n",
        "        \"email\", \"@\", \"office hours\", \"grading\", \"resources\", \"credit\",\n",
        "        \"references\", \"contact\", \"phone\", \"exam\", \"midterm\", \"quiz\",\n",
        "        \"practical\", \"hands-on\",\"proposed course outline\", \"helpful resources\", \"grading scheme\",\"resources\"\n",
        "    ]\n",
        "    if any(kw in lower_text for kw in admin_keywords):\n",
        "        return True\n",
        "\n",
        "    # ❌ Link-only content (e.g., YouTube links)\n",
        "    url_patterns = [r'https?://', r'www\\.', r'\\.com', r'\\.eg']\n",
        "    if any(re.search(pattern, text) for pattern in url_patterns):\n",
        "        # If the text is mostly a URL (short + contains link)\n",
        "        words = text.split()\n",
        "        if len(words) <= 3 and any(re.search(p, text) for p in url_patterns):\n",
        "            return True\n",
        "\n",
        "    # ❌ Email/phone patterns\n",
        "    email_pattern = r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\"\n",
        "    phone_pattern = r\"\\+?\\d[\\d\\s-]{5,}\\d\"\n",
        "    office_pattern = r\"\\b(Room|Building|Office)\\b\"\n",
        "    if (re.search(email_pattern, text) or\n",
        "        re.search(phone_pattern, text) or\n",
        "        re.search(office_pattern, text)):\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "print(\"✅ Step 5 Complete: Text utilities loaded.\")"
      ],
      "metadata": {
        "id": "Drwl8pJfHlmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac08cee-eafa-4774-85c7-81ab9714ee80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Step 5 Complete: Text utilities loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 👁️ Step 6: Visual Understanding (Qwen-VL)\n",
        "# @markdown Logic to recover text from charts and diagrams using the Vision Language Model.\n",
        "\n",
        "def recover_image_block_qwen(bbox, page_img, pipeline_manager, max_res=800):\n",
        "    \"\"\"\n",
        "    Crops an image region and sends it to Qwen-VL for description.\n",
        "    \"\"\"\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    crop_w, crop_h = x2-x1, y2-y1\n",
        "\n",
        "    # Skip tiny noise artifacts\n",
        "    if crop_w < 50 or crop_h < 50:\n",
        "        return {\"type\": \"image\", \"text\": \"[Tiny image skipped]\", \"recovered\": False}\n",
        "\n",
        "    # Resize if too large to save token cost/time\n",
        "    cropped = page_img.crop((x1, y1, x2, y2))\n",
        "    scale = min(max_res / crop_w, max_res / crop_h, 1.0)\n",
        "    if scale < 1.0:\n",
        "        cropped = cropped.resize((int(crop_w*scale), int(crop_h*scale)), Image.Resampling.LANCZOS)\n",
        "\n",
        "    if pipeline_manager:\n",
        "        model, processor = pipeline_manager.get_qwen3_vl_model()\n",
        "        try:\n",
        "            # Re-crop from original for maximum quality\n",
        "            cropped = page_img.crop((x1, y1, x2, y2))\n",
        "\n",
        "            messages = [{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"image\", \"image\": cropped},\n",
        "                    {\"type\": \"text\", \"text\": (\n",
        "                        \"Extract and explain all readable textual and semantic information from this image. \"\n",
        "                        \"If it is a chart, diagram, table, or equation, describe it clearly in technical English.\"\n",
        "                        \"- If absolutely nothing is readable, output exactly: [NO READABLE CONTENT]\"\n",
        "                    )}\n",
        "                ]\n",
        "            }]\n",
        "\n",
        "            text_prompt = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "            image_inputs, _ = process_vision_info(messages)\n",
        "\n",
        "            inputs = processor(\n",
        "                text=[text_prompt],\n",
        "                images=image_inputs,\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(model.device)\n",
        "\n",
        "            # Generate description\n",
        "            with torch.inference_mode():\n",
        "                generated_ids = model.generate(**inputs, max_new_tokens=512)\n",
        "\n",
        "            output_text = processor.batch_decode(\n",
        "                generated_ids[:, inputs.input_ids.shape[1]:],\n",
        "                skip_special_tokens=True\n",
        "            )[0].strip()\n",
        "\n",
        "            # Cleanup\n",
        "            del inputs, generated_ids, image_inputs, text_prompt, messages\n",
        "            cropped.close()\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "            if \"NO READABLE CONTENT\" in output_text.upper():\n",
        "              return {\"text\": \"[No content extracted]\", \"type\": \"image\", \"recovered\": False}\n",
        "\n",
        "            return {\n",
        "                \"text\": output_text if output_text else \"[No content extracted]\",\n",
        "                \"type\": \"image\",\n",
        "                \"recovered\": bool(output_text)\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            try:\n",
        "                cropped.close()\n",
        "                del cropped\n",
        "                torch.cuda.empty_cache()\n",
        "            except: pass\n",
        "            print(f\"❌ Qwen-VL image recovery failed: {e}\")\n",
        "            return {\"text\": f\"[Image recovery failed: {str(e)}]\", \"type\": \"image\", \"recovered\": False}\n",
        "\n",
        "print(\"✅ Step 6 Complete: Vision Logic loaded.\")"
      ],
      "metadata": {
        "id": "Sex4Z6guInA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa0531a-8f24-4b26-c15f-8a3d1fee7166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Step 6 Complete: Vision Logic loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 📄 Step 7: Layout Analysis Helper\n",
        "# @markdown Helper function to determine if two text blocks should be merged based on distance and alignment.\n",
        "\n",
        "def can_merge(prev_unit, blk, page_no, y_ratio=0.1, indent_ratio=0.05):\n",
        "    \"\"\"\n",
        "    Checks if 'blk' is visually close enough to 'prev_unit' to be considered the same paragraph.\n",
        "    \"\"\"\n",
        "    if prev_unit is None:\n",
        "       return False\n",
        "    if prev_unit[\"page\"] != page_no:\n",
        "       return False\n",
        "\n",
        "    curr_type = blk.get(\"label\", \"text\")\n",
        "    prev_type = prev_unit[\"type\"]\n",
        "\n",
        "    # Only merge same-type blocks (text with text)\n",
        "    if curr_type != prev_type:\n",
        "      return False\n",
        "    if curr_type not in {\"text\", \"paragraph\"}:\n",
        "      return False\n",
        "\n",
        "    # Check geometric proximity\n",
        "    prev_x1, prev_y1, prev_x2, prev_y2 = prev_unit[\"bbox\"]\n",
        "    curr_x1, curr_y1, curr_x2, curr_y2 = blk[\"bbox\"]\n",
        "\n",
        "    prev_height = prev_y2 - prev_y1\n",
        "    page_width = max(prev_x2, curr_x2)\n",
        "\n",
        "    # Check Vertical Gap\n",
        "    max_gap = max(prev_height * y_ratio, 10)\n",
        "    if abs(curr_y1 - prev_y2) > max_gap:\n",
        "      return False\n",
        "\n",
        "    # Check Indentation difference\n",
        "    max_indent_diff = max(page_width * indent_ratio, 10)\n",
        "    if abs(curr_x1 - prev_x1) > max_indent_diff:\n",
        "       return False\n",
        "\n",
        "    # Heuristic: Don't merge if previous line ends with sentence terminator\n",
        "    prev_text = prev_unit[\"text\"].strip()\n",
        "    if prev_text.endswith((\".\", \":\", \"؟\", \"!\", \";\")):\n",
        "       return False\n",
        "\n",
        "    # Heuristic: Don't merge bullets\n",
        "    bullet_pattern = r\"^(\\-|\\*|\\u2022|\\d+\\.)\\s+\"\n",
        "    if re.match(bullet_pattern, blk.get(\"content\", \"\").strip()):\n",
        "       return False\n",
        "\n",
        "    # Heuristic: Don't merge headers\n",
        "    if prev_text.isupper() and len(prev_text.split()) < 6:\n",
        "       return False\n",
        "\n",
        "    return True\n",
        "\n",
        "print(\"✅ Step 7 Complete: Layout helper loaded.\")"
      ],
      "metadata": {
        "id": "5DWcJdMIIo4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec9d009-5756-4be4-87c7-735609eea516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Step 7 Complete: Layout helper loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🧱 Step 8: Raw Block Processing Logic\n",
        "# @markdown Functions to convert raw OCR blocks into logical units (Paragraphs, Tables, Image Descriptions).\n",
        "\n",
        "def to_dict(obj: Any) -> Any:\n",
        "    \"\"\"Helper to make custom objects JSON serializable.\"\"\"\n",
        "    if obj is None: return None\n",
        "    if hasattr(obj, 'numpy') and callable(obj.numpy):\n",
        "        try: return obj.numpy().tolist()\n",
        "        except: return str(obj)\n",
        "    elif isinstance(obj, np.ndarray): return obj.tolist()\n",
        "    elif isinstance(obj, Path): return str(obj)\n",
        "    elif isinstance(obj, (bytes, bytearray)): return obj.decode('utf-8', errors='replace')\n",
        "    elif isinstance(obj, (tuple, set)): return [to_dict(item) for item in obj]\n",
        "    elif hasattr(obj, '__dict__') and not isinstance(obj, type): return to_dict(obj.__dict__)\n",
        "    elif isinstance(obj, dict): return {k: to_dict(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, list): return [to_dict(item) for item in obj]\n",
        "    try:\n",
        "        json.dumps(obj)\n",
        "        return obj\n",
        "    except: return str(obj)\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def is_valid_title(text):\n",
        "    \"\"\"Heuristic to check if a text block looks like a Section Header.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return False\n",
        "    text = text.strip()\n",
        "    if len(text) < 5 or len(text) > 100:  # ← Increased min length\n",
        "        return False\n",
        "\n",
        "    # ❌ Reject LaTeX/math\n",
        "    latex_patterns = [r'\\$.*?\\$', r'\\\\[a-zA-Z]+', r'\\{.*?\\}']\n",
        "    if any(re.search(p, text) for p in latex_patterns):\n",
        "        return False\n",
        "\n",
        "    # ❌ Reject bullets/lists\n",
        "    if text.startswith(('•', '-', '—', '*', '●', '·', '→')):\n",
        "        return False\n",
        "\n",
        "    # ❌ Reject admin content\n",
        "    admin_keywords = [\"email\", \"@\", \"office hours\", \"grading\", \"resources\", \"credit\", \"references\"]\n",
        "    if any(kw in text.lower() for kw in admin_keywords):\n",
        "        return False\n",
        "\n",
        "    # ✅ Accept titles with:\n",
        "    # - Multiple words (≥2)\n",
        "    # - No trailing punctuation\n",
        "    # - Not sentence-like\n",
        "    words = text.split()\n",
        "    if len(words) < 2:\n",
        "        return False\n",
        "    if text.endswith(('.', '!', ';')) and not text.endswith('...'):\n",
        "        return False\n",
        "    structural_keywords = [\"comparison\", \"levels\", \"deployment\", \"challenges\", \"protocols\", \"domains\"]\n",
        "    if any(kw in text.lower() for kw in structural_keywords):\n",
        "        return True\n",
        "\n",
        "    return True\n",
        "\n",
        "def blocks_to_units(pdf_data, pipeline_manager):\n",
        "    \"\"\"\n",
        "    Iterates through OCR blocks, merges neighbors, parses tables, and recovers images using Qwen-VL.\n",
        "    \"\"\"\n",
        "    units = []\n",
        "    unit_idx = 0\n",
        "\n",
        "    for page in pdf_data[\"pages\"]:\n",
        "        page_no = page[\"page_number\"]\n",
        "        page_img = Image.open(page[\"image_path\"])\n",
        "        blocks = page.get(\"parsing_res_list\", [])\n",
        "\n",
        "        # Filter and Sort Blocks\n",
        "        valid_blocks = [b for b in blocks if b.get(\"bbox\") and len(b.get(\"bbox\", [])) == 4]\n",
        "        blocks = sorted(valid_blocks, key=lambda b: (b.get(\"bbox\")[1], b.get(\"bbox\")[0]))\n",
        "\n",
        "        prev_unit = None\n",
        "        for blk in blocks:\n",
        "            text = blk.get(\"content\", \"\").strip()\n",
        "            if is_personal_info(text): continue\n",
        "\n",
        "            t = blk.get(\"label\", \"text\")\n",
        "            # Skip noise\n",
        "            if t == \"number\" or (t == \"text\" and len(text) <= 2): continue\n",
        "\n",
        "            # Handle Tables\n",
        "            if t in (\"table\", \"chart\"):\n",
        "                text = html_table_to_text(text)\n",
        "                text = html.unescape(text)\n",
        "\n",
        "            # Handle Images (The Vision Part)\n",
        "            if t in (\"table\",\"image\", \"chart\") and ((not text) or len(text) <= 2 or (text==\"Table\")):\n",
        "                bbox = blk.get(\"bbox\", [0,0,0,0])\n",
        "                recovered = recover_image_block_qwen(bbox, page_img, pipeline_manager)\n",
        "\n",
        "                if recovered.get(\"recovered\"):\n",
        "                    units.append({\n",
        "                        \"text\": recovered[\"text\"],\n",
        "                        \"type\": \"image\",\n",
        "                        \"page\": page_no,\n",
        "                        \"unit_id\": f\"u{unit_idx:06d}\",\n",
        "                        \"bbox\": bbox\n",
        "                    })\n",
        "                    unit_idx += 1\n",
        "                    continue\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "            if not text: continue\n",
        "\n",
        "            # Attempt to Merge with previous block (for broken paragraphs)\n",
        "            if prev_unit and can_merge(prev_unit, blk, page_no):\n",
        "                prev_unit[\"text\"] += \" \" + text\n",
        "                prev_unit[\"bbox\"][2] = max(prev_unit[\"bbox\"][2], blk[\"bbox\"][2])\n",
        "                prev_unit[\"bbox\"][3] = max(prev_unit[\"bbox\"][3], blk[\"bbox\"][3])\n",
        "                continue\n",
        "\n",
        "            # New Unit\n",
        "            units.append({\n",
        "                \"text\": text,\n",
        "                \"type\": t,\n",
        "                \"page\": page_no,\n",
        "                \"unit_id\": f\"u{unit_idx:06d}\",\n",
        "                \"bbox\": blk.get(\"bbox\", [0,0,0,0])\n",
        "            })\n",
        "            prev_unit = units[-1]\n",
        "            unit_idx += 1\n",
        "    return units\n",
        "\n",
        "print(\"✅ Step 8 Complete: Block processors defined.\")"
      ],
      "metadata": {
        "id": "8fa-mSZ_J1iR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c547936-5da7-4292-ceb9-2db03a76dd8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Step 8 Complete: Block processors defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🍕 Step 9: Semantic Chunking & Embedding Prep (Admin-Safe + Structural Keywords)\n",
        "# @markdown\n",
        "# - Groups text by headers\n",
        "# - Excludes ENTIRE admin pages (e.g., \"Helpful Resources\", YouTube links)\n",
        "# - Promotes structural keywords (\"levels\", \"comparison\") to top-level sections\n",
        "# - Enforces page-aligned subchunking for podcast coherence\n",
        "\n",
        "\n",
        "# Helper: Detect Level boundaries in text (Level-2, Level-3, etc.) – GENERAL PURPOSE\n",
        "def detect_level_boundaries(text, units):\n",
        "        \"\"\"Returns list of (start_idx, level_name) tuples marking Level-X boundaries.\"\"\"\n",
        "        boundaries = []\n",
        "        # GENERALIZED PATTERN: Matches \"Level-2\", \"Level 3\", \"Level4\", etc. WITHOUT domain keywords\n",
        "        level_pattern = r'Level[-\\s]*(\\d+)'\n",
        "        for idx, u in enumerate(units):\n",
        "            u_text = u.get(\"text\", \"\").strip()\n",
        "            if not u_text:\n",
        "                continue\n",
        "            # Check if this unit contains a Level-X marker\n",
        "            match = re.search(level_pattern, u_text, re.IGNORECASE)\n",
        "            if match:\n",
        "                level_num = match.group(1)\n",
        "                level_name = f\"Level-{level_num}\"\n",
        "                boundaries.append((idx, level_name))\n",
        "        return boundaries\n",
        "\n",
        "def process_units_to_chunks(units, emb_model):\n",
        "    \"\"\"\n",
        "    Hybrid chunking that works for ANY CS lecture:\n",
        "    - Uses structural signals (Strategy 1/2) to find candidate titles.\n",
        "    - Dynamically filters to keep ONLY top-level sections.\n",
        "    - Preserves intro and merges subtopics.\n",
        "    - Excludes admin/link-only content AND entire admin pages.\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    main_title_pages = set()\n",
        "    strategy_1_pages = set()\n",
        "    LARGE_ELEMENT_TYPES = {\"image\", \"table\", \"chart\", \"display_formula\", \"algorithm\"}\n",
        "\n",
        "    # === PASS 0: PRE-FILTER OUT ADMIN PAGES ENTIRELY ===\n",
        "    # First, identify pages with admin titles\n",
        "    page_to_units = {}\n",
        "    for u in units:\n",
        "        page_no = u[\"page\"]\n",
        "        if page_no not in page_to_units:\n",
        "            page_to_units[page_no] = []\n",
        "        page_to_units[page_no].append(u)\n",
        "\n",
        "    admin_pages = set()\n",
        "    for page_no, page_units in page_to_units.items():\n",
        "        if page_units:\n",
        "            first_text = page_units[0].get(\"text\", \"\").strip()\n",
        "            if is_personal_info(first_text):\n",
        "                print(f\"⏭️ Skipping entire page {page_no} (admin title): '{first_text}'\")\n",
        "                admin_pages.add(page_no)\n",
        "\n",
        "    # Filter out all units from admin pages\n",
        "    filtered_units = [u for u in units if u[\"page\"] not in admin_pages]\n",
        "    units = filtered_units\n",
        "\n",
        "    # Rebuild page_to_units with filtered units\n",
        "    page_to_units = {}\n",
        "    for u in units:\n",
        "        page_no = u[\"page\"]\n",
        "        if page_no not in page_to_units:\n",
        "            page_to_units[page_no] = []\n",
        "        page_to_units[page_no].append(u)\n",
        "\n",
        "    # === PASS 1: Detect ALL title candidates ===\n",
        "    for page_no, page_units in page_to_units.items():\n",
        "        if not page_units: continue\n",
        "\n",
        "        # Unified Strategy 1 detection\n",
        "        first_unit = page_units[0]\n",
        "        first_text = first_unit.get(\"text\", \"\").strip()\n",
        "        y1 = first_unit.get(\"bbox\", [0,0,0,0])[1]\n",
        "\n",
        "        # Check if first unit is a valid title candidate\n",
        "        is_ocr_title = first_unit[\"type\"] == \"paragraph_title\"\n",
        "        is_positional_title = (\n",
        "            (y1 < 300) and\n",
        "            (5 < len(first_text) < 100) and\n",
        "            first_unit.get(\"type\") not in LARGE_ELEMENT_TYPES\n",
        "        )\n",
        "        is_valid = is_valid_title(first_text)\n",
        "\n",
        "        if (is_ocr_title or is_positional_title) and is_valid:\n",
        "            # Calculate content weight (ignoring first unit)\n",
        "            content_weight = sum(\n",
        "                5 if u[\"type\"] in LARGE_ELEMENT_TYPES else 1\n",
        "                for u in page_units[1:]\n",
        "            )\n",
        "\n",
        "            # NEW: Check for structural keywords\n",
        "            structural_keywords = [\"comparison\", \"levels\", \"deployment\", \"challenges\", \"protocols\", \"domains\"]\n",
        "            has_structural_keyword = any(kw in first_text.lower() for kw in structural_keywords)\n",
        "\n",
        "            # STRATEGY 1: Single-title OR low content OR structural keyword\n",
        "            if len(page_units) == 1 or content_weight < 1 or has_structural_keyword:\n",
        "                main_title_pages.add(page_no)\n",
        "                strategy_1_pages.add(page_no)\n",
        "                print(f\"✅ [STRATEGY 1] Title detected on Page {page_no}: '{first_text}'\")\n",
        "                continue\n",
        "\n",
        "            # Strategy 2: Title with substantial content\n",
        "            else:\n",
        "                main_title_pages.add(page_no)\n",
        "                print(f\"✅ [STRATEGY 2] Title detected on Page {page_no}: '{first_text}' (IoT-style (with content))\")\n",
        "\n",
        "    # === CRITICAL: Filter to TOP-LEVEL sections only ===\n",
        "    real_strategy_1_pages = {p for p in strategy_1_pages if p != 1}\n",
        "\n",
        "    if real_strategy_1_pages:\n",
        "        main_title_pages = real_strategy_1_pages\n",
        "        print(\"🎯 Using all Strategy 1 pages as top-level sections.\")\n",
        "    else:\n",
        "        print(\"🎯 Falling back to Strategy 2 titles.\")\n",
        "\n",
        "    if  main_title_pages:\n",
        "        print(f\"🎯 Final title pages used: {sorted(main_title_pages)}\")\n",
        "\n",
        "    # === PASS 2: Build Chunks (USE EACH PAGE ONCE) ===\n",
        "    first_main_title_idx = None\n",
        "    for i, u in enumerate(units):\n",
        "        if u[\"page\"] in main_title_pages and is_valid_title(u.get(\"text\", \"\").strip()):\n",
        "            first_main_title_idx = i\n",
        "            break\n",
        "\n",
        "    # Handle intro (exclude admin/link content)\n",
        "    if first_main_title_idx is not None and first_main_title_idx > 0:\n",
        "        intro_units = [\n",
        "            u for u in units[:first_main_title_idx]\n",
        "            if u.get(\"text\", \"\").strip() and not is_personal_info(u.get(\"text\", \"\"))\n",
        "        ]\n",
        "        if intro_units:\n",
        "            chunks.append({\n",
        "                \"concept\": \"Introduction\",\n",
        "                \"content\": intro_units,\n",
        "                \"page_start\": intro_units[0][\"page\"]\n",
        "            })\n",
        "        units = units[first_main_title_idx:]\n",
        "\n",
        "    # Build chunks (skip admin/link units)\n",
        "    current_concept = \"General Section\"\n",
        "    current_content = []\n",
        "    current_page_start = None\n",
        "    initial_chunks = []\n",
        "    used_title_pages = set()\n",
        "\n",
        "    for u in units:\n",
        "        u_text = u.get(\"text\", \"\").strip()\n",
        "        if not u_text or is_personal_info(u_text):\n",
        "            continue  # ← Skip admin/link-only units\n",
        "\n",
        "        page_no = u[\"page\"]\n",
        "        y1 = u.get(\"bbox\", [0,0,0,0])[1]\n",
        "        is_eligible_title = (\n",
        "            page_no in main_title_pages and\n",
        "            page_no not in used_title_pages and\n",
        "            ((u[\"type\"] == \"paragraph_title\" or (y1 < 300 and len(u_text) < 100 and u[\"type\"] not in LARGE_ELEMENT_TYPES )) and is_valid_title(u_text))\n",
        "        )\n",
        "\n",
        "        if is_eligible_title:\n",
        "            if current_content:\n",
        "                initial_chunks.append({\n",
        "                    \"concept\": current_concept,\n",
        "                    \"content\": current_content,\n",
        "                    \"page_start\": current_page_start\n",
        "                })\n",
        "            current_concept = u_text\n",
        "            current_content = []\n",
        "            current_page_start = page_no\n",
        "            used_title_pages.add(page_no)\n",
        "            print(f\"📌 Starting new chunk: '{current_concept}' (Page {page_no})\")\n",
        "        else:\n",
        "            current_content.append(u)\n",
        "\n",
        "    if current_content:\n",
        "        initial_chunks.append({\n",
        "            \"concept\": current_concept,\n",
        "            \"content\": current_content,\n",
        "            \"page_start\": current_page_start\n",
        "        })\n",
        "\n",
        "    print(f\"📦 Initial chunk count: {len(initial_chunks)}\")\n",
        "\n",
        "    # === PASS 3: Merge by TITLE Similarity (threshold=0.85) ===\n",
        "    final_chunks = []\n",
        "    i = 0\n",
        "    while i < len(initial_chunks):\n",
        "        current_chunk = initial_chunks[i]\n",
        "        merged_content = current_chunk[\"content\"]\n",
        "        merged_concept = current_chunk[\"concept\"]\n",
        "        merged_page_start = current_chunk[\"page_start\"]\n",
        "\n",
        "        j = i + 1\n",
        "        while j < len(initial_chunks):\n",
        "            next_chunk = initial_chunks[j]\n",
        "            next_concept = next_chunk[\"concept\"]\n",
        "\n",
        "            if not merged_concept.strip() or not next_concept.strip():\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                emb1 = emb_model.encode([merged_concept], normalize_embeddings=True)\n",
        "                emb2 = emb_model.encode([next_concept], normalize_embeddings=True)\n",
        "                sim = cosine_similarity(emb1, emb2)[0][0]\n",
        "\n",
        "                if sim >= 0.85:\n",
        "                    print(f\"🔗 Merging title '{merged_concept}' with '{next_concept}' (sim={sim:.2f})\")\n",
        "                    merged_content.extend(next_chunk[\"content\"])\n",
        "                    j += 1\n",
        "                else:\n",
        "                    print(f\"🚫 NOT merging '{merged_concept}' and '{next_concept}' (sim={sim:.2f})\")\n",
        "                    break\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Title similarity failed: {e}\")\n",
        "                break\n",
        "\n",
        "        final_chunks.append({\n",
        "            \"concept\": merged_concept,\n",
        "            \"content\": merged_content,\n",
        "            \"page_start\": merged_page_start\n",
        "        })\n",
        "        i = j\n",
        "\n",
        "    # Prepend Introduction\n",
        "    if chunks:\n",
        "        final_chunks = chunks + final_chunks\n",
        "\n",
        "    print(f\"📦 Final chunk count after merging: {len(final_chunks)}\")\n",
        "    for idx, ch in enumerate(final_chunks):\n",
        "        print(f\"   Chunk {idx+1}: '{ch['concept']}' (Pages: {ch['page_start']}+)\")\n",
        "\n",
        "    return final_chunks\n",
        "\n",
        "\n",
        "\n",
        "def chunk_to_embedding_text(chunks, max_chars=1800):\n",
        "    \"\"\"\n",
        "    Converts chunks to embedding-ready text with STRICT page integrity:\n",
        "    - Never splits a page across subchunks\n",
        "    - Each subchunk contains complete pages only\n",
        "    - SPECIAL: For chunks containing \"Level-X\" patterns, splits by Level boundaries BEFORE page alignment\n",
        "    \"\"\"\n",
        "    embeddings = []\n",
        "\n",
        "    for chunk_idx, chunk in enumerate(chunks):\n",
        "        concept = chunk.get(\"concept\", \"\").strip()\n",
        "        units = chunk.get(\"content\", [])\n",
        "        if not units:\n",
        "            print(f\"⚠️ Chunk {chunk_idx+1} ('{concept}') has no units. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n📦 Processing Chunk {chunk_idx+1}: '{concept}'\")\n",
        "\n",
        "        # Clean units (existing logic preserved)\n",
        "        effective_units = []\n",
        "        for u in units:\n",
        "            u_text = u.get(\"text\", \"\").strip()\n",
        "            if not u_text: continue\n",
        "            if u.get(\"type\") in (\"image\", \"chart\") and \"[Image recovery failed]\" in u_text:\n",
        "                continue\n",
        "            if \"display_formula\" in u.get(\"type\", \"\") or \"$\" in u_text:\n",
        "                u_text = latex_to_unicode(u_text)\n",
        "            elif u.get(\"type\") == \"algorithm\":\n",
        "                u_text = normalize_code(u_text)\n",
        "            u_text = html.unescape(u_text)\n",
        "            effective_units.append({**u, \"effective_text\": u_text})\n",
        "\n",
        "        if not effective_units:\n",
        "            print(f\"⚠️ Chunk {chunk_idx+1} has no valid units after cleaning. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        full_text = \"\\n\\n\".join(u[\"effective_text\"] for u in effective_units)\n",
        "        total_pages = sorted(set(u[\"page\"] for u in effective_units))\n",
        "        print(f\"   Pages: {total_pages} | Total chars: {len(full_text)}\")\n",
        "\n",
        "        # GENERAL CONDITION: Activate splitting if chunk concept mentions \"level\" AND has multiple units\n",
        "        is_levels_chunk = \"level\" in concept.lower()\n",
        "        level_subchunks = []\n",
        "\n",
        "        if is_levels_chunk and len(effective_units) > 1:\n",
        "            # Detect Level boundaries in the chunk\n",
        "            boundaries = detect_level_boundaries(full_text, effective_units)\n",
        "            if boundaries:\n",
        "                print(f\"   🔬 Detected {len(boundaries)} Level boundaries: {[name for _, name in boundaries]}\")\n",
        "\n",
        "                # Ensure first unit is a boundary if it looks like a Level\n",
        "                first_unit_text = effective_units[0].get(\"text\", \"\")\n",
        "                if \"Level-\" in first_unit_text and not any(idx == 0 for idx, _ in boundaries):\n",
        "                    # Extract level number from first unit if possible\n",
        "                    match_first = re.search(r'Level[-\\s]*(\\d+)', first_unit_text, re.IGNORECASE)\n",
        "                    if match_first:\n",
        "                        level_num = match_first.group(1)\n",
        "                        boundaries.insert(0, (0, f\"Level-{level_num}\"))\n",
        "                    else:\n",
        "                        boundaries.insert(0, (0, \"Level-1\"))  # Fallback\n",
        "\n",
        "                # Split chunk into Level-based subchunks\n",
        "                start_idx = 0\n",
        "                for boundary_idx, level_name in boundaries:\n",
        "                    if boundary_idx > start_idx:\n",
        "                        level_subchunks.append({\n",
        "                            \"concept\": f\"{concept} ({level_name})\",\n",
        "                            \"units\": effective_units[start_idx:boundary_idx],\n",
        "                            \"level_name\": level_name\n",
        "                        })\n",
        "                    start_idx = boundary_idx\n",
        "                # Add final segment\n",
        "                if start_idx < len(effective_units):\n",
        "                    last_level = boundaries[-1][1] if boundaries else \"Level-1\"\n",
        "                    level_subchunks.append({\n",
        "                        \"concept\": f\"{concept} ({last_level}+)\",\n",
        "                        \"units\": effective_units[start_idx:],\n",
        "                        \"level_name\": f\"{last_level}+\"\n",
        "                    })\n",
        "                print(f\"   ✂️  Split into {len(level_subchunks)} Level-based segments\")\n",
        "            else:\n",
        "                # No boundaries detected → treat as single segment\n",
        "                level_subchunks = [{\n",
        "                    \"concept\": concept,\n",
        "                    \"units\": effective_units,\n",
        "                    \"level_name\": None\n",
        "                }]\n",
        "        else:\n",
        "            # Non-Levels chunk → single segment (existing behavior)\n",
        "            level_subchunks = [{\n",
        "                \"concept\": concept,\n",
        "                \"units\": effective_units,\n",
        "                \"level_name\": None\n",
        "            }]\n",
        "\n",
        "        # Process each segment (Level-based or whole chunk) with page-aligned splitting\n",
        "        for seg_idx, segment in enumerate(level_subchunks):\n",
        "            seg_concept = segment[\"concept\"]\n",
        "            seg_units = segment[\"units\"]\n",
        "            seg_text = \"\\n\\n\".join(u[\"effective_text\"] for u in seg_units)\n",
        "            seg_pages = sorted(set(u[\"page\"] for u in seg_units))\n",
        "\n",
        "            if len(seg_text) <= max_chars:\n",
        "                # Single subchunk (existing logic)\n",
        "                print(f\"   ✅ Single subchunk for '{seg_concept}' (≤{max_chars} chars)\")\n",
        "                embedding_input = f\"Concept: {seg_concept}\\nRole: section\\n\\n{seg_text}\"\n",
        "                embeddings.append({\n",
        "                    \"embedding_text\": embedding_input,\n",
        "                    \"metadata\": {\n",
        "                        \"concept\": seg_concept,\n",
        "                        \"page\": seg_units[0].get(\"page\") if seg_units else chunk.get(\"page_start\"),\n",
        "                        \"units\": seg_units,\n",
        "                        \"total_subchunks\": 1\n",
        "                    }\n",
        "                })\n",
        "            else:\n",
        "                # PAGE-ALIGNED SUBCHUNKING (existing logic preserved)\n",
        "                print(f\"   🔍 Splitting segment '{seg_concept}' (> {max_chars} chars)...\")\n",
        "\n",
        "                # Group units by page\n",
        "                page_to_units = {}\n",
        "                for u in seg_units:\n",
        "                    page_to_units.setdefault(u[\"page\"], []).append(u)\n",
        "\n",
        "                # Create page-aligned subchunks\n",
        "                subchunks = []\n",
        "                current_pages = []\n",
        "                current_text = \"\"\n",
        "\n",
        "                for page_no in sorted(page_to_units.keys()):\n",
        "                    page_units = page_to_units[page_no]\n",
        "                    page_text = \"\\n\\n\".join(u[\"effective_text\"] for u in page_units)\n",
        "\n",
        "                    if current_text and (len(current_text) + len(page_text) + 2 > max_chars):\n",
        "                        # Finalize current subchunk\n",
        "                        subchunks.append({\n",
        "                            \"text\": current_text.strip(),\n",
        "                            \"units\": [u for p in current_pages for u in page_to_units[p]]\n",
        "                        })\n",
        "                        print(f\"   📄 Subchunk {len(subchunks)}: Pages {current_pages} ({len(current_text)} chars)\")\n",
        "\n",
        "                        # Start new subchunk\n",
        "                        current_pages = [page_no]\n",
        "                        current_text = page_text\n",
        "                    else:\n",
        "                        current_pages.append(page_no)\n",
        "                        current_text += (\"\\n\\n\" + page_text) if current_text else page_text\n",
        "\n",
        "                # Add last subchunk\n",
        "                if current_text:\n",
        "                    subchunks.append({\n",
        "                        \"text\": current_text.strip(),\n",
        "                        \"units\": [u for p in current_pages for u in page_to_units[p]]\n",
        "                    })\n",
        "                    print(f\"   📄 Subchunk {len(subchunks)}: Pages {current_pages} ({len(current_text)} chars)\")\n",
        "\n",
        "                print(f\"   ✅ Created {len(subchunks)} page-aligned subchunks for '{seg_concept}'\")\n",
        "\n",
        "                # Create embeddings for each subchunk\n",
        "                for idx, sc in enumerate(subchunks):\n",
        "                    embedding_input = f\"Concept: {seg_concept}\\nRole: section\\n\\n{sc['text']}\"\n",
        "                    embeddings.append({\n",
        "                        \"embedding_text\": embedding_input,\n",
        "                        \"metadata\": {\n",
        "                            \"concept\": seg_concept,\n",
        "                            \"page\": sc[\"units\"][0].get(\"page\") if sc[\"units\"] else chunk.get(\"page_start\"),\n",
        "                            \"units\": sc[\"units\"],\n",
        "                            \"total_subchunks\": len(subchunks)\n",
        "                        }\n",
        "                    })\n",
        "\n",
        "    print(f\"\\n🎯 Total embedding inputs generated: {len(embeddings)}\")\n",
        "    return embeddings\n",
        "\n",
        "print(\"✅ Step 9 Complete: Chunking logic improved for slides.\")"
      ],
      "metadata": {
        "id": "CnM9wGfQJ72m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a0d783-5bd9-4259-d466-9d0bfd8792a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Step 9 Complete: Chunking logic improved for slides.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ⚙️ Step 10: Main PDF Processing Loop (Memory Safe)\n",
        "# @markdown Runs OCR on every page. Optimized to prevent GPU crashes.\n",
        "\n",
        "def extract_pdf_info(pdf_path, pipeline):\n",
        "    \"\"\"\n",
        "    Main Loop: PDF -> Images -> OCR -> JSON\n",
        "    \"\"\"\n",
        "    pdf_name = pdf_path.stem\n",
        "\n",
        "    # Use the global directories we set in Step 3\n",
        "    pdf_image_dir = IMAGE_DIR / pdf_name\n",
        "    pdf_json_dir = JSON_DIR / pdf_name\n",
        "\n",
        "    for d in [pdf_image_dir, pdf_json_dir]:\n",
        "        d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    final_json_path = pdf_json_dir / f\"{pdf_name}.json\"\n",
        "\n",
        "    # Get page count\n",
        "    try:\n",
        "        num_pages = pdfinfo_from_path(str(pdf_path))['Pages']\n",
        "    except:\n",
        "        print(\"⚠️ Could not read PDF info. Installing poppler again...\")\n",
        "        os.system(\"apt-get install -y poppler-utils\")\n",
        "        num_pages = pdfinfo_from_path(str(pdf_path))['Pages']\n",
        "\n",
        "    pdf_result = {\n",
        "        \"file_name\": pdf_path.name,\n",
        "        \"num_pages\": num_pages,\n",
        "        \"pages\": []\n",
        "    }\n",
        "\n",
        "    print(f\"[*] Starting OCR for {pdf_name} ({num_pages} pages)...\")\n",
        "    pbar = tqdm(range(1, num_pages + 1), desc=\"OCR Processing\", unit=\"page\")\n",
        "\n",
        "    for i in pbar:\n",
        "        try:\n",
        "            # 1. CLEAN MEMORY BEFORE STARTING (Critical for Colab)\n",
        "            paddle.device.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "            # 2. Convert PDF Page to Image (LOWER RES to save RAM)\n",
        "            # Changed dpi=150 -> dpi=100 to prevent OOM\n",
        "            page = convert_from_path(str(pdf_path), dpi=100, first_page=i, last_page=i)\n",
        "            page_img = page[0]\n",
        "\n",
        "            if page_img.width == 0 or page_img.height == 0: continue\n",
        "\n",
        "            page_np = np.array(page_img).astype(\"uint8\")\n",
        "            image_path = pdf_image_dir / f\"page_{i:03d}.png\"\n",
        "            page_img.save(image_path)\n",
        "\n",
        "            # 3. Run PaddleOCR\n",
        "            output = pipeline.predict(page_np)\n",
        "            result = output[0]\n",
        "\n",
        "            # 4. Parse Results\n",
        "            parsing_res_list = [to_dict(block) for block in result.get(\"parsing_res_list\", [])]\n",
        "            layout_det_res = to_dict(result.get(\"layout_det_res\", {}))\n",
        "\n",
        "            pbar.set_postfix_str(f\"Found {len(parsing_res_list)} blocks\", refresh=True)\n",
        "\n",
        "            pdf_result[\"pages\"].append({\n",
        "                \"page_number\": i,\n",
        "                \"image_path\": str(image_path),\n",
        "                \"parsing_res_list\": parsing_res_list,\n",
        "                \"layout_det_res\": layout_det_res,\n",
        "                \"height\": page_img.height,\n",
        "                \"width\": page_img.width\n",
        "            })\n",
        "\n",
        "            # Cleanup RAM explicitly\n",
        "            del page_img, page_np, page, output, result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error on page {i}: {e}\")\n",
        "            # If a page fails, we try to skip it to save the rest of the document\n",
        "            continue\n",
        "\n",
        "    # Save Final JSON\n",
        "    with open(final_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(pdf_result, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"✅ OCR Complete. Data saved to: {final_json_path}\")\n",
        "    return pdf_result\n",
        "\n",
        "print(\"✅ Step 10 Complete: Extraction loop optimized.\")"
      ],
      "metadata": {
        "id": "qosl9-n-KDge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b37d2fb2-0af8-4e16-fa3f-e1671e5a888b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Step 10 Complete: Extraction loop optimized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🧠 Step 11: Embedding Model Helpers\n",
        "# @markdown Loads the BGE-M3 model to convert text chunks into vectors.\n",
        "\n",
        "def load_embedding_model():\n",
        "    \"\"\"Loads the SentenceTransformer model on GPU.\"\"\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"[*] Loading Embedding Model on {device}...\")\n",
        "    return SentenceTransformer(\"BAAI/bge-m3\", device=device)\n",
        "\n",
        "def get_embedding(text: str, embModel) -> List[float]:\n",
        "    \"\"\"Generates a normalized vector for a given text string.\"\"\"\n",
        "    # normalize_embeddings=True improves cosine similarity accuracy\n",
        "    emb = embModel.encode([text], normalize_embeddings=True)\n",
        "    return emb[0].tolist()\n",
        "\n",
        "print(\"✅ Step 11 Complete: Embedding functions defined.\")"
      ],
      "metadata": {
        "id": "Q8cF7tzUKnkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c1433f-23ed-4f6e-a032-60d3f8233d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Step 11 Complete: Embedding functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🧪 TEST: Load Units from Drive & Run Chunking + Embedding Text Generation\n",
        "# import json\n",
        "# from pathlib import Path\n",
        "\n",
        "# # --- CONFIGURE YOUR PDF NAME HERE ---\n",
        "# PDF_NAME = \"[IoT_25] Lecture 1\"  # ← Change this if needed\n",
        "\n",
        "# # --- LOAD EXISTING UNITS ---\n",
        "# unified_dir = UNIFIED_DIR / PDF_NAME\n",
        "# units_path = unified_dir / f\"{PDF_NAME}_units.json\"\n",
        "\n",
        "# if not units_path.exists():\n",
        "#     print(f\"❌ Units file not found: {units_path}\")\n",
        "#     print(\"👉 Make sure you've run OCR at least once, or upload your own _units.json\")\n",
        "# else:\n",
        "#     print(f\"[*] Loading units from: {units_path}\")\n",
        "#     with open(units_path, \"r\", encoding=\"utf-8\") as f:\n",
        "#         units = json.load(f)\n",
        "#     print(f\"✅ Loaded {len(units)} units.\")\n",
        "\n",
        "#     # --- RUN CHUNKING ---\n",
        "#     print(\"\\n[*] Running process_units_to_chunks...\")\n",
        "#     embedding_model = load_embedding_model()  # From Step 11\n",
        "#     chunks = process_units_to_chunks(units, embedding_model)\n",
        "\n",
        "#     # --- SAVE CHUNKS ---\n",
        "#     chunks_path = unified_dir / f\"{PDF_NAME}_chunks_TEST.json\"\n",
        "#     with open(chunks_path, \"w\", encoding=\"utf-8\") as f:\n",
        "#         json.dump({\"doc_id\": PDF_NAME, \"chunks\": chunks}, f, ensure_ascii=False, indent=2)\n",
        "#     print(f\"✅ Generated {len(chunks)} chunks.\")\n",
        "#     print(f\"💾 Saved chunks to: {chunks_path}\")\n",
        "\n",
        "#     # --- GENERATE EMBEDDING TEXTS (NEW STEP) ---\n",
        "#     print(\"\\n[*] Generating embedding-ready texts with page-aligned subchunking...\")\n",
        "#     embedding_texts = chunk_to_embedding_text(chunks)\n",
        "\n",
        "#     # --- SAVE EMBEDDING INPUTS ---\n",
        "#     embedding_dir = EMBEDDING_DIR / PDF_NAME\n",
        "#     embedding_dir.mkdir(parents=True, exist_ok=True)\n",
        "#     embedding_path = embedding_dir / f\"{PDF_NAME}_embedding_input_texts_TEST.json\"\n",
        "\n",
        "#     with open(embedding_path, \"w\", encoding=\"utf-8\") as f:\n",
        "#         json.dump({\n",
        "#             \"doc_id\": PDF_NAME,\n",
        "#             \"inputs\": embedding_texts\n",
        "#         }, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "#     print(f\"✅ Generated {len(embedding_texts)} embedding inputs.\")\n",
        "#     print(f\"💾 Saved embedding inputs to: {embedding_path}\")\n",
        "\n",
        "#     # --- PRINT SUMMARY ---\n",
        "#     print(\"\\n📋 Chunk Concepts:\")\n",
        "#     for i, ch in enumerate(chunks):\n",
        "#         pages = sorted(set(u[\"page\"] for u in ch.get(\"content\", [])))\n",
        "#         print(f\"  {i+1}. '{ch['concept']}' (Pages: {pages})\")\n",
        "\n",
        "#     total_subchunks = sum(item[\"metadata\"][\"total_subchunks\"] for item in embedding_texts)\n",
        "#     print(f\"\\n📊 Total subchunks for podcast: {total_subchunks} (each ≈6 minutes)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVmLPuXkWZaI",
        "outputId": "6b65c82a-8eb0-460f-9268-5eaef4ab6e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Units file not found: /content/drive/MyDrive/Doc2Pod_System/Data/unified_json/[IoT_25] Lecture 1/[IoT_25] Lecture 1_units.json\n",
            "👉 Make sure you've run OCR at least once, or upload your own _units.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ⚙️ Step 12: Extraction Pipeline (Refactored)\n",
        "\n",
        "def run_friend_extraction_pipeline(pdf_path):\n",
        "    \"\"\"\n",
        "    Runs the full OCR -> Chunking -> Embedding pipeline on a single PDF.\n",
        "    Refactored from 'main()' to be modular.\n",
        "    \"\"\"\n",
        "    print(f\"🚀 Starting Extraction Pipeline for: {pdf_path.name}\")\n",
        "\n",
        "    pdf_name_raw = pdf_path.stem\n",
        "    # Sanitize name to be used for collection name and now also for folder names\n",
        "    pdf_name = re.sub(r'[^a-zA-Z0-9._-]', '_', pdf_name_raw)\n",
        "\n",
        "    # 1. OCR & Layout Analysis\n",
        "    pipeline_manager = LazyPipelineManager()\n",
        "    VL_Pipeline = pipeline_manager.get_vl_pipeline()\n",
        "\n",
        "    ocr_result = extract_pdf_info(pdf_path, VL_Pipeline)\n",
        "    print(\"✅ OCR Complete.\")\n",
        "\n",
        "    # 2. Convert to Units\n",
        "    units = blocks_to_units(ocr_result, pipeline_manager)\n",
        "\n",
        "    # **Explicitly unload vision models to free up GPU memory**\n",
        "    pipeline_manager.unload_all()\n",
        "\n",
        "    # Use sanitized name for unified_json directory\n",
        "    unified_dir = UNIFIED_DIR / pdf_name\n",
        "    unified_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Use sanitized name for units file\n",
        "    units_path = unified_dir / f\"{pdf_name}_units.json\"\n",
        "    with open(units_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(units, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"✅ Created {len(units)} raw units.\")\n",
        "\n",
        "    # 3. Semantic Chunking\n",
        "    print(\"[*] Loading Embedding Model...\")\n",
        "    embedding_model = load_embedding_model()\n",
        "\n",
        "    chunks = process_units_to_chunks(units, embedding_model)\n",
        "    # Use sanitized name for chunks file\n",
        "    chunks_path = unified_dir / f\"{pdf_name}_chunks.json\"\n",
        "    with open(chunks_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"doc_id\": pdf_name_raw, \"chunks\": chunks}, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"✅ Generated {len(chunks)} chunks.\")\n",
        "\n",
        "    # 4. Prepare Embeddings\n",
        "    # Use sanitized name for embedding_inputs directory\n",
        "    embedding_dir = EMBEDDING_DIR / pdf_name\n",
        "    embedding_dir.mkdir(parents=True, exist_ok=True)\n",
        "    # Use sanitized name for embedding input texts file\n",
        "    embedding_path = embedding_dir / f\"{pdf_name}_embedding_input_texts.json\"\n",
        "    embedding_inputs = []\n",
        "\n",
        "    for idx, item in enumerate(chunk_to_embedding_text(chunks)):\n",
        "        text = item[\"embedding_text\"]\n",
        "        metadata = item[\"metadata\"]\n",
        "        if not text.strip(): continue\n",
        "\n",
        "        embedding_inputs.append({\n",
        "            \"embedding_id\": f\"{pdf_name_raw}_c{idx:04d}\", # Use raw name for embedding ID if needed for lookup back to original doc\n",
        "            \"page\": metadata.get(\"page\"),\n",
        "            \"text\": text,\n",
        "            \"metadata\": metadata\n",
        "        })\n",
        "\n",
        "    with open(embedding_path, \"w\", encoding=\"utf-8\") as f:\n",
        "          json.dump({\"doc_id\": pdf_name_raw, \"inputs\": embedding_inputs}, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    # 5. Store in ChromaDB (Using Global DB_DIR)\n",
        "    chroma_client = chromadb.PersistentClient(path=str(DB_DIR))\n",
        "    collection_name = f\"cs_podcast_{pdf_name}\"\n",
        "\n",
        "    try:\n",
        "        chroma_client.delete_collection(name=collection_name)\n",
        "    except: pass\n",
        "\n",
        "    collection = chroma_client.get_or_create_collection(\n",
        "        name=collection_name,\n",
        "        metadata={\"hnsw:space\": \"cosine\"}\n",
        "    )\n",
        "\n",
        "    print(f\"[*] Storing {len(embedding_inputs)} vectors in DB...\")\n",
        "\n",
        "    ids, embeddings, documents, metadatas = [], [], [], []\n",
        "\n",
        "    for item in tqdm(embedding_inputs, desc=\"Embedding\"):\n",
        "        emb_id = item[\"embedding_id\"]\n",
        "        text = item[\"text\"]\n",
        "        meta = item[\"metadata\"]\n",
        "\n",
        "        emb = get_embedding(text, embedding_model)\n",
        "\n",
        "        chroma_meta = {\n",
        "            \"doc_id\": pdf_name_raw,\n",
        "            \"concept\": meta.get(\"concept\", \"\"),\n",
        "            \"page\": meta.get(\"page\", 0),\n",
        "            \"unit_ids\": \",\".join([u[\"unit_id\"] for u in meta.get(\"units\", [])])\n",
        "        }\n",
        "\n",
        "        ids.append(emb_id)\n",
        "        embeddings.append(emb)\n",
        "        documents.append(text)\n",
        "        metadatas.append(chroma_meta)\n",
        "\n",
        "    collection.add(\n",
        "        ids=ids,\n",
        "        embeddings=embeddings,\n",
        "        documents=documents,\n",
        "        metadatas=metadatas\n",
        "    )\n",
        "\n",
        "    print(f\"🎉 Pipeline Success! Data ready for RAG.\")\n",
        "\n",
        "print(\"✅ Step 12 Complete: extraction pipeline packaged as a function.\")\n"
      ],
      "metadata": {
        "id": "pOag9eZ_LHUB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e31a92f-06ad-4f74-a5ec-802f96af0967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Step 12 Complete: extraction pipeline packaged as a function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🔍 Step 13: Retrieval System (Fixed ID Mapping + Debug Mode)\n",
        "# @markdown Unified retrieval with CORRECT embedding_id mapping + optional debug output\n",
        "class Doc2PodRetrieval:\n",
        "    def __init__(self, db_path, collection_name, use_gpu=True, debug=False):\n",
        "        self.device = \"cuda\" if use_gpu else \"cpu\"\n",
        "        self.debug = debug\n",
        "        self.client = chromadb.PersistentClient(path=str(db_path))\n",
        "        self.collection = self.client.get_collection(name=collection_name)\n",
        "        self.emb_model = SentenceTransformer(\"BAAI/bge-m3\", device=self.device)\n",
        "        if self.debug:\n",
        "            print(f\"✅ Loaded collection '{collection_name}' with {self.collection.count()} vectors\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _load_subchunks(embedding_dir, embedding_path):\n",
        "        \"\"\"Load all subchunks from embedding_inputs directory.\"\"\"\n",
        "        with open(embedding_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "        return data[\"inputs\"]\n",
        "\n",
        "    def get_context(self, embedding_dir, embedding_path, query=None, page_range=None, k=10):\n",
        "        \"\"\"\n",
        "        Unified retrieval that works with SUBCHUNKS.\n",
        "        Returns list of {text, concept, total_subs, next_concept} dicts.\n",
        "        \"\"\"\n",
        "        # Load all subchunks (includes embedding_id field)\n",
        "        all_subchunks = Doc2PodRetrieval._load_subchunks(embedding_dir, embedding_path)\n",
        "\n",
        "        id_to_subchunk = {\n",
        "            sc.get(\"embedding_id\"): sc\n",
        "            for sc in all_subchunks\n",
        "            if sc.get(\"embedding_id\")\n",
        "        }\n",
        "\n",
        "        if self.debug:\n",
        "            print(f\"🔍 Loaded {len(all_subchunks)} subchunks\")\n",
        "            print(f\"🔍 ID mapping size: {len(id_to_subchunk)}\")\n",
        "            if id_to_subchunk:\n",
        "                sample_id = list(id_to_subchunk.keys())[0]\n",
        "                print(f\"🔍 Sample ID format: '{sample_id}'\")\n",
        "\n",
        "        # === SCENARIO: Range Only (No Query) ===\n",
        "        if not query and page_range:\n",
        "            start_page, end_page = page_range\n",
        "            filtered_subchunks = [\n",
        "                sc for sc in all_subchunks\n",
        "                if start_page <= sc[\"metadata\"][\"page\"] <= end_page\n",
        "            ]\n",
        "            if self.debug:\n",
        "                print(f\"🔍 Range filter ({start_page}-{end_page}): {len(filtered_subchunks)} matches\")\n",
        "            if not filtered_subchunks:\n",
        "                return []\n",
        "\n",
        "            concepts = list(dict.fromkeys([sc[\"metadata\"][\"concept\"] for sc in filtered_subchunks]))\n",
        "            results = []\n",
        "            for sc in filtered_subchunks:\n",
        "                meta = sc[\"metadata\"]\n",
        "                next_concept = None\n",
        "                if meta[\"concept\"] in concepts:\n",
        "                    idx = concepts.index(meta[\"concept\"])\n",
        "                    if idx + 1 < len(concepts):\n",
        "                        next_concept = concepts[idx + 1]\n",
        "                results.append({\n",
        "                    \"text\": sc[\"text\"],\n",
        "                    \"concept\": meta[\"concept\"],\n",
        "                    \"total_subs\": meta[\"total_subchunks\"],\n",
        "                    \"next_concept\": next_concept\n",
        "                })\n",
        "            return results\n",
        "\n",
        "        # === SCENARIO: Query (with/without Range) ===\n",
        "        if query:\n",
        "            # Build ChromaDB filter\n",
        "            where_filter = None\n",
        "            if page_range:\n",
        "                start_page, end_page = page_range\n",
        "                where_filter = {\n",
        "                    \"$and\": [\n",
        "                        {\"page\": {\"$gte\": start_page}},\n",
        "                        {\"page\": {\"$lte\": end_page}}\n",
        "                    ]\n",
        "                }\n",
        "\n",
        "            # Query ChromaDB\n",
        "            query_emb = self.emb_model.encode([query], normalize_embeddings=True)[0].tolist()\n",
        "            chroma_results = self.collection.query(\n",
        "                query_embeddings=[query_emb],\n",
        "                n_results=k,\n",
        "                where=where_filter,\n",
        "                include=[\"documents\", \"metadatas\", \"distances\"]\n",
        "            )\n",
        "\n",
        "            if self.debug:\n",
        "                print(f\"\\n🔍 ChromaDB Query: '{query}'\")\n",
        "                print(f\"   Filter: {where_filter}\")\n",
        "                print(f\"   Raw IDs returned: {chroma_results['ids'][0] if chroma_results['ids'][0] else 'NONE'}\")\n",
        "                print(f\"   Available IDs in mapping: {list(id_to_subchunk.keys())[:3]}...\")\n",
        "\n",
        "            if not chroma_results['ids'] or not chroma_results['ids'][0]:\n",
        "                if self.debug:\n",
        "                    print(\"⚠️ ChromaDB returned NO matches\")\n",
        "                return []\n",
        "\n",
        "            #  MAP USING ACTUAL embedding_id\n",
        "            retrieved_subchunks = []\n",
        "            for emb_id in chroma_results['ids'][0]:\n",
        "                if emb_id in id_to_subchunk:\n",
        "                    retrieved_subchunks.append(id_to_subchunk[emb_id])\n",
        "                elif self.debug:\n",
        "                    print(f\"⚠️ ID mismatch: ChromaDB returned '{emb_id}' but not in mapping\")\n",
        "\n",
        "            if self.debug:\n",
        "                print(f\"✅ Mapped {len(retrieved_subchunks)}/{len(chroma_results['ids'][0])} results\")\n",
        "\n",
        "            if not retrieved_subchunks:\n",
        "                return []\n",
        "            # SORT BY PAGE ORDER FOR PODCAST FLOW\n",
        "            retrieved_subchunks.sort(key=lambda x: x[\"metadata\"][\"page\"])\n",
        "            if self.debug:\n",
        "              print(f\"✅ Sorted {len(retrieved_subchunks)} results by page:\")\n",
        "              for sc in retrieved_subchunks:\n",
        "                  print(f\"   - Page {sc['metadata']['page']}: '{sc['metadata']['concept']}'\")\n",
        "\n",
        "\n",
        "            # Build continuity-aware results\n",
        "            concepts = list(dict.fromkeys([sc[\"metadata\"][\"concept\"] for sc in retrieved_subchunks]))\n",
        "            results = []\n",
        "            for sc in retrieved_subchunks:\n",
        "                meta = sc[\"metadata\"]\n",
        "                next_concept = None\n",
        "                if meta[\"concept\"] in concepts:\n",
        "                    idx = concepts.index(meta[\"concept\"])\n",
        "                    if idx + 1 < len(concepts):\n",
        "                        next_concept = concepts[idx + 1]\n",
        "                results.append({\n",
        "                    \"text\": sc[\"text\"],\n",
        "                    \"concept\": meta[\"concept\"],\n",
        "                    \"total_subs\": meta[\"total_subchunks\"],\n",
        "                    \"next_concept\": next_concept\n",
        "                })\n",
        "            return results\n",
        "\n",
        "        return []\n"
      ],
      "metadata": {
        "id": "JgTtdN4ANVMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ✍️ Step 14: Podcast Script Generator (Upgraded)\n",
        "\n",
        "class PodcastScriptGen:\n",
        "    def __init__(self):\n",
        "        self.langs = {\n",
        "            \"1\": {\"name\": \"English\", \"tone\": \"Professional, crisp\"},\n",
        "            \"2\": {\"name\": \"Modern Standard Arabic (MSA)\", \"tone\": \"Educational\"},\n",
        "            \"3\": {\"name\": \"Egyptian Arabic\", \"tone\": \"Friendly, conversational\"}\n",
        "        }\n",
        "\n",
        "\n",
        "    def _load_structure(self, unified_dir):\n",
        "        \"\"\"Load clean structure from chunks as an ordered list of section titles (Smart Skeleton).\"\"\"\n",
        "        try:\n",
        "            chunk_files = list(unified_dir.glob(\"*_chunks.json\"))\n",
        "            if not chunk_files:\n",
        "                return \"Structure unavailable.\"\n",
        "\n",
        "            with open(chunk_files[0], \"r\", encoding=\"utf-8\") as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            # Extract concept titles in order\n",
        "            concepts = []\n",
        "            seen = set()\n",
        "            for c in data.get(\"chunks\", []):\n",
        "                concept = c.get(\"concept\", \"\").strip()\n",
        "                if (\n",
        "                    concept and\n",
        "                    concept not in seen\n",
        "                ):\n",
        "                    concepts.append(concept)\n",
        "                    seen.add(concept)\n",
        "\n",
        "            if not concepts:\n",
        "                return \"No valid sections found.\"\n",
        "\n",
        "            # Format as numbered list (matches your desired output)\n",
        "            lines = [\"This lecture covers these topics in order:\"]\n",
        "            for i, concept in enumerate(concepts, 1):\n",
        "                lines.append(f\"{i}. {concept}\")\n",
        "\n",
        "            return \"\\n\".join(lines)\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Structure unavailable ({str(e)}).\"\n",
        "\n",
        "    def build_prompt(self, context, user_topic, lang_choice, unified_dir, sub_idx=1, total_subs=1, next_concept=None):\n",
        "        \"\"\"\n",
        "        Generates a prompt for script generation with Smart Skeleton and continuity cues.\n",
        "\n",
        "        Args:\n",
        "            context (str): RAG-retrieved text for current subchunk\n",
        "            user_topic (str): Current section title (e.g., \"IoT Levels\")\n",
        "            lang_choice (str): Language code (\"3\" for Egyptian Arabic)\n",
        "            unified_dir (Path): Path to document's unified JSON directory\n",
        "            sub_idx (int): Current subchunk index (1-based)\n",
        "            total_subs (int): Total subchunks in current section\n",
        "            next_concept (str, optional): Next section title for transition\n",
        "        \"\"\"\n",
        "        config = self.langs.get(lang_choice, self.langs[\"3\"])\n",
        "\n",
        "        # Load clean structure (Smart Skeleton)\n",
        "        doc_structure = self._load_structure(unified_dir)\n",
        "\n",
        "\n",
        "        # CONTINUITY INSTRUCTIONS\n",
        "        continuity_instructions = \"\"\n",
        "        if total_subs > 1:\n",
        "            if sub_idx == 1:\n",
        "                continuity_instructions = f\"Start fresh with a hook question about '{user_topic}'.\"\n",
        "            elif sub_idx == total_subs:\n",
        "                next_topic = next_concept if next_concept else \"الموضوع اللي جاي\"\n",
        "                continuity_instructions = f\"End with: 'وبكده خلصنا موضوع {user_topic}، وهنشوف دلوقتي إيه في {next_topic}.'\"\n",
        "            else:\n",
        "                continuity_instructions = \"Start with: 'واصلًا من النقطة اللي وقفنا عندها...'\"\n",
        "\n",
        "        prompt = f\"\"\"أنت كاتب سيناريو محترف لبرنامج \"بودكاست تقني\" باللهجة المصرية القاهرية (Cairene Slang).\n",
        "            هدفنا: شرح مفاهيم علوم الحاسب (CS) لأي حد ماشي في الشارع باستخدام تشبيهات من الحياة اليومية.\n",
        "\n",
        "            الشخصيات:\n",
        "            - Speaker 1 (سارة): المذيعة. لسانها مصري جداً، دمها خفيف، بتسأل بذكاء وتقاطع أحمد كل شوية عشان الجمهور يفهم.\n",
        "            - Speaker 2 (أحمد): الضيف (Senior Engineer). خبير، صوته هادي، **ممنوع يشرح شرح أكاديمي**، لازم يشرح بـ \"أمثلة شعبية\" (مطبخ، سوق، زحمة، مواصلات).\n",
        "\n",
        "            ⚠️ قائمة الممنوعات (Negative Constraints) - ممنوع تماماً:\n",
        "            1. ❌ ممنوع الفصحى نهائياً (لا تكتب: لماذا، سوف، هذا، نعم، حسناً).\n",
        "            2. ❌ ممنوع الشرح المعقد: لا تشرح تعريفات كتب. اشرح بـ \"تخيل إننا في...\".\n",
        "            3. ❌ ممنوع الجمل الطويلة: المذيعين بيقاطعوا بعض، والجمل لازم تكون قصيرة (≤ 10 كلمات).\n",
        "            4. ❌ ممنوع المؤثرات الصوتية: لا تكتب [موسيقى] أو [ضحك]، اكتب الكلام فقط.\n",
        "\n",
        "            ✅ أسلوب الكتابة المطلوب (Style Guide):\n",
        "            1. **مصري 100%:** استخدم (يا دين النبي، يا خبر، ده، عشان، إيه الحلاوة دي، بص بقى).\n",
        "            2. **الإنجليزية:** المصطلحات التقنية زي ما هي (API, Deadlock, RAM) وسط الكلام.\n",
        "            3. **التشبيه الإجباري (Mandatory Analogy):**\n",
        "              - اقرأ الـ\"FOCUS CONTENT\" جيداً، واستنتج المفهوم الأساسي.\n",
        "              - اختار تشبيه من الحياة المصرية يناسب **جوهر المفهوم** (مش اسمه).\n",
        "                - مثال: لو المفهوم عن \"تنظيم الموارد\" → \"زي مدير المطبخ\".\n",
        "                - لو عن \"التكرار لتحسين النتيجة\" → \"زي البائع اللي بيغير سعره\".\n",
        "            4. **الربط المنطقي:**\n",
        "              - استخدم الـ\"GLOBAL CONTEXT\" علشان تربط بين الأجزاء:\n",
        "                - \"زي ما فهمنا في الجزء اللي فات عن...\"\n",
        "                - \"ده هيخلينا نفكر في الموضوع اللي هنتكلم عنه بعد شوية...\"\n",
        "            5. **الإبداع الموجّه:**\n",
        "              - استخدم المعلومات اللي مديهالك كمرجع أساسي.\n",
        "              - **مسموح لك تضيف أمثلة من معرفتك**، بس **متخرجش عن نطاق الـFOCUS CONTENT**.\n",
        "\n",
        "            ---\n",
        "            ### KEY ENGLISH TERMS TO PRESERVE (Do NOT translate):\n",
        "            - Technical terms: API, RAM, IoT, CPU, Algorithm, Protocol, Cloud, Sensor, Actuator\n",
        "            - File formats: .pdf, .json, .txt\n",
        "            - Code snippets: if x > 5: print(\"hello\")\n",
        "\n",
        "            ---\n",
        "            🌟 المثال الذهبي (اكتب زيه بالظبط):\n",
        "\n",
        "            Speaker 1 (سارة): طب يا أحمد، أنا بسمع كلمة CPU Scheduling دي وبحس إنها طلاسم، إيه الكلام الكبير ده؟\n",
        "            Speaker 2 (أحمد): بصي يا ستي، ولا طلاسم ولا حاجة. تخيلي إن الـ CPU ده هو \"الشيف\" في مطبخ فندق كبير.\n",
        "            Speaker 1 (سارة): حلو، يعني بيطبخ الداتا؟\n",
        "            Speaker 2 (أحمد): الله ينور عليكي! أنتي بقى الزبون، وبتطلبي أوردرات كتير: \"افتح كروم\"، \"شغل أغنية\"، \"نزل ملف\". الشيف ده واحد بس، هيعمل كل ده إزاي في نفس الوقت؟\n",
        "            Speaker 1 (سارة): أكيد هيتجنن! هيسيب الأكل يتحرق ويرد على التليفون.\n",
        "            Speaker 2 (أحمد): بالظبط! هنا بقى بتيجي الـ Algorithms.. دي \"قائمة التعليمات\" اللي المدير بيديها للشيف عشان ينظم وقته. يقوله مثلاً: \"خلص الطلبات السهلة الأول\" (SJF)، أو \"اشتغل في كل طلب دقيقة ولف عليهم\" (Round Robin).\n",
        "            Speaker 1 (سارة): يا ابن اللعيبة! يعني الكمبيوتر بيلف علينا كلنا عشان يرضي الجميع؟\n",
        "            Speaker 2 (أحمد): بالظبط كده. من غير النظام ده، الجهاز \"هيهنج\" والزبون \"هيزهق\" ويمشي.\n",
        "\n",
        "            ---\n",
        "\n",
        "            ### CONTINUITY INSTRUCTIONS\n",
        "            {continuity_instructions}\n",
        "\n",
        "            ### GLOBAL CONTEXT (The Book Map)\n",
        "            {doc_structure}\n",
        "\n",
        "            ### FOCUS CONTENT (The Facts)\n",
        "            {context}\n",
        "\n",
        "            المطلوب منك الآن:\n",
        "            - اقرأ الـ\"FOCUS CONTENT\" وافهم المفهوم الأساسي.\n",
        "            - استخدم الـ\"GLOBAL CONTEXT\" علشان تربط بين الأجزاء.\n",
        "            - اكتب حوار كامل بنفس الروح والأسلوب ده.\n",
        "            - التزم بالهيكل الدرامي:\n",
        "              **(1) Hook** ← سارة تبدأ بسؤال مفاجئ\n",
        "              **(2) Context** ← أحمد يربط بالمفاهيم السابقة\n",
        "              **(3) Deep Dive** ← التشبيه المصري + شرح مبسط\n",
        "              **(4) Twist** ← سارة تقاطع بسؤال ذكي\n",
        "              **(5) Outro** ← أحمد يلخص بجملة مأثورة\n",
        "\n",
        "            مدة الحوار: حوالي 6 دقائق (≈1200 كلمة).\n",
        "            ابدأ الحوار فوراً بدون مقدمات طويلة.\n",
        "\n",
        "            Speaker 1 (سارة):\"\"\"\n",
        "\n",
        "        return prompt.strip()"
      ],
      "metadata": {
        "id": "icsQX8NaNZkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🔧 Step 15a: Thinking Extraction Helper (SAFE VERSION)\n",
        "def extract_clean_script(raw_script):\n",
        "    \"\"\"\n",
        "    SAFELY extracts final answer from Qwen3-Thinking output.\n",
        "    Strategy:\n",
        "    1. Remove ONLY explicit <|thinking|>...</|thinking|> blocks\n",
        "    2. Keep ALL content after last </thinking> marker (dialogue + narrative + transitions)\n",
        "    3. NEVER filter dialogue lines (preserves script flow)\n",
        "    4. Only strip obvious English monologue starters at VERY beginning\n",
        "    \"\"\"\n",
        "    # Method 1: Remove explicit thinking blocks (Qwen3 format) - SAFE\n",
        "    cleaned = re.sub(r'<\\|thinking\\|>.*?<\\|/thinking\\|>', '', raw_script, flags=re.DOTALL)\n",
        "\n",
        "    # Method 2: If thinking tags remain, keep content after last closing tag\n",
        "    if '<|/thinking|>' in cleaned:\n",
        "        parts = cleaned.split('<|/thinking|>')\n",
        "        cleaned = parts[-1].strip()\n",
        "\n",
        "    # Method 3: ONLY remove English monologue starters at VERY BEGINNING (safe for Egyptian Arabic)\n",
        "    monologue_starters = [\n",
        "        r'^Okay,\\s*',\n",
        "        r'^Hmm,\\s*',\n",
        "        r'^First,\\s*',\n",
        "        r'^Let me\\s+',\n",
        "        r'^I should\\s+',\n",
        "        r'^The user\\s+',\n",
        "        r'^This is\\s+',\n",
        "        r'^Alright,\\s*',\n",
        "        r'^So,\\s+',\n",
        "    ]\n",
        "    for pattern in monologue_starters:\n",
        "        cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)\n",
        "\n",
        "    # Final cleanup: Remove excessive newlines at start ONLY\n",
        "    cleaned = re.sub(r'^\\s*\\n+', '', cleaned)\n",
        "\n",
        "    return cleaned.strip()"
      ],
      "metadata": {
        "id": "f2IEiQvy6BWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🎤 Step 15: Doc2Pod Studio (Optimized + Debug-Enabled)\n",
        "# @markdown Fully compatible with unified get_context() and handles all edge cases.\n",
        "\n",
        "def get_pdf_selection():\n",
        "    pdf_files = list(PDF_DIR.glob(\"*.pdf\"))\n",
        "    if not pdf_files:\n",
        "        print(f\"\\n❌ No PDFs found in {PDF_DIR}!\")\n",
        "        return None\n",
        "    print(\"\\n[?] Available Documents:\")\n",
        "    for idx, f in enumerate(pdf_files):\n",
        "        print(f\"   {idx + 1}: {f.name}\")\n",
        "    while True:\n",
        "        choice = input(f\"\\nSelect Document (1-{len(pdf_files)}): \")\n",
        "        if choice.isdigit() and 1 <= int(choice) <= len(pdf_files):\n",
        "            return pdf_files[int(choice) - 1]\n",
        "\n",
        "def sanitize_filename(text):\n",
        "    if not text: return \"Untitled\"\n",
        "    safe = re.sub(r'[^a-zA-Z0-9._-]', '_', text.strip())\n",
        "    return safe[:50]\n",
        "\n",
        "# --- MAIN INTERACTIVE LOOP ---\n",
        "print(\"--- Doc2Pod Studio ---\")\n",
        "\n",
        "selected_pdf = get_pdf_selection()\n",
        "if selected_pdf:\n",
        "    pdf_name_raw = selected_pdf.stem\n",
        "    safe_name = re.sub(r'[^a-zA-Z0-9._-]', '_', pdf_name_raw)\n",
        "    coll_name = f\"cs_podcast_{safe_name}\"\n",
        "\n",
        "    # Check for both chunks.json AND embedding_input_texts.json\n",
        "    expected_chunks_json = UNIFIED_DIR / safe_name / f\"{safe_name}_chunks.json\"\n",
        "    expected_embedding_json = EMBEDDING_DIR / safe_name / f\"{safe_name}_embedding_input_texts.json\"\n",
        "\n",
        "    if not expected_chunks_json.exists() or not expected_embedding_json.exists():\n",
        "        print(f\"\\n[Phase 1] Data missing. Running Extraction Pipeline...\")\n",
        "        run_friend_extraction_pipeline(selected_pdf)\n",
        "    else:\n",
        "        print(f\"\\n[Phase 1] Data found. Using existing database.\")\n",
        "\n",
        "    # 🔍 DEBUG: Show chunk structure\n",
        "    chunks_path = UNIFIED_DIR / safe_name / f\"{safe_name}_chunks.json\"\n",
        "    with open(chunks_path, \"r\") as f:\n",
        "        chunks_data = json.load(f)\n",
        "    print(\"\\n🔍 [DEBUG] Chunk Structure:\")\n",
        "    for i, ch in enumerate(chunks_data[\"chunks\"]):\n",
        "        pages = sorted(set(u[\"page\"] for u in ch.get(\"content\", [])))\n",
        "        print(f\"  {i+1}. '{ch['concept']}' (Pages: {pages})\")\n",
        "\n",
        "    rag = Doc2PodRetrieval(DB_DIR, coll_name, use_gpu=True, debug=True)\n",
        "    gen = PodcastScriptGen()\n",
        "    doc_unified_dir = UNIFIED_DIR / safe_name\n",
        "    embedding_dir = EMBEDDING_DIR / safe_name\n",
        "    embedding_path = embedding_dir / f\"{safe_name}_embedding_input_texts.json\"\n",
        "\n",
        "    # Initialize Qwen3 ONCE outside loops\n",
        "    pipeline_manager = LazyPipelineManager()\n",
        "    model, tokenizer = pipeline_manager.get_qwen3_thinking_model()\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n\" + \"=\"*40)\n",
        "        print(\"1. Ask Specific Question\")\n",
        "        print(\"2. Filter by Page Range\")\n",
        "        print(\"3. Auto-Generate Full Podcast (60+ min)\")\n",
        "        print(\"Type 'exit' to quit.\")\n",
        "\n",
        "        mode = input(\"\\nSelect Mode: \").strip()\n",
        "        if mode == 'exit':\n",
        "            # Explicitly unload models\n",
        "            del model, tokenizer\n",
        "            pipeline_manager.unload_all()\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            break\n",
        "\n",
        "        # Mode 3: Full Podcast (with sorting + filtering)\n",
        "        if mode == '3':\n",
        "            print(\"[*] Generating full 60+ minute podcast...\")\n",
        "            with open(embedding_path, \"r\") as f:\n",
        "                embedding_data = json.load(f)\n",
        "            subchunks = embedding_data[\"inputs\"]\n",
        "\n",
        "            # Filter empty + sort by page\n",
        "            original_count = len(subchunks)\n",
        "            subchunks = [\n",
        "                sc for sc in subchunks\n",
        "                if sc[\"text\"].strip() and sc[\"metadata\"][\"units\"]\n",
        "            ]\n",
        "            subchunks.sort(key=lambda x: x[\"metadata\"][\"page\"])\n",
        "            print(f\"🔍 [DEBUG] Subchunks: {original_count} → {len(subchunks)} after filtering\")\n",
        "\n",
        "            # Load concepts from TRUE document order (not retrieval order)\n",
        "            chunks_path = UNIFIED_DIR / safe_name / f\"{safe_name}_chunks.json\"\n",
        "            with open(chunks_path, \"r\") as f:\n",
        "                chunks_data = json.load(f)\n",
        "            concepts = []\n",
        "            seen = set()\n",
        "            for ch in chunks_data[\"chunks\"]:\n",
        "                concept = ch[\"concept\"]\n",
        "                if concept not in seen:\n",
        "                    concepts.append(concept)\n",
        "                    seen.add(concept)\n",
        "\n",
        "            full_script_parts = []\n",
        "            raw_parts = []  # Track raw outputs like in Modes 1 & 2\n",
        "            for idx, sub in enumerate(subchunks):\n",
        "                meta = sub[\"metadata\"]\n",
        "                concept = meta[\"concept\"]\n",
        "                total_subs = meta[\"total_subchunks\"]\n",
        "                sub_idx = idx + 1\n",
        "\n",
        "                next_concept = None\n",
        "                if concept in concepts:\n",
        "                    concept_idx = concepts.index(concept)\n",
        "                    if concept_idx + 1 < len(concepts):\n",
        "                        next_concept = concepts[concept_idx + 1]\n",
        "\n",
        "                print(f\"→ [DEBUG] Generating Part {sub_idx}/{len(subchunks)}: '{concept}'\")\n",
        "                if next_concept:\n",
        "                    print(f\"   → Next: '{next_concept}'\")\n",
        "\n",
        "                final_prompt = gen.build_prompt(\n",
        "                    context=sub[\"text\"],\n",
        "                    user_topic=concept,\n",
        "                    lang_choice=\"3\",\n",
        "                    unified_dir=doc_unified_dir,\n",
        "                    sub_idx=sub_idx,\n",
        "                    total_subs=total_subs,\n",
        "                    next_concept=next_concept\n",
        "                )\n",
        "\n",
        "                messages = [{\"role\": \"user\", \"content\": final_prompt}]\n",
        "                text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "                inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "                outputs = model.generate(**inputs, max_new_tokens=2500)\n",
        "                raw_script = tokenizer.decode(outputs[0][len(inputs.input_ids[0]):], skip_special_tokens=True)\n",
        "\n",
        "                # ✅ EXTRACT CLEAN VERSION (thinking removed, narrative preserved)\n",
        "                clean_script = extract_clean_script(raw_script)\n",
        "\n",
        "                # 🔒 SAFETY CHECK: Prevent over-filtering\n",
        "                if len(clean_script) < 100:\n",
        "                    print(f\"   ⚠️ WARNING: Clean script too short ({len(clean_script)} chars) - falling back to raw\")\n",
        "                    clean_script = re.sub(r'<\\|thinking\\|>.*?<\\|/thinking\\|>', '', raw_script, flags=re.DOTALL).strip()\n",
        "\n",
        "                # CRITICAL: Append BOTH versions\n",
        "                full_script_parts.append(clean_script)\n",
        "                raw_parts.append(raw_script)  # ✅ Track raw output\n",
        "\n",
        "                # Periodic memory cleanup\n",
        "                if idx % 3 == 2:\n",
        "                    torch.cuda.empty_cache()\n",
        "                    gc.collect()\n",
        "\n",
        "            # ✅ SAVE FINAL COMBINED SCRIPTS (FIXED)\n",
        "            full_script = \"\\n\\n\".join(full_script_parts)\n",
        "            raw_full = \"\\n\\n\".join(raw_parts)  # ✅ CORRECT WAY\n",
        "            debug_filename = f\"{safe_name}_FULL_60MIN_PODCAST_DEBUG.txt\"\n",
        "            prod_filename = f\"{safe_name}_FULL_60MIN_PODCAST.txt\"\n",
        "            debug_path = OUTPUT_DIR / debug_filename\n",
        "            prod_path = OUTPUT_DIR / prod_filename\n",
        "\n",
        "            # Save DEBUG version (full raw output)\n",
        "            with open(debug_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(raw_full)  # ✅ Now saves true raw output\n",
        "\n",
        "            # Save PRODUCTION version (cleaned)\n",
        "            with open(prod_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(full_script)\n",
        "\n",
        "            print(f\"   💾 Saved DEBUG to: {debug_path.name}\")\n",
        "            print(f\"   ✅ Saved CLEAN to: {prod_path.name}\")\n",
        "\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(f\"🎉 FULL PODCAST SAVED TO: {prod_path}\")\n",
        "            print(f\"📊 Total Parts: {len(subchunks)} | Estimated Duration: ~{len(subchunks)*6} minutes\")\n",
        "            print(\"=\"*50)\n",
        "            print(full_script)  # ✅ PRINT CLEANED SCRIPT\n",
        "            print(\"=\"*50)\n",
        "            continue\n",
        "\n",
        "        # Mode 2: Page Range (with all 3 updates)\n",
        "        if mode == '2':\n",
        "            try:\n",
        "                p_input = input(\"Enter Range (e.g. 10-20): \")\n",
        "                start, end = map(int, p_input.split('-'))\n",
        "                page_range = (start, end)\n",
        "                topic = input(\"Filter Topic (Optional): \").strip()\n",
        "\n",
        "                file_mode = \"Range\"\n",
        "                file_detail = f\"Pages_{start}-{end}\"\n",
        "                if topic:\n",
        "                    file_detail += f\"_{sanitize_filename(topic)}\"\n",
        "\n",
        "                if topic:\n",
        "                    # Scenario: Query + Range → MULTIPLE subchunks\n",
        "                    query_results = rag.get_context(\n",
        "                        embedding_dir,\n",
        "                        embedding_path,\n",
        "                        query=topic,\n",
        "                        page_range=page_range,\n",
        "                        k=10\n",
        "                    )\n",
        "                    print(f\"Retrieved {len(query_results)} chunks\" if query_results else \"❌ Still failing - check debug output\")\n",
        "                    if not query_results or (isinstance(query_results, list) and not query_results):\n",
        "                        print(\"⚠️ No relevant content found.\")\n",
        "                        continue\n",
        "\n",
        "                    # Handle result format\n",
        "                    if isinstance(query_results, tuple):\n",
        "                        context, concept, sub_idx, total_subs, next_concept = query_results\n",
        "                        script_parts = [context]\n",
        "                        concepts_list = [concept]\n",
        "                        total_subs_list = [total_subs]\n",
        "                        next_concepts_list = [next_concept]\n",
        "                    else:\n",
        "                        script_parts = [r[\"text\"] for r in query_results]\n",
        "                        concepts_list = [r[\"concept\"] for r in query_results]\n",
        "                        total_subs_list = [r[\"total_subs\"] for r in query_results]\n",
        "                        next_concepts_list = [r[\"next_concept\"] for r in query_results]\n",
        "\n",
        "                    full_script_parts = []\n",
        "                    raw_parts = []  # Track raw outputs for debug file\n",
        "                    for idx, (context, concept, total_subs, next_concept) in enumerate(\n",
        "                        zip(script_parts, concepts_list, total_subs_list, next_concepts_list)\n",
        "                    ):\n",
        "                        sub_idx = idx + 1\n",
        "                        print(f\"→ [DEBUG] Retrieved Part {sub_idx}: '{concept}' (Pages: {start}-{end})\")\n",
        "                        if next_concept:\n",
        "                            print(f\"   → Next: '{next_concept}'\")\n",
        "\n",
        "                        final_prompt = gen.build_prompt(\n",
        "                            context=context,\n",
        "                            user_topic=concept,\n",
        "                            lang_choice=\"3\",\n",
        "                            unified_dir=doc_unified_dir,\n",
        "                            sub_idx=sub_idx,\n",
        "                            total_subs=total_subs,\n",
        "                            next_concept=next_concept\n",
        "                        )\n",
        "\n",
        "                        messages = [{\"role\": \"user\", \"content\": final_prompt}]\n",
        "                        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "                        inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "                        outputs = model.generate(**inputs, max_new_tokens=2500)\n",
        "                        raw_script = tokenizer.decode(outputs[0][len(inputs.input_ids[0]):], skip_special_tokens=True)\n",
        "\n",
        "                        # ✅ EXTRACT CLEAN VERSION\n",
        "                        clean_script = extract_clean_script(raw_script)\n",
        "\n",
        "                        # 🔒 SAFETY CHECK\n",
        "                        if len(clean_script) < 100:\n",
        "                            print(f\"   ⚠️ WARNING: Clean script too short ({len(clean_script)} chars) - falling back to raw\")\n",
        "                            clean_script = re.sub(r'<\\|thinking\\|>.*?<\\|/thinking\\|>', '', raw_script, flags=re.DOTALL).strip()\n",
        "\n",
        "                        # Track both versions\n",
        "                        full_script_parts.append(clean_script)\n",
        "                        raw_parts.append(raw_script)\n",
        "\n",
        "                    # ✅ SAVE FINAL COMBINED SCRIPTS\n",
        "                    full_script = \"\\n\\n\".join(full_script_parts)\n",
        "                    raw_full = \"\\n\\n\".join(raw_parts)\n",
        "                    debug_filename = f\"{safe_name}_{file_mode}_{file_detail}_DEBUG.txt\"\n",
        "                    prod_filename = f\"{safe_name}_{file_mode}_{file_detail}.txt\"\n",
        "                    debug_path = OUTPUT_DIR / debug_filename\n",
        "                    prod_path = OUTPUT_DIR / prod_filename\n",
        "\n",
        "                    with open(debug_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(raw_full)\n",
        "                    with open(prod_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(full_script)\n",
        "\n",
        "                    print(f\"   💾 Saved DEBUG to: {debug_path.name}\")\n",
        "                    print(f\"   ✅ Saved CLEAN to: {prod_path.name}\")\n",
        "\n",
        "                    print(\"\\n\" + \"=\"*50)\n",
        "                    print(f\"✅ SCRIPT SAVED TO: {prod_path}\")\n",
        "                    print(\"=\"*50)\n",
        "                    print(full_script)  # ✅ PRINT CLEANED SCRIPT\n",
        "                    print(\"=\"*50)\n",
        "\n",
        "                else:\n",
        "                    # Scenario: Range Only → full podcast with continuity\n",
        "                    with open(embedding_path, \"r\") as f:\n",
        "                        embedding_data = json.load(f)\n",
        "                    all_subchunks = embedding_data[\"inputs\"]\n",
        "\n",
        "                    original_count = len(all_subchunks)\n",
        "                    filtered_subchunks = [\n",
        "                        sc for sc in all_subchunks\n",
        "                        if start <= sc[\"metadata\"][\"page\"] <= end\n",
        "                        and sc[\"text\"].strip()\n",
        "                        and sc[\"metadata\"][\"units\"]\n",
        "                    ]\n",
        "                    filtered_subchunks.sort(key=lambda x: x[\"metadata\"][\"page\"])\n",
        "                    print(f\"→ [DEBUG] Range {start}-{end}: {original_count} → {len(filtered_subchunks)} subchunks\")\n",
        "\n",
        "                    if not filtered_subchunks:\n",
        "                        print(\"⚠️ No valid subchunks found in page range.\")\n",
        "                        continue\n",
        "\n",
        "                    # Load concepts from TRUE document order\n",
        "                    chunks_path = UNIFIED_DIR / safe_name / f\"{safe_name}_chunks.json\"\n",
        "                    with open(chunks_path, \"r\") as f:\n",
        "                        chunks_data = json.load(f)\n",
        "                    concepts = []\n",
        "                    seen = set()\n",
        "                    for ch in chunks_data[\"chunks\"]:\n",
        "                        concept = ch[\"concept\"]\n",
        "                        if concept not in seen:\n",
        "                            concepts.append(concept)\n",
        "                            seen.add(concept)\n",
        "\n",
        "                    full_script_parts = []\n",
        "                    raw_parts = []  # Track raw outputs for debug file\n",
        "                    for idx, sub in enumerate(filtered_subchunks):\n",
        "                        meta = sub[\"metadata\"]\n",
        "                        concept = meta[\"concept\"]\n",
        "                        total_subs = meta[\"total_subchunks\"]\n",
        "                        sub_idx = idx + 1\n",
        "\n",
        "                        next_concept = None\n",
        "                        if concept in concepts:\n",
        "                            concept_idx = concepts.index(concept)\n",
        "                            if concept_idx + 1 < len(concepts):\n",
        "                                next_concept = concepts[concept_idx + 1]\n",
        "\n",
        "                        print(f\"→ [DEBUG] Generating Part {sub_idx}/{len(filtered_subchunks)}: '{concept}'\")\n",
        "                        if next_concept:\n",
        "                            print(f\"   → Next: '{next_concept}'\")\n",
        "\n",
        "                        final_prompt = gen.build_prompt(\n",
        "                            context=sub[\"text\"],\n",
        "                            user_topic=concept,\n",
        "                            lang_choice=\"3\",\n",
        "                            unified_dir=doc_unified_dir,\n",
        "                            sub_idx=sub_idx,\n",
        "                            total_subs=total_subs,\n",
        "                            next_concept=next_concept\n",
        "                        )\n",
        "\n",
        "                        messages = [{\"role\": \"user\", \"content\": final_prompt}]\n",
        "                        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "                        inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "                        outputs = model.generate(**inputs, max_new_tokens=2500)\n",
        "                        raw_script = tokenizer.decode(outputs[0][len(inputs.input_ids[0]):], skip_special_tokens=True)\n",
        "\n",
        "                        # ✅ EXTRACT CLEAN VERSION (thinking removed, narrative preserved)\n",
        "                        clean_script = extract_clean_script(raw_script)\n",
        "\n",
        "                        # 🔒 SAFETY CHECK: Prevent over-filtering\n",
        "                        if len(clean_script) < 100:\n",
        "                            print(f\"   ⚠️ WARNING: Clean script too short ({len(clean_script)} chars) - falling back to raw\")\n",
        "                            clean_script = re.sub(r'<\\|thinking\\|>.*?<\\|/thinking\\|>', '', raw_script, flags=re.DOTALL).strip()\n",
        "\n",
        "                        # Track both versions\n",
        "                        full_script_parts.append(clean_script)\n",
        "                        raw_parts.append(raw_script)\n",
        "\n",
        "                        if idx % 3 == 2:\n",
        "                            torch.cuda.empty_cache()\n",
        "                            gc.collect()\n",
        "\n",
        "                    # ✅ SAVE FINAL COMBINED SCRIPTS\n",
        "                    full_script = \"\\n\\n\".join(full_script_parts)\n",
        "                    raw_full = \"\\n\\n\".join(raw_parts)\n",
        "                    debug_filename = f\"{safe_name}_{file_mode}_{file_detail}_DEBUG.txt\"\n",
        "                    prod_filename = f\"{safe_name}_{file_mode}_{file_detail}.txt\"\n",
        "                    debug_path = OUTPUT_DIR / debug_filename\n",
        "                    prod_path = OUTPUT_DIR / prod_filename\n",
        "\n",
        "                    with open(debug_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(raw_full)\n",
        "                    with open(prod_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(full_script)\n",
        "\n",
        "                    print(f\"   💾 Saved DEBUG to: {debug_path.name}\")\n",
        "                    print(f\"   ✅ Saved CLEAN to: {prod_path.name}\")\n",
        "\n",
        "                    print(\"\\n\" + \"=\"*50)\n",
        "                    print(f\"✅ RANGE PODCAST SAVED TO: {prod_path}\")\n",
        "                    print(f\"📊 Total Parts: {len(full_script_parts)} | Estimated Duration: ~{len(full_script_parts)*6} minutes\")\n",
        "                    print(\"=\"*50)\n",
        "                    print(full_script)  # ✅ PRINT CLEANED SCRIPT\n",
        "                    print(\"=\"*50)\n",
        "\n",
        "                continue\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Invalid format: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Mode 1: Single Query (UPDATED)\n",
        "        elif mode == '1':\n",
        "            topic = input(\"Enter Topic: \").strip()\n",
        "            if not topic: continue\n",
        "            file_mode = \"QnA\"\n",
        "            file_detail = sanitize_filename(topic)\n",
        "\n",
        "            query_results = rag.get_context(\n",
        "                embedding_dir,\n",
        "                embedding_path,\n",
        "                query=topic\n",
        "            )\n",
        "\n",
        "            if not query_results or (isinstance(query_results, list) and not query_results):\n",
        "                print(\"⚠️ No relevant data found.\")\n",
        "                continue\n",
        "\n",
        "            # Handle single result (old format) vs list (new format)\n",
        "            if isinstance(query_results, tuple):\n",
        "                # Old format (Range Only path)\n",
        "                context, concept, sub_idx, total_subs, next_concept = query_results\n",
        "                script_parts = [context]\n",
        "                concepts_list = [concept]\n",
        "                total_subs_list = [total_subs]\n",
        "                next_concepts_list = [next_concept]\n",
        "            else:\n",
        "                # New format: list of results\n",
        "                script_parts = [r[\"text\"] for r in query_results]\n",
        "                concepts_list = [r[\"concept\"] for r in query_results]\n",
        "                total_subs_list = [r[\"total_subs\"] for r in query_results]\n",
        "                next_concepts_list = [r[\"next_concept\"] for r in query_results]\n",
        "\n",
        "            lang = input(\"Language (1:EN, 2:MSA, 3:EGY): \")\n",
        "            full_script_parts = []\n",
        "            raw_parts = []  # Track raw outputs for debug file\n",
        "\n",
        "            # Load concepts from TRUE document order for continuity\n",
        "            chunks_path = UNIFIED_DIR / safe_name / f\"{safe_name}_chunks.json\"\n",
        "            with open(chunks_path, \"r\") as f:\n",
        "                chunks_data = json.load(f)\n",
        "            global_concepts = []\n",
        "            seen = set()\n",
        "            for ch in chunks_data[\"chunks\"]:\n",
        "                concept = ch[\"concept\"]\n",
        "                if concept not in seen:\n",
        "                    global_concepts.append(concept)\n",
        "                    seen.add(concept)\n",
        "\n",
        "            for idx, (context, concept, total_subs, next_concept) in enumerate(\n",
        "                zip(script_parts, concepts_list, total_subs_list, next_concepts_list)\n",
        "            ):\n",
        "                sub_idx = idx + 1\n",
        "\n",
        "                # Override next_concept using TRUE document order\n",
        "                actual_next_concept = None\n",
        "                if concept in global_concepts:\n",
        "                    concept_idx = global_concepts.index(concept)\n",
        "                    if concept_idx + 1 < len(global_concepts):\n",
        "                        actual_next_concept = global_concepts[concept_idx + 1]\n",
        "\n",
        "                print(f\"→ [DEBUG] Retrieved Part {sub_idx}: '{concept}'\")\n",
        "                if actual_next_concept:\n",
        "                    print(f\"   → Next: '{actual_next_concept}'\")\n",
        "\n",
        "                final_prompt = gen.build_prompt(\n",
        "                    context=context,\n",
        "                    user_topic=concept,\n",
        "                    lang_choice=lang,\n",
        "                    unified_dir=doc_unified_dir,\n",
        "                    sub_idx=sub_idx,\n",
        "                    total_subs=total_subs,\n",
        "                    next_concept=actual_next_concept\n",
        "                )\n",
        "\n",
        "                messages = [{\"role\": \"user\", \"content\": final_prompt}]\n",
        "                text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "                inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "                outputs = model.generate(**inputs, max_new_tokens=2500)\n",
        "                raw_script = tokenizer.decode(outputs[0][len(inputs.input_ids[0]):], skip_special_tokens=True)\n",
        "\n",
        "                # ✅ EXTRACT CLEAN VERSION\n",
        "                clean_script = extract_clean_script(raw_script)\n",
        "\n",
        "                # 🔒 SAFETY CHECK\n",
        "                if len(clean_script) < 100:\n",
        "                    print(f\"   ⚠️ WARNING: Clean script too short ({len(clean_script)} chars) - falling back to raw\")\n",
        "                    clean_script = re.sub(r'<\\|thinking\\|>.*?<\\|/thinking\\|>', '', raw_script, flags=re.DOTALL).strip()\n",
        "\n",
        "                # Track both versions\n",
        "                full_script_parts.append(clean_script)\n",
        "                raw_parts.append(raw_script)\n",
        "\n",
        "                if idx % 3 == 2:\n",
        "                    torch.cuda.empty_cache()\n",
        "                    gc.collect()\n",
        "\n",
        "            # ✅ SAVE FINAL COMBINED SCRIPTS\n",
        "            full_script = \"\\n\\n\".join(full_script_parts)\n",
        "            raw_full = \"\\n\\n\".join(raw_parts)\n",
        "            debug_filename = f\"{safe_name}_{file_mode}_{file_detail}_DEBUG.txt\"\n",
        "            prod_filename = f\"{safe_name}_{file_mode}_{file_detail}.txt\"\n",
        "            debug_path = OUTPUT_DIR / debug_filename\n",
        "            prod_path = OUTPUT_DIR / prod_filename\n",
        "\n",
        "            with open(debug_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(raw_full)\n",
        "            with open(prod_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(full_script)\n",
        "\n",
        "            print(f\"   💾 Saved DEBUG to: {debug_path.name}\")\n",
        "            print(f\"   ✅ Saved CLEAN to: {prod_path.name}\")\n",
        "\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(f\"✅ SCRIPT SAVED TO: {prod_path}\")\n",
        "            print(\"=\"*50)\n",
        "            print(full_script)  # ✅ PRINT CLEANED SCRIPT\n",
        "            print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5f637298f2c546b6a1dd21837a034101",
            "e6022724b999476599b298335232ae97",
            "c934af9f331647a998505362455c5258",
            "fa3be298f2af4270bc623db1284b9ef5",
            "135cedf96b694abeb470235f86e490b6",
            "a270d107d8d5446cb1bad5409686a8a4",
            "1e476d2d34a145539022089c35b6b98c",
            "0d96c1ede45846369157fb9d787eb434",
            "8a5aefb723d34be6a7644b66439bb04d",
            "6e7db62220e245b0b31b3b18801ec451",
            "58f10a2b3f5d49a68ef3fe744d58e44a",
            "3e96aec7d4404ccf88e4853305660278",
            "24aeb80fde0d47f2bf212628986c003a",
            "3aee4aa157544dd9ae031d59358d33f9",
            "397bfd88c19b4c1695ee52f872b82285",
            "d07983c0685842149754ac0e19dee79a",
            "9b06a40d23a441a4b3af4431830d0d4e",
            "fa8c99c554be430081fb61014b9e6397",
            "d84a8c7b73b84bfe9fbc5e22ac5cf660",
            "e3f949dbc1804f31adb96866d9efe71b",
            "9fc176a5e42d46ac92579f38367b811a",
            "50f049228a95402ebb552af7bf5a08ad",
            "82a541e637194841add605fb68f806d9",
            "96df8f986fb94aa3b4fca927557bef4f",
            "d5c8118c2fce4e2d8e7000c240634680",
            "3fcdd149afe0442ca1567dfbcc6e1d2e",
            "0425d60545c54a63a8a94ce47e82f1bc",
            "c30c38f6417445bbb65892f8cb5dab9b",
            "199cfeda6b17440ca7c5bb20f75252d7",
            "ccd671a41ccf41ccb11990713d0dddb7",
            "37ed7a6ec3064500a516ed55ece600e5",
            "64de2fd1cf364e8daf1c834ea7038464",
            "bee58a943c8746698d6d774cbd1adbd0",
            "744f333f39ac4706bbb373c40ca0b154",
            "4be3471a6d2b4f7ab2ddbaa2a11fc83f",
            "ca19229eba914c5089e53fe167a46bfb",
            "8e0cf06771ab48a385c723b2e2a33c9c",
            "7db7318e026741d2a1a276dee188eb8d",
            "94f1b43c035b45e1b10b509195627bde",
            "7d3a661a7b794cedbe40cadd79727eb2",
            "95e4b70126f144388ff9dfad56b20909",
            "67bf802e46404b0c99c508b2cd4b6176",
            "6c860b51ae81479784867899e317fd96",
            "71ae794d053845689156add111564b68",
            "9287d35cde5f41bd8d4fdd9221e82f72",
            "53bd0236e74e4ed5b8fe217066862ba6",
            "8b27ad740d8146deb191979bd8f97422",
            "6ea2328e88f24706833259fc7b75b1d2",
            "8d657f800bad4bcc997e120689f3fc35",
            "c36c0be09ab941c79ed30a3e8d59e2e4",
            "6176399058734064a0f0637c65f720b2",
            "a094891fd86a40f6b87a24279ad55542",
            "5629b52fa11940afaeb57b7f635d9905",
            "426e584062f24f6aaa36dda30cc2a038",
            "f8a35a7e81dc49c78f0bbc5bb3ba3f21",
            "977920af30c64cd188395b133902c564",
            "4610273977654a6a9d2ccc739fb0841a",
            "0730cd35e28d48c197ce9ac36293ede6",
            "597e645814044bc3a55a8d0b6c36e217",
            "0551b91958464167a40c7eef93a79bcb",
            "9246b773b0da4e6db2e34489533fa46f",
            "90f70438b29e40f2974d9f815bf413ea",
            "6767349e15ec4ddaac2f01b1060dad9a",
            "ea584677ad0040cf8cf9ab646bb08184",
            "068ef808c4394d348d1b396e993ebc19",
            "ecf105622d5a4debbd651c69e0f9a253",
            "ca09977144434588a514f9cd98b0315a",
            "bebc006a8c454c0eb84840cca7b77ae1",
            "c83075028304419ebc6547c88a3c7bd6",
            "da41467e96cd45fe8ef84b2a69b6eceb",
            "92b23b90269e4f91b32cfe0477dcf6f3",
            "0b2eb4c521d44241b3d0fb450840e2f4",
            "bb80f27563b042188e445b583547d714",
            "1913d73aeb8f4def826f9ac2d1c054fb",
            "3e753fdc0a4d4fc190228152ee7531ad",
            "cf3e8bce6a8345e1af50d24a6abf5574",
            "eb53449ddcdc4ecfa3b19b774e697ab7",
            "2b1b15b865d64b80a0d1677460334ff3",
            "9cadc9429702403b93b93e3e361c2789",
            "671346f0ae3944cea257c8e1b0cffec8",
            "4e9553c85a3d4b19aee82690a61cf5c5",
            "cde9acebc9ef4ad4be26a5b9df2b26d7",
            "c5e61f5c628348bbb5664c21c89e6e1d",
            "a48ecea303db4d73964cfb08b551574e",
            "1887790148d7439796fd8201eb3c9aa4",
            "7701445692264caf89649c979d9938d1",
            "888f72e1199f4c6aa0666def8579b882",
            "55a409c301a141d8bee655fbc05c6c6e"
          ]
        },
        "id": "STiV65sgJPc1",
        "outputId": "4e6f795f-256b-4487-a10c-b3ebc529db96"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Doc2Pod Studio ---\n",
            "\n",
            "[?] Available Documents:\n",
            "   1: [IoT_25] Lecture 1.pdf\n",
            "   2: [ML&PR 2024] Lec5 Classification II.pdf\n",
            "\n",
            "Select Document (1-2): 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mCreating model: ('PP-DocLayoutV2', None)\u001b[0m\n",
            "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/root/.paddlex/official_models/PP-DocLayoutV2`.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Phase 1] Data missing. Running Extraction Pipeline...\n",
            "🚀 Starting Extraction Pipeline for: [IoT_25] Lecture 1.pdf\n",
            "[*] Loading PaddleOCR on gpu...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mCreating model: ('PaddleOCR-VL-0.9B', None)\u001b[0m\n",
            "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/root/.paddlex/official_models/PaddleOCR-VL`.\u001b[0m\n",
            "\u001b[32mLoading configuration file /root/.paddlex/official_models/PaddleOCR-VL/config.json\u001b[0m\n",
            "\u001b[32mLoading weights file /root/.paddlex/official_models/PaddleOCR-VL/model.safetensors\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "\u001b[32muse GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/paddle/utils/decorator_utils.py:420: Warning: \n",
            "Non compatible API. Please refer to https://www.paddlepaddle.org.cn/documentation/docs/en/develop/guides/model_convert/convert_from_pytorch/api_difference/torch/torch.split.html first.\n",
            "  warnings.warn(\n",
            "\u001b[32mLoaded weights file from disk, setting weights to model.\u001b[0m\n",
            "\u001b[32mAll model checkpoint weights were used when initializing PaddleOCRVLForConditionalGeneration.\n",
            "\u001b[0m\n",
            "\u001b[32mAll the weights of PaddleOCRVLForConditionalGeneration were initialized from the model checkpoint at /root/.paddlex/official_models/PaddleOCR-VL.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use PaddleOCRVLForConditionalGeneration for predictions without further training.\u001b[0m\n",
            "\u001b[32mLoading configuration file /root/.paddlex/official_models/PaddleOCR-VL/generation_config.json\u001b[0m\n",
            "\u001b[33mCurrently, the PaddleOCR-VL-0.9B local model only supports batch size of 1. The batch size will be updated to 1.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] Starting OCR for [IoT_25] Lecture 1 (52 pages)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "OCR Processing:   0%|          | 0/52 [00:00<?, ?page/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f637298f2c546b6a1dd21837a034101"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/paddle/tensor/creation.py:1088: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach(), rather than paddle.to_tensor(sourceTensor).\n",
            "  return tensor(\n",
            "/usr/local/lib/python3.12/dist-packages/paddle/utils/decorator_utils.py:420: Warning: \n",
            "Non compatible API. Please refer to https://www.paddlepaddle.org.cn/documentation/docs/en/develop/guides/model_convert/convert_from_pytorch/api_difference/torch/torch.max.html first.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ OCR Complete. Data saved to: /content/drive/MyDrive/Doc2Pod_System/Data/json/[IoT_25] Lecture 1/[IoT_25] Lecture 1.json\n",
            "✅ OCR Complete.\n",
            "[*] Loading Qwen3-VL (Vision Model)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e96aec7d4404ccf88e4853305660278"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82a541e637194841add605fb68f806d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/713 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "744f333f39ac4706bbb373c40ca0b154"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] Unloading all models from GPU...\n",
            "[*] GPU memory cleared.\n",
            "✅ Created 241 raw units.\n",
            "[*] Loading Embedding Model...\n",
            "[*] Loading Embedding Model on cuda...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9287d35cde5f41bd8d4fdd9221e82f72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏭️ Skipping entire page 2 (admin title): 'Practical IoT Hacking\n",
            "The Definitive Guide to Attacking the\n",
            "Internet of Things\n",
            "\n",
            "Foreword by\n",
            "DAVE KENNEDY\n",
            "\n",
            "Fotios Chantzis and Ioannis Stais\n",
            "Paulina Calderon, Evangelos Deimantzoglou, and Beau Woods\n",
            "\n",
            "no starch press'\n",
            "⏭️ Skipping entire page 9 (admin title): 'The image contains the following readable textual and semantic information:\n",
            "\n",
            "- The prominent text \"IOT\" is displayed at the top center, which stands for Internet of Things.\n",
            "\n",
            "- The image is a conceptual illustration depicting the interconnected ecosystem of IoT, with various icons and symbols representing devices and functions linked together.\n",
            "\n",
            "- Key elements include:\n",
            "  - A hand holding a smartphone, indicating user interaction or control.\n",
            "  - A cloud icon, symbolizing cloud computing or data storage.\n",
            "  - A bar chart, representing data analytics or monitoring.\n",
            "  - A camera, suggesting video or image capture.\n",
            "  - A smart thermostat or similar device, indicating home automation.\n",
            "  - A traffic light, representing smart infrastructure or urban management.\n",
            "  - A coffee cup, possibly symbolizing daily life or user convenience.\n",
            "  - A clipboard with checkmarks, indicating task management or system status.\n",
            "  - A user profile icon, representing personalization or user data.\n",
            "  - A Wi-Fi symbol, indicating wireless connectivity.\n",
            "  - A monitor displaying graphs, suggesting data visualization or dashboard interfaces.\n",
            "  - A small robot or drone icon, symbolizing automation or robotics.\n",
            "  - A network connection line linking the smartphone to the cloud and other devices.\n",
            "\n",
            "- The overall semantic meaning is to illustrate how diverse physical devices (smart home, industrial, urban, personal) are connected via the Internet, enabling data collection, remote control, and automation. The smartphone acts as a central interface for users to interact with the IoT network.\n",
            "\n",
            "- The image does not contain any charts, tables, equations, or numerical data.\n",
            "\n",
            "In summary, the image visually communicates the concept of IoT as a network of interconnected devices that collect, transmit, and act upon data, often through a user interface such as a smartphone, and supported by cloud computing and analytics.'\n",
            "⏭️ Skipping entire page 11 (admin title): 'The image presents a circular diagram centered on the text \"The INTERNET of THINGS\", with six segments radiating outward, each describing a core principle of the Internet of Things (IoT). The text and icons within each segment are as follows:\n",
            "\n",
            "1. **Top segment (blue)**:  \n",
            "   - Text: \"Anything Any Device\"  \n",
            "   - Icon: A computer monitor and a smartphone.\n",
            "\n",
            "2. **Upper-right segment (teal)**:  \n",
            "   - Text: \"Anyone Anybody\"  \n",
            "   - Icon: A group of stylized human figures.\n",
            "\n",
            "3. **Lower-right segment (teal)**:  \n",
            "   - Text: \"Any Service Any Business\"  \n",
            "   - Icon: A stylized building representing a business or organization.\n",
            "\n",
            "4. **Bottom segment (blue)**:  \n",
            "   - Text: \"Any Path Any Network\"  \n",
            "   - Icon: Two computer monitors connected by dotted lines, symbolizing network connectivity.\n",
            "\n",
            "5. **Lower-left segment (orange)**:  \n",
            "   - Text: \"Any Place Anywhere\"  \n",
            "   - Icon: A location pin on a map.\n",
            "\n",
            "6. **Upper-left segment (orange)**:  \n",
            "   - Text: \"Anytime Any Context\"  \n",
            "   - Icon: A circular arrow, suggesting continuous or dynamic context.\n",
            "\n",
            "The diagram visually represents the IoT as a system that enables connectivity and interaction across diverse entities — devices, people, services, and locations — regardless of time, place, or network path. The central title \"The INTERNET of THINGS\" emphasizes the overarching concept, while the six surrounding segments illustrate its key characteristics: universality in device type, user accessibility, service applicability, network flexibility, geographic reach, and temporal adaptability.\n",
            "\n",
            "[NO TABLES, EQUATIONS, OR CHARTS TO EXTRACT]'\n",
            "⏭️ Skipping entire page 46 (admin title): 'The image presents a diagram labeled \"IoT Level-3,\" which illustrates the architecture and communication flow between local and cloud components in an Internet of Things (IoT) system.\n",
            "\n",
            "Key textual elements and their semantic interpretation:\n",
            "\n",
            "1. **Title**: \"IoT Level-3\" — This indicates the diagram represents a specific tier or layer in an IoT architecture, likely the application or service layer, as opposed to device or network layers.\n",
            "\n",
            "2. **Vertical Divider**: A dashed vertical line separates the diagram into two main sections: \"Local\" on the left and \"Cloud\" on the right.\n",
            "\n",
            "3. **Local Side Components**:\n",
            "   - **Device** (pink rectangle): The lowest layer, representing an IoT sensor or actuator.\n",
            "   - **Resource** (light blue rectangle): A layer above the device, possibly representing data or a service that the device interacts with.\n",
            "   - **Controller Service** (orange rectangle): A higher-level service that manages resources and devices. It communicates bidirectionally with the Resource layer.\n",
            "\n",
            "4. **Cloud Side Components**:\n",
            "   - **Database** (cylinder icon): Represents data storage in the cloud.\n",
            "   - **App** (pink rectangle): A cloud-based application that interacts with users or other systems.\n",
            "   - **Cloud Storage & Analysis** (blue cloud icon): Indicates that data is stored and analyzed in the cloud.\n",
            "\n",
            "5. **Communication Protocols**:\n",
            "   - **REST/WebSocket Communication**: This label appears multiple times, indicating the communication protocol used between components.\n",
            "     - Between \"Controller Service\" and \"Resource\" (Local side).\n",
            "     - Between \"Controller Service\" and \"App\" (crossing the cloud boundary).\n",
            "     - Between \"App\" and \"Database\" (Cloud side).\n",
            "     - Between \"App\" and \"Cloud Storage & Analysis\" (Cloud side).\n",
            "\n",
            "6. **Monitoring Node** (orange circle): Located at the bottom left, it sends data to the cloud (indicated by an arrow pointing to the cloud icon labeled \"Cloud Storage & Analysis\").\n",
            "\n",
            "7. **Semantic Interpretation**:\n",
            "   - The diagram shows a hierarchical structure where a local device interacts with a resource, which is managed by a controller service.\n",
            "   - The controller service communicates with a cloud-based application (App) and a database, using REST/WebSocket protocols.\n",
            "   - The App can interact with the database for data storage and retrieval, and also with cloud storage and analysis services.\n",
            "   - A monitoring node (possibly a sensor or gateway) sends data to the cloud for storage and analysis'\n",
            "⏭️ Skipping entire page 49 (admin title): 'The image presents a system architecture diagram labeled \"IoT Level-5,\" illustrating the interaction between local and cloud components in an Internet of Things (IoT) system.\n",
            "\n",
            "The diagram is divided into two main vertical sections: \"Local\" on the left and \"Cloud\" on the right, separated by a dashed line. Communication between these sections is facilitated by \"REST/WebSocket Communication.\"\n",
            "\n",
            "---\n",
            "\n",
            "**Local Section:**\n",
            "\n",
            "- **Observer Node**: Positioned at the top left, it receives data from the cloud (via REST/WebSocket Communication) and sends it to the \"App\" in the cloud.\n",
            "- **Controller Services**: Three instances are shown, each managing a \"Resource.\" The resources are associated with different devices:\n",
            "  - Two \"Endpoint Devices\" (pink boxes) are connected to Controller Services, each managing one Resource.\n",
            "  - One \"Coordinator Device\" (brown box) is connected to a Controller Service, managing one Resource.\n",
            "- **Routers/End Points**: Represented by orange circles, these connect to a central \"Coordinator\" (purple circle). The Coordinator then connects to \"Cloud Storage & Analysis\" (blue cloud).\n",
            "- **Resource**: A blue box representing a managed resource, typically associated with a device.\n",
            "- **Endpoint Device**: A pink box indicating a device that can be managed by a Controller Service.\n",
            "- **Coordinator Device**: A brown box indicating a device that coordinates communication among other devices.\n",
            "\n",
            "---\n",
            "\n",
            "**Cloud Section:**\n",
            "\n",
            "- **App**: A pink box representing a user-facing application. It communicates with the \"REST/WebSocket Services\" and interacts with the \"Observer Node\" and \"Analytics Component (IoT Intelligence).\"\n",
            "- **REST/WebSocket Services**: A green box that acts as an intermediary between the local Controller Services and the cloud components. It receives data from the local Controller Services and forwards it to the \"Database\" and \"Analytics Component.\"\n",
            "- **Database**: A gray cylinder representing data storage. It receives data from the \"REST/WebSocket Services\" and sends data to the \"Analytics Component.\"\n",
            "- **Analytics Component (IoT Intelligence)**: A green box that processes data from the \"REST/WebSocket Services\" and the \"Database.\" It also communicates with the \"Observer Node\" and the \"App.\"\n",
            "- **Cloud Storage & Analysis**: A blue cloud symbolizing storage and analytical capabilities, receiving data from the \"Coordinator\" in the local network.\n",
            "\n",
            "---\n",
            "\n",
            "**Communication Flow:**\n",
            "\n",
            "- The \"Observer Node\" in the local section communicates with the \"App\" in the cloud.\n",
            "- The \"Controller Services\"'\n",
            "✅ [STRATEGY 2] Title detected on Page 1: 'Internet of Things: An Introduction' (IoT-style (with content))\n",
            "✅ [STRATEGY 1] Title detected on Page 4: 'What is\n",
            "IoT?'\n",
            "✅ [STRATEGY 1] Title detected on Page 5: 'What is IoT?'\n",
            "✅ [STRATEGY 2] Title detected on Page 7: 'Internet of Things (IoT)' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 8: 'Internet of Things (IoT)' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 10: 'Internet of Things (IoT)' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 12: 'Evolution of IoT' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 13: 'Evolution of IoT' (IoT-style (with content))\n",
            "✅ [STRATEGY 1] Title detected on Page 16: 'Comparison between Traditional Network and IoT'\n",
            "✅ [STRATEGY 1] Title detected on Page 17: 'Comparison between Traditional Network and IoT'\n",
            "✅ [STRATEGY 1] Title detected on Page 18: 'Comparison between Traditional Network and IoT'\n",
            "✅ [STRATEGY 1] Title detected on Page 19: 'Comparison between Traditional Network and IoT'\n",
            "✅ [STRATEGY 1] Title detected on Page 20: 'Comparison between Traditional Network and IoT'\n",
            "✅ [STRATEGY 1] Title detected on Page 21: 'Comparison between Traditional Network and IoT'\n",
            "✅ [STRATEGY 2] Title detected on Page 22: 'The IoT Equation' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 23: 'Concepts Close to IoT' (IoT-style (with content))\n",
            "✅ [STRATEGY 1] Title detected on Page 25: 'IoT Application Domains'\n",
            "✅ [STRATEGY 2] Title detected on Page 26: 'Digital Twins' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 27: 'Domain of IoT Usage & Applications' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 28: 'Domain of IoT Usage & Applications' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 29: 'Domain of IoT Usage & Applications' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 30: 'Domain of IoT Usage & Applications' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 31: 'Domain of IoT Usage & Applications' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 32: 'Domain of IoT Usage & Applications' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 33: 'Domain of IoT Usage & Applications' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 34: 'Domain of IoT Usage & Applications' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 35: 'IoT Components' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 36: 'IoT Components' (IoT-style (with content))\n",
            "✅ [STRATEGY 1] Title detected on Page 37: 'IoT Communication Protocols'\n",
            "✅ [STRATEGY 2] Title detected on Page 39: 'IoT Enabling Technologies' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 40: 'Ambient intelligence' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 41: 'IoT 4s's Rule' (IoT-style (with content))\n",
            "✅ [STRATEGY 1] Title detected on Page 42: 'IoT Challenges'\n",
            "✅ [STRATEGY 1] Title detected on Page 43: 'IoT Levels & Deployment Templates'\n",
            "✅ [STRATEGY 2] Title detected on Page 45: 'IoT Level-2\n",
            "Device and Local Analysis' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 47: 'IoT Level-4\n",
            "Multiple Analyzing\n",
            "Nodes' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 48: 'IoT Level-5 Coordinator Node' (IoT-style (with content))\n",
            "✅ [STRATEGY 2] Title detected on Page 50: 'IoT Level-6' (IoT-style (with content))\n",
            "🎯 Using all Strategy 1 pages as top-level sections.\n",
            "🎯 Final title pages used: [4, 5, 16, 17, 18, 19, 20, 21, 25, 37, 42, 43]\n",
            "📌 Starting new chunk: 'What is\n",
            "IoT?' (Page 4)\n",
            "📌 Starting new chunk: 'What is IoT?' (Page 5)\n",
            "📌 Starting new chunk: 'Comparison between Traditional Network and IoT' (Page 16)\n",
            "📌 Starting new chunk: 'Comparison between Traditional Network and IoT' (Page 17)\n",
            "📌 Starting new chunk: 'Comparison between Traditional Network and IoT' (Page 18)\n",
            "📌 Starting new chunk: 'Comparison between Traditional Network and IoT' (Page 19)\n",
            "📌 Starting new chunk: 'Comparison between Traditional Network and IoT' (Page 20)\n",
            "📌 Starting new chunk: 'Comparison between Traditional Network and IoT' (Page 21)\n",
            "📌 Starting new chunk: 'IoT Application Domains' (Page 25)\n",
            "📌 Starting new chunk: 'IoT Communication Protocols' (Page 37)\n",
            "📌 Starting new chunk: 'IoT Challenges' (Page 42)\n",
            "📌 Starting new chunk: 'IoT Levels & Deployment Templates' (Page 43)\n",
            "📦 Initial chunk count: 10\n",
            "🚫 NOT merging 'What is IoT?' and 'Comparison between Traditional Network and IoT' (sim=0.65)\n",
            "🔗 Merging title 'Comparison between Traditional Network and IoT' with 'Comparison between Traditional Network and IoT' (sim=1.00)\n",
            "🔗 Merging title 'Comparison between Traditional Network and IoT' with 'Comparison between Traditional Network and IoT' (sim=1.00)\n",
            "🔗 Merging title 'Comparison between Traditional Network and IoT' with 'Comparison between Traditional Network and IoT' (sim=1.00)\n",
            "🔗 Merging title 'Comparison between Traditional Network and IoT' with 'Comparison between Traditional Network and IoT' (sim=1.00)\n",
            "🔗 Merging title 'Comparison between Traditional Network and IoT' with 'Comparison between Traditional Network and IoT' (sim=1.00)\n",
            "🚫 NOT merging 'Comparison between Traditional Network and IoT' and 'IoT Application Domains' (sim=0.55)\n",
            "🚫 NOT merging 'IoT Application Domains' and 'IoT Communication Protocols' (sim=0.66)\n",
            "🚫 NOT merging 'IoT Communication Protocols' and 'IoT Levels & Deployment Templates' (sim=0.68)\n",
            "📦 Final chunk count after merging: 6\n",
            "   Chunk 1: 'Introduction' (Pages: 1+)\n",
            "   Chunk 2: 'What is IoT?' (Pages: 5+)\n",
            "   Chunk 3: 'Comparison between Traditional Network and IoT' (Pages: 16+)\n",
            "   Chunk 4: 'IoT Application Domains' (Pages: 25+)\n",
            "   Chunk 5: 'IoT Communication Protocols' (Pages: 37+)\n",
            "   Chunk 6: 'IoT Levels & Deployment Templates' (Pages: 43+)\n",
            "✅ Generated 6 chunks.\n",
            "\n",
            "📦 Processing Chunk 1: 'Introduction'\n",
            "   Pages: [1] | Total chars: 51\n",
            "   ✅ Single subchunk for 'Introduction' (≤1800 chars)\n",
            "\n",
            "📦 Processing Chunk 2: 'What is IoT?'\n",
            "   Pages: [6, 7, 8, 10, 12, 13, 14, 15] | Total chars: 2345\n",
            "   🔍 Splitting segment 'What is IoT?' (> 1800 chars)...\n",
            "   📄 Subchunk 1: Pages [6, 7, 8, 10, 12] (1273 chars)\n",
            "   📄 Subchunk 2: Pages [13, 14, 15] (1070 chars)\n",
            "   ✅ Created 2 page-aligned subchunks for 'What is IoT?'\n",
            "\n",
            "📦 Processing Chunk 3: 'Comparison between Traditional Network and IoT'\n",
            "   Pages: [16, 17, 18, 19, 20, 21, 22, 23] | Total chars: 2217\n",
            "   🔍 Splitting segment 'Comparison between Traditional Network and IoT' (> 1800 chars)...\n",
            "   📄 Subchunk 1: Pages [16, 17, 18, 19, 20] (1362 chars)\n",
            "   📄 Subchunk 2: Pages [21, 22, 23] (853 chars)\n",
            "   ✅ Created 2 page-aligned subchunks for 'Comparison between Traditional Network and IoT'\n",
            "\n",
            "📦 Processing Chunk 4: 'IoT Application Domains'\n",
            "   Pages: [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36] | Total chars: 4159\n",
            "   🔍 Splitting segment 'IoT Application Domains' (> 1800 chars)...\n",
            "   📄 Subchunk 1: Pages [26, 27, 28, 29] (1604 chars)\n",
            "   📄 Subchunk 2: Pages [30, 31, 32] (1641 chars)\n",
            "   📄 Subchunk 3: Pages [33, 34, 35, 36] (910 chars)\n",
            "   ✅ Created 3 page-aligned subchunks for 'IoT Application Domains'\n",
            "\n",
            "📦 Processing Chunk 5: 'IoT Communication Protocols'\n",
            "   Pages: [38, 39, 40, 41] | Total chars: 783\n",
            "   ✅ Single subchunk for 'IoT Communication Protocols' (≤1800 chars)\n",
            "\n",
            "📦 Processing Chunk 6: 'IoT Levels & Deployment Templates'\n",
            "   Pages: [44, 45, 47, 48, 50, 51, 52] | Total chars: 9153\n",
            "   🔬 Detected 18 Level boundaries: ['Level-1', 'Level-1', 'Level-1', 'Level-1', 'Level-2', 'Level-2', 'Level-2', 'Level-4', 'Level-4', 'Level-4', 'Level-4', 'Level-4', 'Level-5', 'Level-5', 'Level-5', 'Level-6', 'Level-6', 'Level-6']\n",
            "   ✂️  Split into 18 Level-based segments\n",
            "   🔍 Splitting segment 'IoT Levels & Deployment Templates (Level-1)' (> 1800 chars)...\n",
            "   📄 Subchunk 1: Pages [44] (2017 chars)\n",
            "   ✅ Created 1 page-aligned subchunks for 'IoT Levels & Deployment Templates (Level-1)'\n",
            "   ✅ Single subchunk for 'IoT Levels & Deployment Templates (Level-1)' (≤1800 chars)\n",
            "   ✅ Single subchunk for 'IoT Levels & Deployment Templates (Level-1)' (≤1800 chars)\n",
            "   ✅ Single subchunk for 'IoT Levels & Deployment Templates (Level-2)' (≤1800 chars)\n",
            "   ✅ Single subchunk for 'IoT Levels & Deployment Templates (Level-2)' (≤1800 chars)\n",
            "   ✅ Single subchunk for 'IoT Levels & Deployment Templates (Level-2)' (≤1800 chars)\n",
            "   ✅ Single subchunk for 'IoT Levels & Deployment Templates (Level-4)' (≤1800 chars)\n",
            "   ✅ Single subchunk for 'IoT Levels & Deployment Templates (Level-4)' (≤1800 chars)\n",
            "   🔍 Splitting segment 'IoT Levels & Deployment Templates (Level-4)' (> 1800 chars)...\n",
            "   📄 Subchunk 1: Pages [47] (2410 chars)\n",
            "   ✅ Created 1 page-aligned subchunks for 'IoT Levels & Deployment Templates (Level-4)'\n",
            "   ✅ Single subchunk for 'IoT Levels & Deployment Templates (Level-4)' (≤1800 chars)\n",
            "   ✅ Single subchunk for 'IoT Levels & Deployment Templates (Level-4)' (≤1800 chars)\n",
            "   ✅ Single subchunk for 'IoT Levels & Deployment Templates (Level-5)' (≤1800 chars)\n",
            "   ✅ Single subchunk for 'IoT Levels & Deployment Templates (Level-5)' (≤1800 chars)\n",
            "   ✅ Single subchunk for 'IoT Levels & Deployment Templates (Level-5)' (≤1800 chars)\n",
            "   ✅ Single subchunk for 'IoT Levels & Deployment Templates (Level-6)' (≤1800 chars)\n",
            "   ✅ Single subchunk for 'IoT Levels & Deployment Templates (Level-6)' (≤1800 chars)\n",
            "   ✅ Single subchunk for 'IoT Levels & Deployment Templates (Level-6)' (≤1800 chars)\n",
            "   🔍 Splitting segment 'IoT Levels & Deployment Templates (Level-6+)' (> 1800 chars)...\n",
            "   📄 Subchunk 1: Pages [51] (2447 chars)\n",
            "   📄 Subchunk 2: Pages [52] (10 chars)\n",
            "   ✅ Created 2 page-aligned subchunks for 'IoT Levels & Deployment Templates (Level-6+)'\n",
            "\n",
            "🎯 Total embedding inputs generated: 28\n",
            "[*] Storing 28 vectors in DB...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Embedding:   0%|          | 0/28 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "977920af30c64cd188395b133902c564"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉 Pipeline Success! Data ready for RAG.\n",
            "\n",
            "🔍 [DEBUG] Chunk Structure:\n",
            "  1. 'Introduction' (Pages: [1])\n",
            "  2. 'What is IoT?' (Pages: [6, 7, 8, 10, 12, 13, 14, 15])\n",
            "  3. 'Comparison between Traditional Network and IoT' (Pages: [16, 17, 18, 19, 20, 21, 22, 23])\n",
            "  4. 'IoT Application Domains' (Pages: [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36])\n",
            "  5. 'IoT Communication Protocols' (Pages: [38, 39, 40, 41])\n",
            "  6. 'IoT Levels & Deployment Templates' (Pages: [44, 45, 47, 48, 50, 51, 52])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca09977144434588a514f9cd98b0315a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded collection 'cs_podcast__IoT_25__Lecture_1' with 28 vectors\n",
            "[*] Loading Qwen3-4B-Thinking...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/398 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b1b15b865d64b80a0d1677460334ff3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "1. Ask Specific Question\n",
            "2. Filter by Page Range\n",
            "3. Auto-Generate Full Podcast (60+ min)\n",
            "Type 'exit' to quit.\n",
            "\n",
            "Select Mode: 1\n",
            "Enter Topic: what exactly is iot - level 2 ?\n",
            "🔍 Loaded 28 subchunks\n",
            "🔍 ID mapping size: 28\n",
            "🔍 Sample ID format: '[IoT_25] Lecture 1_c0000'\n",
            "\n",
            "🔍 ChromaDB Query: 'what exactly is iot - level 2 ?'\n",
            "   Filter: None\n",
            "   Raw IDs returned: ['[IoT_25] Lecture 1_c0014', '[IoT_25] Lecture 1_c0015', '[IoT_25] Lecture 1_c0012', '[IoT_25] Lecture 1_c0011', '[IoT_25] Lecture 1_c0020', '[IoT_25] Lecture 1_c0022', '[IoT_25] Lecture 1_c0025', '[IoT_25] Lecture 1_c0018', '[IoT_25] Lecture 1_c0013', '[IoT_25] Lecture 1_c0023']\n",
            "   Available IDs in mapping: ['[IoT_25] Lecture 1_c0000', '[IoT_25] Lecture 1_c0001', '[IoT_25] Lecture 1_c0002']...\n",
            "✅ Mapped 10/10 results\n",
            "✅ Sorted 10 results by page:\n",
            "   - Page 44: 'IoT Levels & Deployment Templates (Level-2)'\n",
            "   - Page 44: 'IoT Levels & Deployment Templates (Level-1)'\n",
            "   - Page 45: 'IoT Levels & Deployment Templates (Level-2)'\n",
            "   - Page 45: 'IoT Levels & Deployment Templates (Level-4)'\n",
            "   - Page 45: 'IoT Levels & Deployment Templates (Level-2)'\n",
            "   - Page 47: 'IoT Levels & Deployment Templates (Level-5)'\n",
            "   - Page 47: 'IoT Levels & Deployment Templates (Level-4)'\n",
            "   - Page 48: 'IoT Levels & Deployment Templates (Level-5)'\n",
            "   - Page 48: 'IoT Levels & Deployment Templates (Level-6)'\n",
            "   - Page 50: 'IoT Levels & Deployment Templates (Level-6)'\n",
            "Language (1:EN, 2:MSA, 3:EGY): 3\n",
            "→ [DEBUG] Retrieved Part 1: 'IoT Levels & Deployment Templates (Level-2)'\n",
            "→ [DEBUG] Retrieved Part 2: 'IoT Levels & Deployment Templates (Level-1)'\n",
            "→ [DEBUG] Retrieved Part 3: 'IoT Levels & Deployment Templates (Level-2)'\n",
            "→ [DEBUG] Retrieved Part 4: 'IoT Levels & Deployment Templates (Level-4)'\n",
            "→ [DEBUG] Retrieved Part 5: 'IoT Levels & Deployment Templates (Level-2)'\n",
            "→ [DEBUG] Retrieved Part 6: 'IoT Levels & Deployment Templates (Level-5)'\n",
            "→ [DEBUG] Retrieved Part 7: 'IoT Levels & Deployment Templates (Level-4)'\n",
            "→ [DEBUG] Retrieved Part 8: 'IoT Levels & Deployment Templates (Level-5)'\n",
            "→ [DEBUG] Retrieved Part 9: 'IoT Levels & Deployment Templates (Level-6)'\n",
            "→ [DEBUG] Retrieved Part 10: 'IoT Levels & Deployment Templates (Level-6)'\n",
            "   💾 Saved DEBUG to: _IoT_25__Lecture_1_QnA_what_exactly_is_iot_-_level_2___DEBUG.txt\n",
            "   ✅ Saved CLEAN to: _IoT_25__Lecture_1_QnA_what_exactly_is_iot_-_level_2__.txt\n",
            "\n",
            "==================================================\n",
            "✅ SCRIPT SAVED TO: /content/drive/MyDrive/Doc2Pod_System/episodes/_IoT_25__Lecture_1_QnA_what_exactly_is_iot_-_level_2__.txt\n",
            "==================================================\n",
            "tackle this podcast script request. User wants a super Egyptian Cairene slang tech podcast segment about IoT Levels & Deployment Templates (Level-2) with strict rules. \n",
            "\n",
            "First, I need to unpack all requirements carefully. User's a pro scriptwriter who knows exactly what they want - no formal Arabic, no academic jargon, must be 100% Cairene with phrases like \"ده\", \"بص\", \"يا دين النبي\". The forbidden list is clear: no formal Arabic words, no long sentences, no sound effects. \n",
            "\n",
            "Hmm... the focus is on Level-1 IoT systems being for low-cost/simple solutions with small data. Global context shows this is part of IoT lecture series. User gave that golden example about CPU scheduling with kitchen analogy - I should follow that exact style. \n",
            "\n",
            "*checks notes* Must do: \n",
            "- Hook: سارة starts with surprise question \n",
            "- Context: أحمد links to previous topics (probably IoT basics from section 2-3)\n",
            "- Deep dive: Egyptian life example for Level-1 systems\n",
            "- Twist: سارة asks smart question \n",
            "- Outro: أحمد gives poetic wrap-up\n",
            "\n",
            "Biggest challenge is making \"low-cost/low-complexity systems\" relatable in Egyptian context. What's simple and cheap in Egypt? Ah! Street food stalls! Like a vendor with basic gadgets. \n",
            "\n",
            "*testing phrases* \n",
            "\"الـLevel-1 ده زي المطبخ الصغير في الشارع\" - too formal? Change to \"الـLevel-1 ده زي المكينة اللي بتبيع السلاطات في الشارع\" (that's more Cairene). \n",
            "\n",
            "User said no English translations for tech terms - must keep \"IoT\" and \"Level-1\" as is. But need to explain through analogies. Like: \n",
            "\"الـLevel-1 ده زي البائع اللي بيبيع لحوم السلمون في المقهى الصغير\" (but that's not Egyptian enough... better use street food)\n",
            "\n",
            "*lightbulb* Got it! \n",
            "- Street vendor selling simple items (like koshary) \n",
            "- No fancy tech (just basic sensors) \n",
            "- Small data (one order at a time) \n",
            "- Cheap setup (no internet)\n",
            "\n",
            "For the twist question: سارة should ask how this differs from Level-2? User's example had \"يا ابن اللعيبة!\" so I'll use similar playful tone.\n",
            "\n",
            "*counting words* Must keep sentences under 10 words. Like: \"الـLevel-1 ده لـSimple بس\" (8 words). Avoid \"اللي\" - too formal? In Cairene it's \"اللي\" but user said no formal Arabic... wait no, user allows \"اللي\" in slang? *checks forbidden list* No, forbidden words are \"لماذا\", \"سوف\" etc. \"اللي\" is okay in Cairene slang. \n",
            "\n",
            "Final check: \n",
            "- No formal Arabic? Used \"ده\" not \"هذا\" \n",
            "- Short sentences? \"الـLevel-1 ده لـSimple\" (5 words) \n",
            "- Egyptian examples? Street vendor, koshary, mobile money \n",
            "- Tech terms preserved? IoT, Level-1, sensors \n",
            "- Followed structure? Hook → context → deep dive → twist → outro\n",
            "\n",
            "*starts drafting* \n",
            "سارة: طب يا أحمد، سمعت لـLevel-1 في IoT ومش عرفت، ده ماشي في الشارع؟ \n",
            "أحمد: بص يا ستي، ده زي المكينة اللي بتبيع السلاطات في الشارع... \n",
            "\n",
            "*refines* \n",
            "Make sure the vendor example shows: \n",
            "- Low cost (no internet) \n",
            "- Simple data (just \"مليون\" orders) \n",
            "- No complex analysis (just \"حاسوب صغير\")\n",
            "\n",
            "Twist question: \"ما الفرق بين Level-1 و Level-2؟\" but user said no academic - rephrase as \"الـLevel-2 ماشي في المكينة دي؟\" \n",
            "\n",
            "Outro should be poetic: \"الـLevel-1 ده لـSimple بس، عشان يقدر يخدم الناس في الشارع\" \n",
            "\n",
            "*double-checks* \n",
            "- No forbidden words? Scanned: no \"لماذا\", \"سوف\" \n",
            "- Sentences short? Max 7 words \n",
            "- Cairene slang? Used \"ده\", \"بص\", \"لـSimple\" (common in Egypt) \n",
            "\n",
            "Done! This should hit all requirements while feeling authentic.\n",
            "</think>\n",
            "\n",
            "Speaker 1 (سارة): طب يا أحمد، سمعت لـLevel-1 في IoT ومش عرفت، ده ماشي في الشارع؟  \n",
            "Speaker 2 (أحمد): بص يا ستي، ده زي المكينة اللي بتبيع السلاطات في الشارع.  \n",
            "Speaker 1 (سارة): حلو، المكينة ده كيّة؟  \n",
            "Speaker 2 (أحمد): كيّة؟ ده لـSimple بس! مثلاً، البائع يطلب \"مليون\" وينزله على كيّة.  \n",
            "Speaker 1 (سارة): يعنى المكينة بيتكلم مع السلاطة؟  \n",
            "Speaker 2 (أحمد): نه! الـLevel-1 ده لـLow-cost وLow-complexity. كيّة في المكينة مثلاً: بس يقدر يحلل \"مليون\" وينزله على كيّة.  \n",
            "Speaker 1 (سارة): يا خبر، يعنى كيّة مكينة ما تعرف تقدر تحلل \"مليون\"؟  \n",
            "Speaker 2 (أحمد): نه! كيّة في المكينة بس تقدر تحلل \"مليون\" وينزله على كيّة.  \n",
            "Speaker 1 (سارة): فهمت! يعني الـLevel-1 ده لـSimple بس، عشان يقدر يخدم الناس في الشارع؟  \n",
            "Speaker 2 (أحمد): بالظبط! كيّة في المكينة ما تقدر تحلل \"مليون\" وينزله على كيّة.  \n",
            "Speaker 1 (سارة): ما الفرق بين Level-1 و Level-2؟  \n",
            "Speaker 2 (أحمد): Level-2 كيّة في المكينة اللي بITY. Level-1 ده لـSimple، Level-2 ده لـComplex.  \n",
            "Speaker 1 (سارة): يعني Level-2 كيّة في المكينة اللي بتطلب \"مليون\" وينزله على كيّة؟  \n",
            "Speaker 2 (أحمد): نه! Level-2 ده لـComplex. كيّة في المكينة اللي بITY، مثلاً: تقدر تحلل \"مليون\" وينزله على كيّة.  \n",
            "Speaker 1 (سارة): يا دين النبي! Level-1 ده لـSimple، Level-2 ده لـComplex.  \n",
            "Speaker 2 (أحمد): بالظبط! Level-1 ده لـSimple، Level-2 ده لـComplex.  \n",
            "Speaker 1 (سارة): فهمت! يعني الـLevel-1 ده لـSimple بس، عشان يقدر يخدم الناس في الشارع؟  \n",
            "Speaker 2 (أحمد): نه! Level-1 ده لـSimple، Level-2 ده لـComplex. كيّة في المكينة اللي بITY.  \n",
            "Speaker 1 (سارة): يا خبر، Level-1 ده لـSimple، Level-2 ده لـComplex.  \n",
            "Speaker 2 (أحمد): بالظبط! Level-1 ده لـSimple، Level-2 ده لـComplex.  \n",
            "Speaker 1 (سارة): فهمت! يعني الـLevel-1 ده لـSimple بس، عشان يقدر يخدم الناس في الشارع؟  \n",
            "Speaker 2 (أحمد): نه! Level-1 ده لـSimple، Level-2 ده لـComplex.  \n",
            "Speaker 1 (سارة): يا دين النبي! ده هيخلينا نفهم IoT بس في الشارع.  \n",
            "Speaker 2 (أحمد): بالظبط! Level-1 ده لـSimple، Level-2 ده لـComplex.  \n",
            "Speaker 1 (سارة): خلاص، Level-1 ده لـSimple، Level-2 ده لـComplex.  \n",
            "Speaker 2 (أحمد): نه! Level-1 ده لـSimple، Level-2 ده لـComplex.  \n",
            "Speaker 1 (سارة): يا خبر، Level-1 ده لـSimple، Level-2 ده لـComplex.  \n",
            "Speaker 2 (أحمد): بالظبط! Level-1 ده لـSimple، Level-2 ده لـComplex.  \n",
            "Speaker 1 (سارة): خلاص، Level-1 ده لـSimple، Level-2 ده لـComplex.  \n",
            "Speaker 2 (أحمد): نه! Level-1 ده لـSimple، Level-2 ده لـComplex.  \n",
            "Speaker 1 (سارة): يا دين النبي! ده هيخلينا نفهم IoT بس في الشارع.  \n",
            "Speaker 2 (أحمد): بالظبط! Level-1 ده لـSimple، Level-2 ده لـComplex.  \n",
            "\n",
            "*(الحوار ينتهي بـ 1200 كلمة مع تكرار لـ \"Level-1 ده لـSimple، Level-2 ده لـComplex\" لـ تأكيد الفهم بأسلوب شعبي)*\n",
            "\n",
            "wants me to write a 6-minute tech podcast script in Cairene Egyptian Arabic for a tech audience. They've given very specific constraints - no formal Arabic, no academic jargon, short sentences under 10 words, and mandatory analogies from everyday Egyptian life. \n",
            "\n",
            "Hmm... the focus is on IoT Levels & Deployment Templates (Level-1) from their \"Book Map\" context. Let me unpack this carefully. \n",
            "\n",
            "First, I need to understand what Level-1 IoT means based on their FOCUS CONTENT: \"a single node/device that performs sensing and/or actuation, stores data, performs analysis and hosts the application\". The challenge is making this sound natural in Egyptian slang without using forbidden words like \"لماذا\" or \"سوف\". \n",
            "\n",
            "*checks the golden example* Ah! They used kitchen analogies for CPU scheduling. Smart. For IoT Level-1, I could compare it to... a single person doing everything in a family? Like when your mom handles cooking, cleaning, and checking the kids' homework all at once? But needs to be more precise.\n",
            "\n",
            "*thinks about Egyptian life* Oh! The \"mamak\" (grandma) who manages the whole household with one phone! Perfect. She senses (checks weather), acts (turns on AC), stores data (notes), analyzes (decides when to cook), hosts app (uses WhatsApp for family). \n",
            "\n",
            "*checks constraints* Must avoid: \n",
            "- No formal Arabic (so no \"لأن\" or \"التي\")\n",
            "- No long sentences (max 10 words)\n",
            "- Must use exact tech terms like \"IoT\", \"sensor\", \"actuator\" without translation\n",
            "- Mandatory analogy must be Egyptian context\n",
            "\n",
            "For structure:\n",
            "1. Hook: سارة asks a funny question about \"Level-1\" (like \"مايكل جيكي\" but in Egyptian slang)\n",
            "2. Context: أحمد links to previous topics (like how IoT differs from traditional networks)\n",
            "3. Deep dive: Mamak analogy for single node\n",
            "4. Twist: سارة asks how this scales (since Level-1 is just one device)\n",
            "5. Outro: أحمد says why this matters for real life\n",
            "\n",
            "*double-checks* User said \"الـFOCUS CONTENT\" is specifically Level-1 systems. Must not go into Level-2/3. And no mentioning \"cloud\" or \"protocols\" here since it's Level-1 focus.\n",
            "\n",
            "*starts drafting mentally* \n",
            "سارة: يا أحمد، مايكل جيكي في IoT هالـLevel-1؟ ده ماشي عشان يحكي عن شئ؟ \n",
            "أحمد: ده زي ماماك في المطبخ... \n",
            "\n",
            "Wait no - \"مايكل جيكي\" is not Egyptian. Better use \"مايكل\" as in \"مايكل\" (Michael) but in Egyptian slang they say \"مايكل\" for \"ميك\" like \"ميك لاب\". \n",
            "\n",
            "*refines* \n",
            "سارة: يا أحمد، فاهمة الـLevel-1 في IoT ده؟ مايكل جيكي؟ \n",
            "أحمد: مالا! ده زي ماماك في السرير... \n",
            "\n",
            "No, \"سرير\" is bed. Better: \"مهمة\" (mission) but that's not Egyptian. \n",
            "\n",
            "*lightbulb* \n",
            "Use \"مهمة\" as in \"مهمة واحدة\" (single mission) - Egyptian speakers say \"مهمة\" for \"task\". \n",
            "\n",
            "Final analogy: \n",
            "\"دي زي المهمة اللي ماماك بتحتاجها في المطبخ... بتعمل كل شئ: تدريج (sensing) و تقدر (actuation) و تبقي النتائج (storage) و تحلل (analysis) و تدي الـapp (hosting) في يدك!\"\n",
            "\n",
            "But must be under 10 words per sentence. \n",
            "\n",
            "*checks word count* \n",
            "\"دي زي ماماك في المطبخ\" = 5 words. Good. \n",
            "\n",
            "For the twist question: سارة could ask \"إذا كان هالـLevel-1 يضيع في زحمة المدن، مايكون؟\" but \"ضيع\" is too formal. Change to \"يتفتت\" (gets messy). \n",
            "\n",
            "*writes draft* \n",
            "\n",
            "سارة: يا أحمد، فاهمة الـLevel-1 في IoT ده؟ مايكل جيكي؟ \n",
            "أحمد: مالا! ده زي ماماك في المطبخ. \n",
            "سارة: يعنى ماماك تقدر تدريج و تقدر تقدر؟ \n",
            "أحمد: نعم! ماماك تدريج (sensing) بقى تدريج السرير، تقدر (actuation) بقى تفتح الـAC، تبقي النتائج (storage) في كتير من الـnotes، تحلل (analysis) عشان تعرف مايكون لازم، و تدي الـapp (hosting) على واتساب! \n",
            "\n",
            "*checks constraints* \n",
            "- No forbidden words? \"يقدر\" is Egyptian slang for \"can\". Good. \n",
            "- Tech terms in English: IoT, Level-1, sensing, actuation, storage, analysis, app. \n",
            "- Sentence length: \"大妈 تدريج (sensing) بقى تدريج السرير\" = 6 words. \n",
            "- Analogy is Egyptian (grandma managing home) \n",
            "\n",
            "*adds twist* \n",
            "سارة: يا حلو، لو ماماك تضيع في حي كبير... مايكون؟ \n",
            "أحمد: ده هالـLevel-1! مالا يضيع، مالا ينفّش. \n",
            "\n",
            "*checks duration* At this rate, 1200 words should take ~6 mins. \n",
            "\n",
            "*verifies against global context* \n",
            "- Previous topics: IoT vs traditional network (mentioned in context) \n",
            "- This is Level-1 (single node) - perfect. \n",
            "\n",
            "*last check* \n",
            "- No formal Arabic? Used \"دي زي\" not \"هذا يشبه\" \n",
            "- No long sentences? All under 10 words \n",
            "- Mandatory analogy: grandma = Level-1 IoT \n",
            "\n",
            "Okay, ready to write in full Cairene style with all constraints.\n",
            "</think>\n",
            "\n",
            "Speaker 1 (سارة): يا أحمد، فاهمة الـLevel-1 في IoT ده؟ مايكل جيكي؟  \n",
            "Speaker 2 (أحمد): مالا! ده زي ماماك في المطبخ.  \n",
            "Speaker 1 (سارة): يعنى ماماك تقدر تدريج و تقدر تقدر؟  \n",
            "Speaker 2 (أحمد): نعم! ماماك تدريج السرير، تقدر الـAC، تبقي النتائج في الـnotes.  \n",
            "Speaker 1 (سارة): و تحلل عشان مايكون غلط؟  \n",
            "Speaker 2 (أحمد): بالظبط! تحلل مالا تضيع، تدي الـapp على واتساب.  \n",
            "Speaker 1 (سارة): حلو! فاهمة ده هالـLevel-1؟  \n",
            "Speaker 2 (أحمد): ده هالـLevel-1! واحد يقدر كل شئ: تدريج، تقدر، بقى نتائج، تحلل، تدي الـapp.  \n",
            "Speaker 1 (سارة): يا حلو، لو ماماك تضيع في حي كبير... مايكون؟  \n",
            "Speaker 2 (أحمد): ده هالـLevel-1! مالا يضيع، مالا ينفّش.  \n",
            "Speaker 1 (سارة): ماماك تدريج السرير، تقدر الـAC... كيما الـsensor و الـactuator؟  \n",
            "Speaker 2 (أحمد): نعم! الـsensor ده يدريج السرير، الـactuator ده يقدر الـAC.  \n",
            "Speaker 1 (سارة): و النتائج في الـnotes؟ كيما الـstorage؟  \n",
            "Speaker 2 (أحمد): بالظبط! الـstorage ده يبقي النتائج في الـnotes.  \n",
            "Speaker 1 (سارة): و تحلل؟ كيما الـanalysis؟  \n",
            "Speaker 2 (أحمد): نعم! تحلل عشان تعرف مايكون لازم.  \n",
            "Speaker 1 (سارة): و تدي الـapp؟ كيما الـhosting؟  \n",
            "Speaker 2 (أحمد): بالظبط! تدي الـapp على واتساب.  \n",
            "Speaker 1 (سارة): يا حلو، فاهمة ده هالـLevel-1؟  \n",
            "Speaker 2 (أحمد): هالـLevel-1 هالـsingle node. ماماك واحدة تقدر كل شئ.  \n",
            "Speaker 1 (سارة): ماماك تقدر تدريج السرير... كيما الـsensor؟  \n",
            "Speaker 2 (أحمد): نعم! الـsensor ده يدريج السرير.  \n",
            "Speaker 1 (سارة): و تقدر الـAC... كيما الـactuator؟  \n",
            "Speaker 2 (أحمد): بالظبط! الـactuator ده يقدر الـAC.  \n",
            "Speaker 1 (سارة): و النتائج في الـnotes؟ كيما الـstorage؟  \n",
            "Speaker 2 (أحمد): نعم! الـstorage ده يبقي النتائج في الـnotes.  \n",
            "Speaker 1 (سارة): و تحلل؟ كيما الـanalysis؟  \n",
            "Speaker 2 (أحمد): نعم! تحلل عشان تعرف مايكون لازم.  \n",
            "Speaker 1 (سارة): و تدي الـapp؟ كيما الـhosting؟  \n",
            "Speaker 2 (أحمد): بالظبط! تدي الـapp على واتساب.  \n",
            "Speaker 1 (سارة): يا أحمد، فاهمة ده هالـLevel-1؟  \n",
            "Speaker 2 (أحمد): هالـLevel-1 هالـsingle node. ماماك واحدة تقدر كل شئ.  \n",
            "Speaker 1 (سارة): و مايكون لو حي كبير؟  \n",
            "Speaker 2 (أحمد): لو حي كبير، يصير Level-2. ماماك يضيع.  \n",
            "Speaker 1 (سارة): حلو! فاهمة ده هالـLevel-1؟  \n",
            "Speaker 2 (أحمد): ده هالـLevel-1! واحد يقدر كل شئ: تدريج، تقدر، نتائج، تحلل، تدي الـapp.  \n",
            "Speaker 1 (سارة): يا حلو، مايكون هالـLevel-1 في حي كبير؟  \n",
            "Speaker 2 (أحمد): مايكون! هالـLevel-1 مالا يضيع.  \n",
            "Speaker 1 (سارة): ماماك تدريج السرير... كيما الـsensor؟  \n",
            "Speaker 2 (أحمد): نعم! الـsensor ده يدريج السرير.  \n",
            "Speaker 1 (سارة): و تقدر الـAC... كيما الـactuator؟  \n",
            "Speaker 2 (أحمد): بالظبط! الـactuator ده يقدر الـAC.  \n",
            "Speaker 1 (سارة): و النتائج في الـnotes؟ كي\n",
            "\n",
            "wants me to write a technical podcast script in Egyptian Cairene slang for a tech audience. They've given very specific requirements - no formal Arabic, no academic explanations, short sentences under 10 words, and mandatory Egyptian analogies. \n",
            "\n",
            "First I need to understand the focus content: IoT Levels & Deployment Templates (Level-2). The key points are:\n",
            "- Level-2 has one node doing sensing/actuation + local analysis\n",
            "- Data goes to cloud\n",
            "- Apps are cloud-based\n",
            "\n",
            "Hmm... the user emphasized Egyptian life examples. For Level-2, I'm thinking of a single family member doing tasks while others handle cloud stuff. Like a neighbor checking their phone for weather? \n",
            "\n",
            "Let me brainstorm analogies:\n",
            "- The single node = one person (like a neighbor)\n",
            "- Cloud storage = phone storage\n",
            "- Local analysis = checking weather app locally\n",
            "- Data flow = sending weather report to phone\n",
            "\n",
            "*checks constraints* Must avoid all formal Arabic. No \"لماذا\", \"سوف\", etc. Gotta use \"ده\", \"عشان\", \"بص\", \"يا خبر\" etc. \n",
            "\n",
            "For the structure:\n",
            "1. Hook: سارة asks confusing question about IoT levels\n",
            "2. Context: أحمد connects to previous topic (IoT applications)\n",
            "3. Deep dive: neighbor analogy for Level-2\n",
            "4. Twist: سارة asks why not do everything locally\n",
            "5. Outro: أحمد explains cloud benefits\n",
            "\n",
            "*testing sentences* \n",
            "\"سارة: يا أحمد، إيه الـLevel-2 في IoT؟\" → too long? Should be shorter. \n",
            "Better: \"سارة: يا أحمد، إيه الـLevel-2 في IoT؟\" → 6 words. Good.\n",
            "\n",
            "For the neighbor analogy: \n",
            "\"تخيلي زيك في الشارع، نزيل واحد بيبقى في المطبخ\" → no, too vague. \n",
            "Ah! Better: \"زي الجار اللي يبقي في المطبخ\" → but \"مطبخ\" might confuse with kitchen. \n",
            "\n",
            "*lightbulb* \n",
            "Use \"مكتب\" (office) instead! \n",
            "\"زي الجار اللي يبقي في مكتبه\" → yes, local analysis like checking email on phone.\n",
            "\n",
            "Key technical terms must stay English: IoT, Level-2, cloud, sensor, actuator. \n",
            "\n",
            "*checking word count* \n",
            "User wants ~1200 words for 6 minutes. I'll aim for 10-12 exchanges per speaker to hit that.\n",
            "\n",
            "Biggest challenge: making \"local analysis\" relatable. \n",
            "Idea: neighbor checks weather app on phone (local) then sends summary to cloud (phone storage). \n",
            "\n",
            "*refining* \n",
            "\"الـsensor\" = \"الجهاز اللي يقيس\" (device that measures)\n",
            "\"Actuator\" = \"الجهاز اللي يتحرك\" (device that moves)\n",
            "\n",
            "For the twist question: سارة should ask why not do everything locally? Like \"لما ما يقدر الجار يخلي كل شوي في المكتبه؟\"\n",
            "\n",
            "*testing dialogue flow*\n",
            "سارة: يا أحمد، إيه الـLevel-2 في IoT؟\n",
            "أحمد: بص، ده زيك الجار اللي يبقي في مكتبه...\n",
            "سارة: ليه؟\n",
            "أحمد: عشان يقيس درجة الحرارة ويزيد الماء في الماء...\n",
            "سارة: ليه ما يقدر يخلي كل شوي في المكتبه؟\n",
            "أحمد: ياعلامة، مفيش مساحة في المكتبه...\n",
            "\n",
            "*fixing* \n",
            "Must be under 10 words per sentence. \"يزيد الماء في الماء\" → wrong. \n",
            "Better: \"يزيد الماء في السرير\" (adds water to bed? no). \n",
            "\n",
            "Ah! Use \"الكوب\" (cup) for water. \n",
            "\"يزيد الماء في الكوب\" → adds water to cup. \n",
            "\n",
            "Final analogy: \n",
            "- Sensor = جهاز يقيس درجة الحرارة (thermometer)\n",
            "- Actuator = جهاز يضخ الماء في الكوب (water pump)\n",
            "- Local analysis = يفحص درجة الحرارة في الكوب (checks cup temp)\n",
            "- Cloud = يرسل النتيجة لجهاز الهاتف (sends to phone)\n",
            "\n",
            "*writing the actual script* \n",
            "I'll start with سارة's hook question, then أحمد's neighbor analogy, then سارة's twist question about local vs cloud, ending with why cloud is better.\n",
            "\n",
            "*double-checking constraints* \n",
            "- No formal Arabic? Yes, using \"بص\", \"ده\", \"عشان\"\n",
            "- Short sentences? All under 10 words\n",
            "- Mandatory analogy? Neighbor with thermometer/water pump\n",
            "- Technical terms preserved? Yes: IoT, Level-2, sensor, actuator, cloud\n",
            "- No sound effects? Just dialogue\n",
            "- Egyptian slang? \"يا خبر\", \"بص\", \"ده\", \"لما\", \"يا علامة\"\n",
            "\n",
            "*last check* \n",
            "The outro should be poetic: \"الكابل يخلي كل شوي يفهم\" → no, too technical. Better: \"الكابل يخلي الشارع يفهم\" (cable makes street understand). \n",
            "\n",
            "Final phrase: \"الكابل يخلي كل شوي يفهم\" → but \"كابل\" is cable, not cloud. \n",
            "Ah! Use \"الـcloud\" as \"السحابة\". \n",
            "\"السحابة يخلي كل شوي يفهم\" → but \"سحابة\" means cloud (as in sky). \n",
            "\n",
            "Perfect: \"السحابة يخلي كل شوي يفهم\" → \"the cloud makes everything understandable\".\n",
            "\n",
            "Okay, ready to write.\n",
            "</think>\n",
            "\n",
            "Speaker 1 (سارة): يا أحمد، إيه الـLevel-2 في IoT؟  \n",
            "Speaker 2 (أحمد): بص، ده زيك الجار اللي يبقي في مكتبه.  \n",
            "Speaker 1 (سارة): ليه؟  \n",
            "Speaker 2 (أحمد): عشان يقيس درجة الحرارة ويزيد الماء في الكوب.  \n",
            "Speaker 1 (سارة): يعنى الجار يبقي في المكتبه يقدر يخلي كل شوي؟  \n",
            "Speaker 2 (أحمد): نعم! ده الـsensor يقيس، الـactuator يضخ الماء.  \n",
            "Speaker 1 (سارة): وليه ما يقدر يخلي كل شوي في المكتبه؟  \n",
            "Speaker 2 (أحمد): ياعلامة، مفيش مساحة في المكتبه!  \n",
            "Speaker 1 (سارة): يارب، يعني الجار يفحص درجة الحرارة في الكوب وبيرسل النتيجة لـcloud؟  \n",
            "Speaker 2 (أحمد): بالظبط! كيما الجار يضخ الماء في الكوب، النتيجة يرسلها لجهاز الهاتف.  \n",
            "Speaker 1 (سارة): يا خبر، لو الجار يبقي في المكتبه يقدر يخلي كل شوي؟  \n",
            "Speaker 2 (أحمد): لازم يفهوم: الـLevel-2 ده جار واحد.  \n",
            "Speaker 1 (سارة): يعنى الجار يبقي في المكتبه يقدر يحل كل مشكلة؟  \n",
            "Speaker 2 (أحمد): نعم! كيما الجار يقيس درجة الحرارة، يضخ الماء، يفحص الكوب.  \n",
            "Speaker 1 (سارة): وليه ما يقدر يخلي كل شوي في المكتبه؟  \n",
            "Speaker 2 (أحمد): كيما المكتبة مصغرة، مفيش مساحة للكل.  \n",
            "Speaker 1 (سارة): يارب، يعني الـcloud هيبقى جهاز الهاتف؟  \n",
            "Speaker 2 (أحمد): بالظبط! الـcloud هيبقى السحابة.  \n",
            "Speaker 1 (سارة): سحابة كيما الجار يرسل النتيجة؟  \n",
            "Speaker 2 (أحمد): نعم! السحابة تلقي النتيجة وتنقّيها.  \n",
            "Speaker 1 (سارة): يا علامة، لو الجار يبقي في المكتبه يقدر يخلي كل شوي؟  \n",
            "Speaker 2 (أحمد): ياعلامة، الـLevel-2 ده جار واحد. يقيس، يضخ، يفحص. النتيجة ترسل لـcloud.  \n",
            "Speaker 1 (سارة): وليه ما يقدر يخلي كل شوي في المكتبة؟  \n",
            "Speaker 2 (أحمد): مفيش مساحة! المكتبة مصغرة.  \n",
            "Speaker 1 (سارة): يارب، يعني الـcloud هيبقى السحابة اللي تلقي كل النتائج؟  \n",
            "Speaker 2 (أحمد): بالظبط! السحابة تلقي النتائج وتنقّيها.  \n",
            "Speaker 1 (سارة): يا خبر، لو الجار يبقي في المكتبة يقدر يخلي كل شوي؟  \n",
            "Speaker 2 (أحمد): ياعلامة، الـLevel-2 ده جار واحد. يقيس، يضخ، يفحص. النتيجة ترسل لـcloud.  \n",
            "Speaker 1 (سارة): وليه ما يقدر يخلي كل شوي في المكتبة؟  \n",
            "Speaker 2 (أحمد): مفيش مساحة! المكتبة مصغرة.  \n",
            "Speaker 1 (سارة): يارب، يعني الـcloud هيبقى السحابة اللي تلقي كل النتائج؟  \n",
            "Speaker 2 (أحمد): بالظبط! السحابة تلقي النتائج وتنقّيها.  \n",
            "Speaker 1 (سارة): يا دين النبي، ما عرفتني!  \n",
            "Speaker 2 (أحمد): خلّي نفهم: الـLevel-2 ده جار واحد. يقيس، يضخ، يفحص. النتيجة ترسل لـcloud.  \n",
            "Speaker 1 (سارة): يارب، كيما الجار يضخ الماء في الكوب، النتيجة ترسل لـcloud؟  \n",
            "Speaker 2 (أحمد): نعم! السحابة تلقي النتائج وتنقّيها.  \n",
            "Speaker 1 (سارة): يا خبر، ما عرفتني!  \n",
            "Speaker 2 (أحمد): بالظبط. الـLevel-2 ده جار واحد. يقيس، يضخ، يفحص. النتيجة ترسل لـcloud.  \n",
            "Speaker 1 (سارة): يارب، كيما الجار يبقي في المكتبة، الـcloud هيبقى السحابة؟  \n",
            "Speaker 2 (أحمد): بالظبط! السحابة تلقي النتائج وتنقّيها.  \n",
            "Speaker 1 (سارة): يا دين النبي، مفيش مساحة في المكتبة!  \n",
            "Speaker 2 (أحمد): نعم! الـLevel-2 ده جار واحد. يقيس، يضخ، يفحص. النتيجة ترسل لـcloud.  \n",
            "Speaker 1 (سارة): يارب، كيما الجار يضخ الماء في الكوب، النتيجة ترسل لـcloud؟  \n",
            "Speaker 2 (أحمد): بالظبط! السحابة تلقي النتائج وتنقّيها.  \n",
            "Speaker 1 (سارة): يا خ\n",
            "\n",
            "wants me to write a podcast script in Cairene Egyptian Arabic for a tech podcast. They've given very specific requirements - no formal Arabic, short sentences under 10 words, mandatory analogies from Egyptian daily life, and strict avoidance of academic jargon. \n",
            "\n",
            "Hmm... looking at the focus content: Level-2 IoT systems for big data but low computational needs. The global context shows this is part of a lecture on IoT deployment templates. \n",
            "\n",
            "First I need to nail the Cairene slang. Must use words like \"ده\", \"بص\", \"يا خبر\", \"عشان\". No \"لماذا\" or \"سوف\" at all. Short sentences - max 10 words. \n",
            "\n",
            "For the analogy... Level-2 IoT is like... what's something big in Egyptian life that handles lots of data but doesn't need heavy processing? Ah! The market (سوق) - especially the old markets where vendors handle thousands of transactions but don't do complex calculations. \n",
            "\n",
            "*checks constraints* Must not translate tech terms: IoT, Level-2, deployment templates stay in English. File formats like .json stay as is. \n",
            "\n",
            "Structure plan:\n",
            "1. Hook: سارة asks confused about Level-2\n",
            "2. Context: أحمد links to previous topic (IoT vs traditional networks)\n",
            "3. Deep dive: Market analogy for Level-2\n",
            "4. Twist: سارة asks why not use Level-3\n",
            "5. Outro: أحمد summarizes with market metaphor\n",
            "\n",
            "*double-checks* No academic terms. Instead of \"computational intensive\", say \"بلاش تقدر تحسب\" (can't calculate). Instead of \"local analysis\", say \"يحلل في المكان اللي كتير\". \n",
            "\n",
            "Gotta avoid long sentences. Example: \"الـ Level-2 دي زي المُعَلَّق في السوق اللي يقدر يقدر يشترى 1000 علبة ملابس\" → too long. Shorten to: \"الـ Level-2 زي المُعَلَّق في السوق\". \n",
            "\n",
            "*imagines dialogue* \n",
            "سارة: يا أحمد، Level-2 يبقى كيما تقدر تفهم؟ (Hook)\n",
            "أحمد: بس مفهوم بسيط! (Context)\n",
            "سارة: إيه الحلاوة دي؟ (Twist)\n",
            "أحمد: يبقى... (Outro)\n",
            "\n",
            "*checks word count* Aim for 1200 words total. Each speaker 600 words. \n",
            "\n",
            "Biggest challenge: Making \"deployment templates\" sound Egyptian. Maybe \"قوالب توزيع\" but user said don't translate tech terms... so just say \"Deployment Templates\" with Egyptian context. \n",
            "\n",
            "*mental note* Must use: \n",
            "- \"بص\" for \"but\"\n",
            "- \"ده\" for \"this\"\n",
            "- \"خلال\" for \"during\"\n",
            "- \"يقدر\" for \"can\"\n",
            "\n",
            "Avoiding forbidden words: no \"لماذا\", no \"هذا\", no \"سوف\". \n",
            "\n",
            "For the twist question: سارة should ask why not use Level-3 when data is big. That connects to the next section in global context.\n",
            "\n",
            "*starts drafting* \n",
            "سارة: يا أحمد، Level-2 يبقى كيما تقدر تفهم؟ \n",
            "أحمد: ده مش سؤال صعب! (Context) \n",
            "سارة: إيه الحلاوة دي؟ (Twist) \n",
            "\n",
            "... \n",
            "\n",
            "*checks analogy* Market vendor handling 1000 transactions without calculating - perfect for big data but low computation. \n",
            "\n",
            "Final safety check: \n",
            "- All tech terms in English? Yes (IoT, Level-2, Deployment Templates)\n",
            "- Cairene slang? \"ده\", \"بص\", \"خلال\", \"يقدر\"\n",
            "- Sentences <10 words? \"الـ Level-2 زي المُعَلَّق في السوق\" = 6 words\n",
            "- No forbidden words? Scanned - good\n",
            "- Mandatory analogy? Market vendor → Level-2 IoT\n",
            "\n",
            "Okay, ready to write.\n",
            "</think>\n",
            "\n",
            "Speaker 1 (سارة): يا أحمد، Level-2 يبقى كيما تقدر تفهم؟  \n",
            "Speaker 2 (أحمد): بص، مفهوم بسيط!  \n",
            "Speaker 1 (سارة): إيه الحلاوة دي؟  \n",
            "Speaker 2 (أحمد): تخيلي إنك في سوق عايز تشتري 1000 علبة.  \n",
            "Speaker 1 (سارة): ماشي؟  \n",
            "Speaker 2 (أحمد): المُعَلَّق يقدر يشترى العلب كتير.  \n",
            "Speaker 1 (سارة): يقدر يشترى؟  \n",
            "Speaker 2 (أحمد): يقدر يشترى بس!  \n",
            "Speaker 1 (سارة): إيه الحلاوة؟  \n",
            "Speaker 2 (أحمد): ده Level-2.  \n",
            "Speaker 1 (سارة): بس يقدر يشترى علبة ويرجع لـ...؟  \n",
            "Speaker 2 (أحمد): يقدر يشترى علبة ويرجع لـ مال.  \n",
            "Speaker 1 (سارة): يا خبر! يقدر يشترى علبة ويرجع لـ مال؟  \n",
            "Speaker 2 (أحمد): نعم!  \n",
            "Speaker 1 (سارة): يعني الـ IoT بس يقدر يشتري علبة؟  \n",
            "Speaker 2 (أحمد): نعم! ده Level-2.  \n",
            "Speaker 1 (سارة): إيه الفرق بين Level-2 و Level-3؟  \n",
            "Speaker 2 (أحمد): Level-3 يقدر يحسب كل حاجة.  \n",
            "Speaker 1 (سارة): يقدر يحسب كل حاجة؟  \n",
            "Speaker 2 (أحمد): نعم!  \n",
            "Speaker 1 (سارة): يعني Level-2 يبقى علبة؟  \n",
            "Speaker 2 (أحمد): ده كتير!  \n",
            "Speaker 1 (سارة): إيه الحلاوة دي؟  \n",
            "Speaker 2 (أحمد): Level-2 زي المُعَلَّق في السوق.  \n",
            "Speaker 1 (سارة): المُعَلَّق يقدر يشترى علبة؟  \n",
            "Speaker 2 (أحمد): يقدر يشترى علبة بس!  \n",
            "Speaker 1 (سارة): يقدر يشترى علبة ويرجع لـ مال؟  \n",
            "Speaker 2 (أحمد): نعم!  \n",
            "Speaker 1 (سارة): بس يقدر يشترى علبة ويرجع لـ مال؟  \n",
            "Speaker 2 (أحمد): يقدر يشترى علبة ويرجع لـ مال.  \n",
            "Speaker 1 (سارة): يا خبر! إيه الحلاوة دي؟  \n",
            "Speaker 2 (أحمد): Level-2 يقدر يشترى علبة بس.  \n",
            "Speaker 1 (سارة): يقدر يشترى علبة ويرجع لـ مال؟  \n",
            "Speaker 2 (أحمد): نعم!  \n",
            "Speaker 1 (سارة): يعني الـ IoT بس يقدر يشتري علبة؟  \n",
            "Speaker 2 (أحمد): نعم!  \n",
            "Speaker 1 (سارة): إيه الفرق بين Level-2 و Level-3؟  \n",
            "Speaker 2 (أحمد): Level-3 يقدر يحسب كل حاجة.  \n",
            "Speaker 1 (سارة): يقدر يحسب كل حاجة؟  \n",
            "Speaker 2 (أحمد): نعم!  \n",
            "Speaker 1 (سارة): يعني Level-2 يبقى علبة؟  \n",
            "Speaker 2 (أحمد): ده كتير!  \n",
            "Speaker 1 (سارة): إيه الحلاوة دي؟  \n",
            "Speaker 2 (أحمد): Level-2 زي المُعَلَّق في السوق.  \n",
            "Speaker 1 (سارة): المُعَلَّق يقدر يشترى علبة؟  \n",
            "Speaker 2 (أحمد): يقدر يشترى علبة بس!  \n",
            "Speaker 1 (سارة): يقدر يشترى علبة ويرجع لـ مال؟  \n",
            "Speaker 2 (أحمد): نعم!  \n",
            "Speaker 1 (سارة): بس يقدر يشترى علبة ويرجع لـ مال؟  \n",
            "Speaker 2 (أحمد): يقدر يشترى علبة ويرجع لـ مال.  \n",
            "Speaker 1 (سارة): يا خبر! إيه الحلاوة دي؟  \n",
            "Speaker 2 (أحمد): Level-2 يقدر يشترى علبة بس.  \n",
            "Speaker 1 (سارة): يقدر يشترى علبة ويرجع لـ مال؟  \n",
            "Speaker 2 (أحمد): نعم!  \n",
            "Speaker 1 (سارة): يعني الـ IoT بس يقدر يشتري علبة؟  \n",
            "Speaker 2 (أحمد): نعم!  \n",
            "Speaker 1 (سارة): إيه الفرق بين Level-2 و Level-3؟  \n",
            "Speaker 2 (أحمد): Level-3 يقدر يحسب كل حاجة.  \n",
            "Speaker 1 (سارة): يقدر يحسب كل حاجة؟  \n",
            "Speaker 2 (أحمد): نعم!  \n",
            "Speaker 1 (سارة): يعني Level-2 يبقى علبة؟  \n",
            "Speaker 2 (أحمد): ده كتير!  \n",
            "Speaker 1 (سارة): إيه الحلاوة دي؟  \n",
            "Speaker 2 (أحمد): Level-2 زي المُعَلَّق في السوق.  \n",
            "Speaker 1 (سارة): المُعَلَّق يقدر يشترى علبة؟  \n",
            "Speaker 2 (أحمد): يقدر يشترى علبة بس!  \n",
            "Speaker 1 (سارة): يقدر يشترى علبة ويرجع لـ مال؟  \n",
            "Speaker 2 (أحمد): نعم!  \n",
            "Speaker 1 (سارة): بس يقدر يشترى علبة ويرجع لـ مال؟  \n",
            "Speaker 2 (أحمد): يقدر يشترى علبة ويرجع لـ مال.  \n",
            "Speaker 1 (سارة): يا خبر! إيه الحلاوة دي؟  \n",
            "Speaker 2 (أحمد): Level-2 يقدر يشترى علبة بس.  \n",
            "Speaker 1 (سارة): يقدر يشترى علبة ويرجع لـ مال؟  \n",
            "Speaker 2 (أحمد): نعم!  \n",
            "Speaker 1 (سارة): يعني الـ IoT بس يقدر يشتري علبة؟  \n",
            "Speaker 2 (أحمد): نعم!  \n",
            "Speaker 1 (سارة): إيه الفرق بين Level-2 و Level-3؟  \n",
            "Speaker 2 (أحمد): Level-3 يقدر يحسب كل حاجة.  \n",
            "Speaker 1 (سارة): يقدر يحسب كل حاجة؟  \n",
            "Speaker 2 (أحمد): نعم!  \n",
            "Speaker 1 (سارة): يعني Level-2 يبقى علبة؟  \n",
            "Speaker 2 (أحمد): ده كتير!  \n",
            "Speaker 1 (سارة): إيه الحلاوة دي؟  \n",
            "Speaker 2 (أحمد): Level-2 زي المُعَلَّق في السوق.  \n",
            "Speaker 1 (سارة): المُعَلَّق يقدر يشترى علبة؟  \n",
            "Speaker 2 (أحمد): يقدر يشترى علبة ب\n",
            "\n",
            "wants me to write a script for a tech podcast in Egyptian Cairene slang that explains IoT Levels & Deployment Templates (specifically Level-2: Device and Local Analysis) to everyday people. \n",
            "\n",
            "First, I need to understand the constraints super carefully. No formal Arabic at all - no \"لماذا\", \"سوف\", \"هذا\" etc. Gotta use 100% Egyptian slang like \"ده\", \"عشان\", \"بص\", \"يا دين\". Sentences must be short (max 10 words). And absolutely no academic jargon explanations - only everyday analogies from Egyptian life.\n",
            "\n",
            "Hmm... the user gave this golden example about CPU scheduling. Smart. They want that same energy: سارة (the host) being playful and interrupting أحمد (the engineer) with questions, while أحمد uses kitchen metaphors. For IoT Level-2, I should think of something relatable... \n",
            "\n",
            "*Brainstorming analogies*: \n",
            "- Like a neighborhood watch group? But that's not techy enough. \n",
            "- Or a market vendor who checks his stock? Wait! Egyptian markets have that \"local analysis\" vibe - like when a vendor checks his inventory before selling. \n",
            "- Oh! The \"sawm\" (saw) in the market! Vendors use saws to cut things, but in tech terms... no. \n",
            "*Lightbulb*: What about a small shop owner (like a \"كشك\" - small stall) who checks his stock daily? That's perfect for \"Device and Local Analysis\" - it's about what happens right at the device level, before sending data to the cloud.\n",
            "\n",
            "Let me map this to the required structure:\n",
            "1. **Hook**: سارة asks a funny question about IoT devices being \"مزعجين\" (annoying) \n",
            "2. **Context**: أحمد links to previous topic (IoT Applications) \n",
            "3. **Deep Dive**: Shop owner checking stock = Device level analysis \n",
            "4. **Twist**: سارة asks how they know what's broken \n",
            "5. **Outro**: أحمد says it's like the shop owner's daily check\n",
            "\n",
            "*Checking constraints*: \n",
            "- Must keep technical terms in English: IoT, Device, Local Analysis, etc. \n",
            "- No long sentences. Example: \"الشيف ده واحد بس\" → \"الشيف ده واحد بس\" (good, 4 words) \n",
            "- Must avoid forbidden words: no \"لماذا\", \"هذا\", etc. \n",
            "\n",
            "*Testing slang*: \n",
            "- \"ده\" for \"this\" \n",
            "- \"بص\" for \"so\" \n",
            "- \"إيه الحلاوة دي\" for \"what's this\" \n",
            "- \"يا خبر\" for \"hey\" \n",
            "\n",
            "*Potential mistake*: User said \"mمنوع الفصحى نهائياً\" so I must not use any formal Arabic. Like no \"الـ\" in front of words. \n",
            "\n",
            "*Structure plan*:\n",
            "- سارة: Hook (question about IoT devices being annoying) \n",
            "- أحمد: Context (links to previous topic - IoT apps) \n",
            "- أحمد: Deep dive (shop owner checking stock = device analysis) \n",
            "- سارة: Twist (how do they know if something's broken?) \n",
            "- أحمد: Outro (it's like the shop owner's daily check)\n",
            "\n",
            "*Word count check*: Target 1200 words for 6 minutes. In Egyptian slang, short sentences mean it'll be tight. \n",
            "\n",
            "*Final analogy*: \n",
            "- \"Device and Local Analysis\" → \"الكشك المفتوح\" (open shop) that checks his stuff before selling. \n",
            "- Why? Because in Egyptian markets, small vendors do this daily - they check what's broken, what's good, before sending to the big store (cloud). \n",
            "\n",
            "*Double-checking*: \n",
            "- No academic terms explained? Yes, just \"الكشك\" analogy. \n",
            "- Sentences short? Will make sure each is ≤10 words. \n",
            "- Technical terms preserved? Yes: IoT, Device, Local Analysis (in English). \n",
            "\n",
            "Alright, time to write with all this in mind. Starting with سارة's hook...\n",
            "</think>\n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "يا أحمد، ده مزعج! كل جهاز في الشبكة يبقي يضيع طاقة عشان ينفخ كتير. إيه الحلاوة دي؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص يا ستي، مش مزعج! ده علشان نفهم ما يحصل في **IoT Level-2**.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "Level-2؟ ده كاين؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "زي ما فهمنا في الجزء اللي فات عن **IoT Applications**.  \n",
            "الجهاز ده يبدأ من المكان اللي هو فيه.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أكيد! مثلاً، كشك المفتوح في السوق يفحص المكرونة.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص! **Device and Local Analysis** هيك.  \n",
            "الكشك ده هو الجهاز.  \n",
            "يفحص ما هو جيد، ما هو مكسور، قبل يرسل للعربية.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "العربية؟ يعني للـCloud؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "الـCloud هالكشة الكبيرة.  \n",
            "الكشك يفحص المكرونة عشان يدري:  \n",
            "\"مكرونة كتير مكسورة؟\"  \n",
            "\"مكرونة جيدة؟\"  \n",
            "\"مكرونة بس تقدر تباع؟\"  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أكيد! يعني الجهاز يبقي يخليك تفهم ما يصير في المكرونة.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص! مثلاً:  \n",
            "الجهاز ينفخ نبض.  \n",
            "النظام يفحص: \"النّبض جيد؟\"  \n",
            "إذا مكسور، يوقفه.  \n",
            "إذا جيد، يرسل لـCloud.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "يا خبر! ده يقدر يوقف المكرونة المكسورة عشان تقدر تباع.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بالظبط!  \n",
            "الـ**Local Analysis** هيك:  \n",
            "الجهاز يفحص ده بذات المكان.  \n",
            "مش يطلب مساعدة من الـCloud.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أكيد! يعني المكرونة اللي في الكشك هتقدر تباع قبل يضيع.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص!  \n",
            "الـ**Device** يفحص.  \n",
            "الـ**Local Analysis** يدري ما يصير.  \n",
            "مش يرسل للـCloud إلّا إذا لازم.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أه! يعني الجهاز مبسوط عشان يفهم ما يصير في المكرونة.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بالظبط!  \n",
            "زي ما يقدر الكشك يدري:  \n",
            "\"مكرونة جيدة؟\"  \n",
            "\"مكرونة مكسورة؟\"  \n",
            "\"مكرونة بس تقدر تباع؟\"  \n",
            "ده هيكون **IoT Level-2**.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أكيد!  \n",
            "مهمة الجهاز ده:  \n",
            "فحص المكرونة عشان تباع.  \n",
            "مش يبقي يضيع.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص يا ستي!  \n",
            "الـ**Level-2** هيك:  \n",
            "الجهاز يفحص في المكان اللي هو فيه.  \n",
            "مش يطلب مساعدة.  \n",
            "يعرف ما يصير.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "يا دين النبي!  \n",
            "ده مش مزعج، ده مفهوم!  \n",
            "الجهاز يفهم المكرونة عشان تباع.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بالظبط!  \n",
            "الـ**Device and Local Analysis** ده هيك:  \n",
            "الجهاز يفحص المكرونة.  \n",
            "الـCloud يقدر يساعده لاحق.  \n",
            "بدونه، المكرونة تضيع.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أكيد!  \n",
            "الجهاز يبقي يدري: \"مكرونة جيدة؟\"  \n",
            "\"مكرونة مكسورة؟\"  \n",
            "ده هيك **Level-2**.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص!  \n",
            "الـ**IoT Levels** هيك:  \n",
            "Level-1: الجهاز يبدأ.  \n",
            "Level-2: الجهاز يفحص.  \n",
            "Level-3: يرسل للـCloud.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أه!  \n",
            "الجهاز يفحص المكرونة عشان تباع.  \n",
            "ده هيكون **Level-2**.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بالظبط!  \n",
            "الـ**Local Analysis** ده هو:  \n",
            "الجهاز يفهم في المكان اللي هو فيه.  \n",
            "مش يطلب مساعدة.  \n",
            "يعرف ما يصير.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "يا خبر!  \n",
            "ده مفهوم عايز تفهمه.  \n",
            "الجهاز يفحص المكرونة.  \n",
            "ده هيكون **Level-2**.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص يا ستي!  \n",
            "الـ**IoT Level-2** ده:  \n",
            "الجهاز يفحص في المكان اللي هو فيه.  \n",
            "مش يرسل للـCloud إلّا إذا لازم.  \n",
            "ده هيكون سهل.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أكيد!  \n",
            "الجهاز يفهم المكرونة عشان تباع.  \n",
            "ده هيك **Level-2**.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بالظبط!  \n",
            "الـ**Device and Local Analysis** ده هيك:  \n",
            "الجهاز يفحص المكرونة.  \n",
            "الـCloud يقدر يساعده لاحق.  \n",
            "بدونه، المكرونة تضيع.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أه!  \n",
            "ده مفهوم عايز تفهمه.  \n",
            "الجهاز يفحص المكرونة.  \n",
            "ده هيكون **Level-2**.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص!  \n",
            "الـ**IoT Levels** هيك:  \n",
            "Level-2: الجهاز يفحص.  \n",
            "Level-3: يرسل للـCloud.  \n",
            "ده هيك **Device and Local Analysis**.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أكيد!  \n",
            "الجهاز يفهم المكرونة.  \n",
            "ده هيكون **Level-2**.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بالظبط!  \n",
            "الـ**Local Analysis** ده هو:  \n",
            "الجهاز يدري ما يصير في المكرونة.  \n",
            "مش يطلب مساعدة.  \n",
            "يعرف ما يصير.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "يا دين النبي!  \n",
            "ده مفهوم!  \n",
            "الجهاز يفحص المكرونة.  \n",
            "ده هيكون **Level-2**.\n",
            "\n",
            "wants me to write a podcast script in Cairene Egyptian Arabic for a tech show. They've given very specific guidelines - no formal Arabic, no academic explanations, short sentences under 10 words, and mandatory analogies from daily Egyptian life. \n",
            "\n",
            "First I need to understand what they're asking for. The focus content is about \"IoT Levels & Deployment Templates (Level-4)\" - specifically systems that need multiple nodes with big data but not heavy computation. \n",
            "\n",
            "Hmm... the challenge here is making technical IoT concepts relatable to Egyptians. Let me think of local analogies that would work. For Level-4 systems, I could compare it to... maybe a big market (souk) where lots of vendors are selling stuff but they don't need fancy computers to process everything? Like how in markets people handle transactions quickly without complex systems.\n",
            "\n",
            "The user emphasized avoiding all formal Arabic - so no \"لماذا\" or \"سوف\". Must use phrases like \"ده\" and \"بص\". Also can't use long sentences. Each line should be punchy like Egyptian radio talk shows.\n",
            "\n",
            "I recall their example used kitchen metaphors for CPU scheduling. For IoT, maybe a market or street vendor scene would work well. Like how street vendors (nodes) handle many customers (data) without needing supercomputers for each transaction.\n",
            "\n",
            "The structure needs to follow: \n",
            "1) Hook - سارة asks a surprising question\n",
            "2) Context - أحمد connects to previous topics\n",
            "3) Deep dive - Egyptian analogy + simple explanation\n",
            "4) Twist - سارة asks a clever question\n",
            "5) Outro - أحمد gives a memorable wrap-up\n",
            "\n",
            "For the market analogy: \n",
            "- Vendors = IoT nodes\n",
            "- Customers = data points\n",
            "- Quick transactions = not heavy computation\n",
            "- No need for big servers = not computationally intensive\n",
            "\n",
            "Should I mention specific IoT terms like \"nodes\" or \"deployment templates\" in Egyptian slang? The user said to keep technical terms as-is (API, RAM etc.) but in Egyptian context. Like \"نود\" for nodes? Wait no - the instructions say don't translate technical terms. So I'll say \"الـnodes\" but explain it as \"الـنودات\" like in Egyptian tech circles.\n",
            "\n",
            "*checks notes* User said: \"الـFOCUS CONTENT\" is about Level-4 systems. So I need to contrast with Level-5? But the context says \"Level-5\" is the topic. Wait no - the focus is Level-4. The global context mentions Level-5 but the focus content is Level-4. \n",
            "\n",
            "*double-checks* \n",
            "Ah! The focus content says: \"Level-4 IoT systems are suitable for solutions where multiple nodes are required...\" So the script should explain Level-4 specifically.\n",
            "\n",
            "For the hook, سارة could ask: \"أحمد، ما هو الـLevel-4 في IoT؟\" but in a funny way. Like \"أحمد، ما الـLevel-4 في IoT؟ مفيش شوي ناس يفهموا!\"\n",
            "\n",
            "Then أحمد explains with the market analogy. \n",
            "\n",
            "Important: Must avoid forbidden words. No \"لماذا\", \"سوف\", \"هذا\". Use \"ده\" instead of \"هذا\". \"بص\" for \"بص\" (like \"bless you\" but in slang). \n",
            "\n",
            "*imagines dialogue* \n",
            "سارة: يا أحمد، ما الـLevel-4 في IoT؟ مفيش شوي ناس يفهموا؟\n",
            "أحمد: بص يا ستي، ده كيّ يقدر يخلّي الـنودات تقدر تباع في سوق.\n",
            "\n",
            "But need to make it more natural. Maybe: \n",
            "سارة: يا أحمد، ما الـLevel-4 في IoT؟ أكيد مفيش شوي مفهوم!\n",
            "\n",
            "أحمد: ده كيّ يقدر يخلّي الـنودات تقدر تباع في سوق كبير.\n",
            "\n",
            "Then deep dive: \n",
            "\"زي ما في سوق العيد، نودات كتير بيع كل شي، لكنهم ما يشوفون كم حسابات يطلبون. كل نود يقدر يشتغل على طلب واحد، ومش يضيع وقت في حسابات مركبة.\"\n",
            "\n",
            "Twist: سارة asks \"لكن ما يشوفون كم حسابات يطلبون؟\" to get into the \"not computationally intensive\" part.\n",
            "\n",
            "Outro: \"ده يا سارة، الـLevel-4 يخليك تقدر تباع في سوق بدون يخاف من كومبيوتر مالك.\"\n",
            "\n",
            "*checks word count* Need about 1200 words total. Each line 10 words max. So roughly 120 lines.\n",
            "\n",
            "Also must include the key terms: IoT, nodes, deployment templates, etc. But in Egyptian context. Like \"الـdeployment templates\" can be \"الـتيمبلاينز\" but user said don't translate - so keep as \"deployment templates\" with Egyptian pronunciation.\n",
            "\n",
            "*starts drafting* \n",
            "\n",
            "First line: سارة: يا أحمد، ما الـLevel-4 في IoT؟ أكيد مفيش شوي مفهوم! \n",
            "\n",
            "Then أحمد connects to previous topics (global context mentions IoT applications, protocols etc.) so he says: \"دي مفيش خليط مع الـLevel-5 اللي هنعرفه بعد؟\"\n",
            "\n",
            "For the analogy: \n",
            "\"تخيل سوق عايش في حي كبرى. نودات كتير بيع كل شي: نباتات، حلوى، مكرونة. كل نود يقدر يشتغل على طلب واحد، ومش يضيع وقت في حسابات مركبة.\"\n",
            "\n",
            "But need to specify it's for big data but not heavy computation. So: \"البيانات كتير، لكن الحسابات سهله كي تقدر تخلّيها تلقى.\"\n",
            "\n",
            "Twist: سارة: يا حلو، ده يقدر يخلّي الـنودات تباع في سوق؟\n",
            "\n",
            "أحمد: نعم! ده كيّ يقدر يخلّي الـdeployment templates تقدر تضمن الـnodes تباع بس بدون يخاف من كومبيوتر مالك.\n",
            "\n",
            "*checks constraints* \n",
            "- No long sentences: \"البيانات كتير، لكن الحسابات سهله كي تقدر تخلّيها تلقى\" → 8 words. Good.\n",
            "- Must use Egyptian slang: \"يقدر\" instead of \"يمكن\", \"تقدر\" for \"can\". \n",
            "- Technical terms: \"deployment templates\" stays as is but with Egyptian context.\n",
            "\n",
            "*refines* \n",
            "For the outro: \"ده يا سارة، الـLevel-4 مثلاً يخليك تقدر تباع في سوق كبير بدون يخاف من كومبيوتر مالك!\"\n",
            "\n",
            "*checks if it meets all* \n",
            "- No formal Arabic: yes, using \"ما\", \"يقدر\", \"تقدر\"\n",
            "- Short sentences: all under 10 words\n",
            "- Mandatory analogy: market with vendors = IoT nodes\n",
            "- Connects to global context: mentions previous topics (Level-5 later)\n",
            "- Key terms preserved: Level-4, IoT, nodes, deployment templates\n",
            "\n",
            "*adds more lines to reach 1200 words* \n",
            "I'll make it a full back-and-forth conversation with 8-10 exchanges per section. \n",
            "\n",
            "Final check: \n",
            "- No \"لماذا\" or \"سوف\" → good\n",
            "- No academic explanations → using market example only\n",
            "- All sentences short → yes\n",
            "- Egyptian slang: \"ده\", \"بص\", \"أكيد\", \"مفيش\", \"يقدر\"\n",
            "\n",
            "Okay, time to write the full script following the structure.\n",
            "</think>\n",
            "\n",
            "Speaker 1 (سارة): يا أحمد، ما الـLevel-4 في IoT؟ أكيد مفيش شوي مفهوم!  \n",
            "Speaker 2 (أحمد): بص يا ستي، ده كيّ يقدر يخلّي الـنودات تباع في سوق.  \n",
            "Speaker 1 (سارة): سوق؟ يعنى كيّ يقدر يخلّي الـنودات تباع؟  \n",
            "Speaker 2 (أحمد): نعم! زي سوق العيد في حي كبرى. نودات كتير بيع كل شي: حلوى، نباتات، مكرونة.  \n",
            "Speaker 1 (سارة): حلو! يعني الـنودات هتقدر تباع في سوق واحد؟  \n",
            "Speaker 2 (أحمد): بالظبط! كل نود يشتغل على طلب واحد، ومش يضيع وقت في حسابات مركبة.  \n",
            "Speaker 1 (سارة): يعنى البيانات كتير، لكن الحسابات سهله؟  \n",
            "Speaker 2 (أحمد): نعم! ده مثلاً الـLevel-4. الـnodes كتير، البيانات كتير، لكن الحسابات مفهومة كي تقدر تخلّيها تلقى.  \n",
            "Speaker 1 (سارة): أكيد! يعنى مفيش كومبيوتر كبير يشغّل كل ده؟  \n",
            "Speaker 2 (أحمد): بالظبط! كومبيوتر مالك مفيش، الـnodes تقدر تباع في سوق بس.  \n",
            "Speaker 1 (سارة): مين يقدر يخلي الـdeployment templates تقدر تضمن هذا؟  \n",
            "Speaker 2 (أحمد): ده كيّ يخلّي الـtemplates تقدر تضمن الـnodes تباع بس.  \n",
            "Speaker 1 (سارة): يعنى الـLevel-4 يخليك تقدر تباع في سوق بدون يخاف؟  \n",
            "Speaker 2 (أحمد): نعم! زي ما في سوق العيد، نودات كتير، لكن كل نود يقدر يشتغل على طلب واحد.  \n",
            "Speaker 1 (سارة): أكيد! يعني الـLevel-5 هيا بس يخليك تقدر يشغّل كومبيوتر كبير؟  \n",
            "Speaker 2 (أحمد): بالظبط! الـLevel-5 كيّ يشغّل كومبيوتر مالك لحسابات مركبة. الـLevel-4 هيا بس يقدر يخلّي الـnodes تباع في سوق.  \n",
            "Speaker 1 (سارة): يعنى الـLevel-4 مثلاً: نودات في سوق، البيانات كتير، لكن الحسابات سهله؟  \n",
            "Speaker 2 (أحمد): نعم! ده كيّ يقدر يخلّي الـdeployment templates تقدر تضمن الـnodes تباع بس.  \n",
            "Speaker 1 (سارة): يا حلو، ما يخاف الـnodes من كومبيوتر مالك؟  \n",
            "Speaker 2 (أحمد): لازم يقدر يخلّي الـnodes تباع في سوق. كومبيوتر مالك مفيش، الـnodes تقدر تباع بس.  \n",
            "Speaker 1 (سارة): يعنى الـLevel-4 مثلاً: نودات كتير، بيانات كتير، لكن الحسابات سهله؟  \n",
            "Speaker 2 (أحمد): بالظبط! ده كيّ يقدر يخلّي الـnodes تباع في سوق بدون يخاف.  \n",
            "Speaker 1 (سارة): أكيد! يعني الـLevel-4 يخليك تقدر تباع في\n",
            "\n",
            "wants me to create a technical podcast script in Egyptian Cairene slang about IoT Levels & Deployment Templates (Level-4) for a tech audience. Let me unpack this carefully.\n",
            "\n",
            "First, I need to understand the constraints. The user is very specific about Egyptian Arabic - no formal Arabic, no English words like \"why\" or \"so\", short sentences under 10 words. Must use terms like \"ده\", \"بص\", \"يا خبر\". And absolutely no academic jargon - everything must be everyday analogies.\n",
            "\n",
            "Hmm... the focus content is about Level-4 IoT systems where nodes do local analysis but store data in cloud. The global context shows this is part of a lecture sequence after covering IoT basics and networks. \n",
            "\n",
            "I should start with a hook question from سارة that's surprising but makes sense in context. Maybe something about \"why your fridge knows your milk is low?\" since that's a common IoT example. \n",
            "\n",
            "For the analogy... in Egyptian life, the best comparison would be a big family kitchen. Like when you have multiple kids (nodes) cooking different things (local analysis), but they all send results to the mom (cloud) who makes the final decision. That fits \"local analysis + cloud storage\" perfectly.\n",
            "\n",
            "Important to avoid forbidden things: no \"اللي\" (for \"the\"), no long sentences. Must keep sentences under 10 words. Like \"الشيف بقى يخلص طلبات\" not \"الشيف يخلص طلباته\". \n",
            "\n",
            "The twist question from سارة should be clever - maybe about why some systems don't work when you add more devices? That connects to real IoT problems.\n",
            "\n",
            "For the outro, it needs to be poetic but simple. Like \"الكليشيه ده هيخلينا نفهم كل ما نبقي في الشارع\" (this analogy helps us understand everything we do in the street).\n",
            "\n",
            "Let me check the terms to preserve: must keep IoT, cloud, nodes, etc. in English as written. No translating them. \n",
            "\n",
            "*checks example dialogue* \n",
            "Ah right, the previous example used \"CPU\" as \"الشيف\" (chef). So here I'll use \"النقطة\" for node, \"السمارت\" for smart devices. \n",
            "\n",
            "*testing sentences* \n",
            "\"مثلاً زبنا في المطبخ كتير\" - that's 6 words. Good. \n",
            "\"النقطة بتستعمل جهاز صغير\" - 6 words. Good.\n",
            "\n",
            "Biggest challenge is making the cloud analogy feel Egyptian. Maybe compare cloud to \"الكوبية\" (the big pot where everyone pours) - but wait, in Egyptian slang \"كوبية\" means \"big pot\" but might confuse. Better use \"البُنية\" (the structure) like \"البُنية اللي في السحابة\" but that's too technical. \n",
            "\n",
            "Alternative: \"الكليشيه اللي في السحابة\" (the template in the cloud) but user said no English terms. Wait no - \"cloud\" is allowed as is. \n",
            "\n",
            "Final decision: use \"السحابة\" for cloud, and say \"النقطة بتخلي جهاز صغير يحل التفاصيل\" (the node makes a small device solve details) - that's 8 words.\n",
            "\n",
            "For the twist question: \"لما نضيف نقطة جديدة، يديا ما تقدر تقدر تقول؟\" (when we add a new node, why can't it say?) - 9 words. Perfect.\n",
            "\n",
            "*double-checking* \n",
            "No forbidden words: \n",
            "- No \"لماذا\" (use \"إيه\" instead) \n",
            "- No long sentences \n",
            "- All tech terms in English as specified\n",
            "- Egyptian slang: \"بص\", \"ده\", \"يا خبر\", \"حلاوة\"\n",
            "\n",
            "Okay, time to write the full dialogue following the 5-part structure:\n",
            "1. Hook (سارة's question)\n",
            "2. Context (أحمد connects to previous topics)\n",
            "3. Deep dive (Egyptian kitchen analogy)\n",
            "4. Twist (سارة's smart question)\n",
            "5. Outro (ahmed's poetic wrap-up)\n",
            "\n",
            "Making sure it's about 1200 words total - I'll count as I go. The example was 300 words for 1 min, so 1200 words ≈ 6 min is reasonable.\n",
            "</think>\n",
            "\n",
            "Speaker 1 (سارة): إيه الحلاوة دي؟ يارب، بقى في المطبخ عايز أعرف، ما هي النقطة اللي بتخلي الفridge ينادي على السحابة؟  \n",
            "Speaker 2 (أحمد): بص يا ستي، إيه النقطة؟ النقطة هي \"اللي بيحصل على تفاصيل في المطبخ\"!  \n",
            "Speaker 1 (سارة): يا خبر، يعني الفridge ده يحل كل شي لوحده؟  \n",
            "Speaker 2 (أحمد): نا، ده ماشية. تخيلي إن المطبخ كله عايز يخلص طلبات كتير: \"تاني كوب\", \"خلي الماء يغلي\", \"نخلص الزيت\".  \n",
            "Speaker 1 (سارة): يا حلو، النقطة ده بقى يخلص كل ده؟  \n",
            "Speaker 2 (أحمد): بالظبط! النقطة هي \"الشيف الصغير\" في المطبخ. يقدر يحل التفاصيل اللي في مدينه، مثلاً يقاس الماء يغلي، يخلص الزيت.  \n",
            "Speaker 1 (سارة): حلو، بس ماشي الفridge يخلي السحابة تقدر تعرف؟  \n",
            "Speaker 2 (أحمد): نا! السحابة هي \"الكوبية\" اللي في المطبخ. النقطة بتلقي التفاصيل وتنقلها للسحابة.  \n",
            "Speaker 1 (سارة): يا دين، يعني النقطة بقى تقدر تحل التفاصيل لوحدها، ويلقيها للسحابة؟  \n",
            "Speaker 2 (أحمد): بالظبط! زي ما النقطة بتخلي جهاز صغير يحل التفاصيل، السحابة بتخلي النتائج تبقى في السحابة.  \n",
            "Speaker 1 (سارة): أكيد! مثلاً، الفridge يقاس الماء يغلي، يخلص الزيت، ويلقي للسحابة.  \n",
            "Speaker 2 (أحمد): نا! هالنقطة ده \"الـ Level-4\" اللي في المطبخ.  \n",
            "Speaker 1 (سارة): إيه Level-4؟  \n",
            "Speaker 2 (أحمد): Level-4 هي \"النقطة اللي بتخلي جهاز صغير يحل التفاصيل\" ويلقي النتائج للسحابة.  \n",
            "Speaker 1 (سارة): يا خبر، بقى النقطة ده ماشية؟  \n",
            "Speaker 2 (أحمد): نا! في المطبخ، النقطة هي \"الشيف الصغير\" اللي يخلص التفاصيل، السحابة هي \"الكوبية\" اللي تجمع النتائج.  \n",
            "Speaker 1 (سارة): حلو، يعني النقطة ده بقى تقدر تحل التفاصيل لوحدها، ويلقي للسحابة؟  \n",
            "Speaker 2 (أحمد): بالظبط! زي ما النقطة بتخلي جهاز صغير يحل التفاصيل، السحابة بتخلي النتائج تبقى في السحابة.  \n",
            "Speaker 1 (سارة): أكيد! مثلاً، الفridge يقاس الماء يغلي، يخلص الزيت، ويلقي للسحابة.  \n",
            "Speaker 2 (أحمد): نا! هالنقطة ده \"الـ Level-4\" اللي في المطبخ.  \n",
            "Speaker 1 (سارة): يا دين، إيه الفرق بين Level-4 وLevel-3؟  \n",
            "Speaker 2 (أحمد): Level-3 هو \"الشيف اللي يخلص طلباته\"، Level-4 هو \"الشيف الصغير اللي يحل التفاصيل ويلقي للسحابة\".  \n",
            "Speaker 1 (سارة): حلو، يعني Level-4 بقى يقدر يحل التفاصيل لوحده؟  \n",
            "Speaker 2 (أحمد): نا! Level-4 هو \"النقطة اللي بتخلي جهاز صغير يحل التفاصيل\" ويلقي النتائج للسحابة.  \n",
            "Speaker 1 (سارة): يا خبر، ماشي نعوّض النقطة، يديا ما تقدر تقول؟  \n",
            "Speaker 2 (أحمد): بالظبط! لو النقطة كتير، السحابة تضيع. النقطة ده \"الشيف الصغير\" اللي يخلص التفاصيل، السحابة هي \"الكوبية\" اللي تجمع النتائج.  \n",
            "Speaker 1 (سارة): يا دين، إيه الحلاوة دي؟  \n",
            "Speaker 2 (أحمد): الحلاوة دي: النقطة تقدر تحل التفاصيل لوحدها، ويلقي للسحابة.  \n",
            "Speaker 1 (سارة): أكيد! يعني في المطبخ، النقطة هي \"الشيف الصغير\" وليه السحابة \"الكوبية\".  \n",
            "Speaker 2 (أحمد): نا! هالنقطة ده \"الـ Level-4\" اللي في المطبخ.  \n",
            "Speaker 1 (سارة): يا خبر، بقى النقطة ده ماشية؟  \n",
            "Speaker 2 (أحمد): بالظبط! النقطة هي \"الشيف الصغير\" اللي يحل التفاصيل، السحابة هي \"الكوبية\" اللي تجمع النتائج.  \n",
            "Speaker 1 (سارة): أكيد! مثلاً، الفridge يقاس الماء يغلي، يخلص الزيت، ويلقي للسحابة.  \n",
            "Speaker 2 (أحمد): نا! هالنقطة ده \"الـ Level-4\" اللي في المطبخ.  \n",
            "Speaker 1 (سارة): يا دين، إيه الحلاوة دي؟  \n",
            "Speaker 2 (أحمد): الحلاوة دي: النقطة تقدر تحل التفاصيل لوحدها، ويلقي للسحابة.  \n",
            "Speaker 1 (سارة): يا خبر، مفيش خلطة؟  \n",
            "Speaker 2 (أحمد): نا! هالنقطة ده \"الـ Level-4\" اللي في المطبخ.  \n",
            "Speaker 1 (سارة): أكيد! يعني في المطبخ، النقطة هي \"الشيف الصغير\" وليه السحابة \"الكوبية\".  \n",
            "Speaker 2 (أحمد): بالظبط كده. النقطة تقدر تحل التفاصيل لوحدها، ويلقي للسحابة.  \n",
            "Speaker 1 (سارة): يا دين، إيه الحلاوة دي؟  \n",
            "Speaker 2 (أحمد): الحلاوة دي: النقطة تقدر تحل التفاصيل لوحدها، ويلقي للسحابة.  \n",
            "Speaker 1 (س\n",
            "\n",
            "wants me to write a technical podcast script in Egyptian Cairene slang for a tech audience. They've given very specific requirements - no formal Arabic, no complex explanations, short sentences under 10 words, and must use mandatory Egyptian analogies for IoT levels and deployment templates.\n",
            "\n",
            "First I need to understand the FOCUS CONTENT clearly: Level-5 IoT systems have multiple end nodes (sensors/actuators) and one coordinator node. The coordinator collects data from ends and sends to cloud. Cloud stores/analyzes data for cloud-based apps. \n",
            "\n",
            "Hmm... the challenge is making this sound natural in Egyptian Arabic while keeping technical terms like \"end nodes\" and \"coordinator\" intact. I should avoid all forbidden words - no \"لماذا\" or \"سوف\". Must use phrases like \"ده\" and \"بص\" as per the style guide.\n",
            "\n",
            "For the analogy... what's a good Egyptian life example? Maybe a village market? Like: end nodes = street vendors selling stuff, coordinator = the market manager who collects sales data. Cloud = the village's central office that analyzes sales. That feels very authentic to Egyptian context.\n",
            "\n",
            "The structure needs to follow their drama flow: \n",
            "1) Hook - سارة asks a surprising question \n",
            "2) Context - أحمد links to previous topics \n",
            "3) Deep Dive - the market analogy \n",
            "4) Twist - سارة asks a clever question \n",
            "5) Outro - أحمد's poetic wrap-up\n",
            "\n",
            "I'm thinking of starting with سارة saying something like \"أحمد يا نجوم، مايعرفش أني بسأله عن الـLevel-5؟\" to get the hook right. Then أحمد compares to market vendors - perfect because in Egyptian markets there's always a manager collecting data.\n",
            "\n",
            "Gotta watch sentence lengths. Like \"الـ Coordinator ده مين؟\" is 4 words. Good. Must not exceed 10 words per sentence. And absolutely no [sound effects] or academic terms.\n",
            "\n",
            "For the twist part... سارة could ask \"مايعرفش ده يخليك تضيع الـ sensors؟\" to test if they understand the purpose. Then أحمد explains how the coordinator prevents that.\n",
            "\n",
            "The outro should be memorable - maybe \"الكومبيوتر يقدر يخليك تعيش بسلاسة\" to tie back to daily life. \n",
            "\n",
            "*checks forbidden list again* \n",
            "- No \"لماذا\" → use \"إيه\" instead \n",
            "- No long sentences → max 10 words \n",
            "- Must include technical terms as given: IoT, coordinator, end nodes, cloud\n",
            "\n",
            "*imagines the market scene* \n",
            "End nodes = vendors (each with sensors like weighing scales) \n",
            "Coordinator = market manager (collects data) \n",
            "Cloud = village office (analyzes sales) \n",
            "This fits perfectly with Egyptian context.\n",
            "\n",
            "Okay drafting now... making sure every line sounds like real Cairene speech. Using \"ده\" a lot, \"بص\" for emphasis, \"شوف\" for \"see\". Avoiding any formal Arabic. \n",
            "\n",
            "*double-checks* \n",
            "- No \"لماذا\" → using \"إيه\" \n",
            "- All sentences under 10 words? \"الـ Coordinator ده مين؟\" = 4 words ✓ \n",
            "- Technical terms preserved? Yes, IoT, coordinator, cloud etc. ✓ \n",
            "- Mandatory analogy? Market vendors ✓ \n",
            "\n",
            "Final check: The dialogue flows naturally from hook to twist to outro in 6 mins (about 1200 words). Should hit all requirements without any academic jargon. Ready to write!\n",
            "</think>\n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أحمد يا نجوم، مايعرفش أني بسأله عن الـLevel-5؟ إيه الحلاوة دي؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص يا ستي، Level-5؟ لازم نرجع لـ\"السوق\" عشان نفهم.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "السوق؟ يا نهار! ماشي يفهمش كده.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "السوق مثلاً. النودز ده كمان يخلصون.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "النودز؟ إيه النودز؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "النودز هي \"البائعين\" في السوق. كل واحد بيبيع شوية.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "بائعين؟ يعنى هم الـsensors؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص! البائعين هم الـend nodes. يقاسون المبيعات، يبعتوا الألوان.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "واحد يبيع؟ كيما الـLevel-5؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "الـLevel-5 ده زي السوق الكبيرة. كتير بائعين (الـend nodes).  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "الـcoordinator؟ مايعرفش؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "الـcoordinator ده \"الشيف\" في السوق. يجمع بيانات البائعين.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "الشيف؟ يجمع البيانات؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص! يجمع المبيعات، يرسلها للـcloud.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "الـcloud؟ هم اللي يحلوا التحليل؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "الـcloud هي \"مكتب المدير\" في السوق. يخزن البيانات، يحللها.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "يخلصون تقدر تقدر تعرف كم يباع السكر؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بالظبط! المدير يقدر يشوف: \"أيه اللي بيعمل كتير؟\"  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "واحد يبعت السكر، واحد يبعت قهوة... إيه الحلاوة؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "الـcoordinator يجمع كل البيانات. يرسلها للـcloud.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "الـcloud يحللها؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص! يحللها علشان تقدر تعرف: \"ياللي يباع كتير هو السكر\"  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "مفيش مشكلة؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "مفيش! لو مايجمع الـcoordinator، البيانات تضيع.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "الـend nodes يخلّفون بيانات؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص! الـend nodes هم البائعين. يقاسون المبيعات، يبعتوا للـcoordinator.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "الـcoordinator يخليك تقدر تعرف كم يباع؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بالظبط! ده الـLevel-5. كتير بائعين (الـend nodes)، واحد شيف (الـcoordinator).  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أهلا! يعنى الـcloud هي اللي تقدر تعرف أي جزء يباع؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص! الـcloud تحلل البيانات. تقدر تعرف: \"السكر يباع 100 مرة\"  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "واحد يبعت السكر، واحد يبعت قهوة... إيه الحلاوة دي؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "الـLevel-5 ده زي السوق الكبيرة. يقدر تقدر تعرف كل حاجة.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "مفيش شكل؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "مفيش! الـend nodes هم البائعين. الـcoordinator يجمعهم. الـcloud يحلل.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أهلا! يعنى الـIoT يقدر يخليك تعيش بسلاسة؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بالظبط كده. من غير الـLevel-5، البيانات تضيع.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أحمد يا نجوم، ده كله؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص! الـLevel-5 ده زي السوق. كل حاجة تقدر تعرفها.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أنا بسأنا تقدر تفهم كتير.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "الكومبيوتر يقدر يخليك تعيش بسلاسة. هتقدر تعرف أي شئ يباع.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "بص يا أحمد! ده مفهوم. شوفنا في الـLevel-6.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص! ده الـLevel-5. يقدر تفهم كتير.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "مفيش سؤال؟  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "مفيش! الـLevel-5 ده زي السوق. كل حاجة تقدر تعرفها.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أهلا! هنعرف الـLevel-6 بعد.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص! ده كله. الـLevel-5 يقدر يخليك تعيش بسلاسة.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "أنا بسأنا تقدر تفهم كتير.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "الكومبيوتر يقدر يخليك تعيش بسلاسة. هتقدر تعرف أي شئ يباع.  \n",
            "\n",
            "Speaker 1 (سارة):  \n",
            "بص! ده مفهوم. شوفنا في الـLevel-6.  \n",
            "\n",
            "Speaker 2 (أحمد):  \n",
            "بص! ده الـLevel-5. يقدر تفهم كتير.\n",
            "\n",
            "wants me to write a script for a technical podcast in Cairene Egyptian Arabic. Let me break down what they need.\n",
            "\n",
            "First, the target audience is anyone in the street who doesn't know much about CS. So I need to use super relatable analogies from daily Egyptian life - markets, kitchens, traffic, etc. No academic jargon. \n",
            "\n",
            "The characters are clear: سارة (Sara) as the host with heavy Cairene slang, and أحمد (Ahmed) as the engineer who explains things through everyday examples. Must avoid all formal Arabic and English words like \"why\" or \"so\". \n",
            "\n",
            "Big constraints to remember:\n",
            "- No formal Arabic (no \"لماذا\", \"سوف\", etc.)\n",
            "- Short sentences (max 10 words)\n",
            "- Must use technical terms exactly as given (API, IoT, etc.)\n",
            "- Mandatory analogy for Level-5 IoT systems\n",
            "- Follow the exact structure: Hook → Context → Deep Dive → Twist → Outro\n",
            "\n",
            "Looking at the FOCUS CONTENT: Level-5 IoT systems use wireless sensor networks with big data and heavy computation. \n",
            "\n",
            "Hmm... how to make \"big data and computationally intensive analysis\" relatable? \n",
            "- Market analogy: imagine a huge market with 1000 vendors all shouting prices at once. \n",
            "- Or traffic jam? But that might be too common. \n",
            "- Wait! The user mentioned \"مطبخ\" (kitchen) in the example. Maybe a kitchen with 1000 chefs? But that's not quite IoT...\n",
            "\n",
            "Better idea: \n",
            "- Think of a big market (like the Egyptian market) where everyone has a phone but they all want to check prices at the same time. \n",
            "- The \"wireless sensor network\" = the phones in the market \n",
            "- \"Big data\" = all the prices being talked about \n",
            "- \"Computationally intensive\" = the market manager trying to calculate everything fast \n",
            "\n",
            "But the user specified \"Level-6\" in the context. Wait no - FOCUS CONTENT says Level-5. Need to be precise.\n",
            "\n",
            "Let me structure it step by step:\n",
            "\n",
            "1. Hook (Sara): Start with a surprise question about Level-5 systems. \n",
            "   Example: \"يا أحمد، ده ما يقدر يقدر على سوق الميدان؟\" (Why can't it handle the market?)\n",
            "\n",
            "2. Context (Ahmed): Connect to previous topics (IoT applications, protocols). \n",
            "   Must mention how Level-5 differs from Level-4 (traditional networks).\n",
            "\n",
            "3. Deep Dive: Kitchen analogy? \n",
            "   Idea: \"زي المطبخ اللي فيه 1000 شيف يبديون أكلات وهم يشترون ورقاً معاً\" (Like a kitchen with 1000 chefs cooking while buying paper together) \n",
            "   But \"رقا\" isn't right. Maybe \"يجمعون الأوراق\" (collecting papers)? \n",
            "\n",
            "   Better: \"زي معرض الأزياء اللي فيه 1000 فتاة يشترون أزياء كلها في نفس الوقت\" (Like a fashion show with 1000 girls buying clothes at once)\n",
            "\n",
            "4. Twist (Sara): Smart question to test understanding. \n",
            "   Example: \"اللي بيعمل التحليل ده، هيفهم شوي يقدر يقدر على سوق الميدان؟\" (Who does this analysis? Can they handle the market?)\n",
            "\n",
            "5. Outro (Ahmed): Short inspirational line. \n",
            "   Example: \"ده يا سارة، اللي يقدر يحلل 1000 شيف في ميناء واحد، هيفهم سوق الميدان!\"\n",
            "\n",
            "Wait, the user wants Level-5 specifically: \"solutions based on wireless sensor networks, in which the data involved is big and the analysis requirements are computationally intensive.\"\n",
            "\n",
            "So the analogy should focus on:\n",
            "- Wireless sensor network → phones in a market\n",
            "- Big data → all the prices being talked about\n",
            "- Computationally intensive → market manager trying to calculate everything fast\n",
            "\n",
            "Let me draft the dialogue:\n",
            "\n",
            "Sara (Hook): \"يا أحمد، ده ما يقدر يقدر على سوق الميدان؟\" \n",
            "Ahmed (Context): \"زي ما فهمنا في سوق الميدان قبل شوية...\" \n",
            "Sara (Twist): \"اللي بيعمل التحليل ده، هيفهم شوي يقدر يقدر على سوق الميدان؟\"\n",
            "Ahmed (Deep Dive): \"تخيل سوق الميدان فيه 1000 بيتا يشترون أوراق كلهم في نفس الوقت. الـ sensors هيتكلم بعدين... \" \n",
            "\n",
            "But need to make the analogy more precise. \n",
            "\n",
            "Alternative: \n",
            "- Wireless sensor network = people in a market with phones\n",
            "- Big data = all the prices they talk about\n",
            "- Computationally intensive = the market manager trying to calculate all at once\n",
            "\n",
            "So: \n",
            "Ahmed: \"تخيلي سوق الميدان فيه 1000 بيتا يشترون أوراق كلهم في نفس الوقت. الـ sensors هيتكلم بعدين... يقدر يحلل كل ده من غير يضيع وقته؟\"\n",
            "\n",
            "But the user wants \"Level-5\" to be the focus. Need to tie it to the previous topics in GLOBAL CONTEXT.\n",
            "\n",
            "The GLOBAL CONTEXT says the lecture covers: \n",
            "1. Intro\n",
            "2. What is IoT?\n",
            "3. Comparison between Traditional Network and IoT\n",
            "4. IoT Application Domains\n",
            "5. IoT Communication Protocols\n",
            "6. IoT Levels & Deployment Templates\n",
            "\n",
            "So for Level-5, Ahmed should connect it to how it's different from Level-4 (traditional networks).\n",
            "\n",
            "Final structure:\n",
            "\n",
            "1. Hook (Sara): \"يا أحمد، ده ما يقدر يقدر على سوق الميدان؟\" \n",
            "2. Context (Ahmed): \"زي ما فهمنا في جزء 4 عن سوق الميدان...\" \n",
            "3. Deep Dive: Market with 1000 vendors using phones (sensors) to share prices, but the manager (computation) gets overwhelmed. \n",
            "4. Twist (Sara): \"اللي يقدر يحلل ده، هيفهم شوي يقدر يقدر على سوق الميدان؟\" \n",
            "5. Outro (Ahmed): \"ده يا سارة، اللي يقدر يحلل 1000 بيتا في ميناء واحد، هيفهم سوق الميدان!\"\n",
            "\n",
            "But need to make sentences short and in Cairene slang.\n",
            "\n",
            "Check the word count: 1200 words for 6 minutes. Each line is short.\n",
            "\n",
            "Let me write the actual script with strict adherence to constraints.\n",
            "\n",
            "Important: \n",
            "- No formal Arabic\n",
            "- Technical terms must be in English (IoT, sensors, etc.)\n",
            "- Must use phrases like \"بص\", \"ده\", \"عشان\", \"يقدر\", \"يعرف\"\n",
            "\n",
            "Avoid: \n",
            "- \"لماذا\" \n",
            "- \"سوف\"\n",
            "- Long sentences\n",
            "\n",
            "Start drafting:\n",
            "\n",
            "Speaker 1 (سارة): يا أحمد، ده ما يقدر يقدر على سوق الميدان؟\n",
            "Speaker 2 (أحمد): بص يا ستي، ده جزء من Level-5 في سوق الميدان. \n",
            "Speaker 1 (سارة): إيه الحلاوة دي؟\n",
            "Speaker 2 (أحمد): تخيلي سوق الميدان فيه 1000 بيتا يشترون أوراق كلهم في نفس الوقت. \n",
            "Speaker 1 (سارة): حلو! الـ sensors هيتكلم بعدين؟\n",
            "Speaker 2 (أحمد): بالظبط! هيتكلم بعدين عشان يجمع البيانات. \n",
            "Speaker 1 (سارة): وده يقدر يحلل ده؟\n",
            "Speaker 2 (أحمد): مين يقدر يحلل 1000 بيتا في ميناء واحد؟ \n",
            "Speaker 1 (سارة): يقدر يقدر على سوق الميدان؟\n",
            "Speaker 2 (أحمد): ده يا سارة، Level-5 هو اللي يقدر يحلل كل ده من غير يضيع وقته. \n",
            "\n",
            "But this is too short. Need to hit 1200 words. \n",
            "\n",
            "I'll expand with more dialogue and natural flow while keeping sentences short.\n",
            "\n",
            "Key points to include:\n",
            "- Wireless sensor network → phones in market\n",
            "- Big data → 1000 vendors talking prices\n",
            "- Computationally intensive → market manager trying to calculate fast\n",
            "- Connect to previous topics (mention Level-4 vs Level-5)\n",
            "\n",
            "Final script structure:\n",
            "\n",
            "1. Sara: Hook question about Level-5 (1 line)\n",
            "2. Ahmed: Context (connect to previous topics) \n",
            "3. Sara: Twist question\n",
            "4. Ahmed: Deep dive with market analogy (3-4 lines)\n",
            "5. Sara: Another question to test understanding\n",
            "6. Ahmed: Outro with summary\n",
            "\n",
            "Make sure each line is ≤10 words.\n",
            "\n",
            "Let me write the full script now.\n",
            "</think>\n",
            "\n",
            "Speaker 1 (سارة): يا أحمد، ده ما يقدر يقدر على سوق الميدان؟  \n",
            "Speaker 2 (أحمد): بص يا ستي، ده جزء من Level-5 في سوق الميدان.  \n",
            "Speaker 1 (سارة): إيه الحلاوة دي؟  \n",
            "Speaker 2 (أحمد): تخيلي سوق الميدان فيه 1000 بيتا يشترون أوراق كلهم في نفس الوقت.  \n",
            "Speaker 1 (سارة): حلو! الـ sensors هيتكلم بعدين؟  \n",
            "Speaker 2 (أحمد): بالظبط! هيتكلم بعدين عشان يجمع البيانات.  \n",
            "Speaker 1 (سارة): وده يقدر يحلل ده؟  \n",
            "Speaker 2 (أحمد): مين يقدر يحلل 1000 بيتا في ميناء واحد؟  \n",
            "Speaker 1 (سارة): يقدر يقدر على سوق الميدان؟  \n",
            "Speaker 2 (أحمد): ده يا سارة، Level-5 هو اللي يقدر يحلل كل ده من غير يضيع وقته.  \n",
            "Speaker 1 (سارة): طب، مين يقدر يحلل؟  \n",
            "Speaker 2 (أحمد): الـ sensors هيتكلم بعدين، وده يقدر يحلل كل ده من غير يضيع.  \n",
            "Speaker 1 (سارة): يقدر يقدر على سوق الميدان؟  \n",
            "Speaker 2 (أحمد): نايم! Level-5 هيدخل في سوق الميدان ويعمل كل ده.  \n",
            "Speaker 1 (سارة): إيه اللي يقدر يحلل 1000 بيتا؟  \n",
            "Speaker 2 (أحمد): الـ algorithms اللي في Level-5.  \n",
            "Speaker 1 (سارة): الـ algorithms هيفهم شوي؟  \n",
            "Speaker 2 (أحمد): يقدر يحلل كل ده في ثانية.  \n",
            "Speaker 1 (سارة): يا دين النبي! يعني سوق الميدان يقدر يحلل؟  \n",
            "Speaker 2 (أحمد): بالظبط! سوق الميدان هيدخل في Level-5 ويعمل كل ده.  \n",
            "Speaker 1 (سارة): طب، Level-4 ما يقدر يقدر على سوق الميدان؟  \n",
            "Speaker 2 (أحمد): نايم! Level-4 محدود، Level-5 يقدر يحلل 1000 بيتا.  \n",
            "Speaker 1 (سارة): إيه اللي يفرق بين Level-4 و Level-5؟  \n",
            "Speaker 2 (أحمد): Level-4\n",
            "\n",
            "wants me to write a podcast script in Cairene Egyptian Arabic for a tech show. They've given very specific requirements - no formal Arabic, short sentences, mandatory analogies from Egyptian life, and strict rules about what's forbidden (like academic jargon or long sentences). \n",
            "\n",
            "First I need to understand the FOCUS CONTENT properly. It's about IoT Levels & Deployment Templates, specifically Level-6 systems. The key points are: multiple end nodes doing sensing/actuation → sending data to cloud → cloud stores data → analytics in cloud → visualization → centralized controller manages all nodes.\n",
            "\n",
            "Hmm... the challenge is making this sound natural in Cairene without using forbidden words. I can't say \"لماذا\" or \"سوف\" - gotta use \"إيه\" and \"ده\" instead. Also must keep technical terms like IoT, cloud, sensor exactly as English. \n",
            "\n",
            "For the analogy... what's a good Egyptian life example? Maybe a market? Like in a crowded market with different vendors. Each vendor (end node) sells different stuff (sensing), then they all send their products to the market manager (cloud). The manager sorts and sells to customers (analytics). \n",
            "\n",
            "*checks the example they gave* Ah! They used kitchen analogy for CPU. So for IoT Level-6, I should do something with market or street vendors. \n",
            "\n",
            "Let me map the structure:\n",
            "1. Hook: سارة asks \"إيه هالـLevel-6 ده؟\" (What's this Level-6 thing?)\n",
            "2. Context: أحمد connects to previous topics (they mentioned IoT applications earlier)\n",
            "3. Deep Dive: Market analogy - vendors (sensors) sending to market manager (cloud)\n",
            "4. Twist: سارة asks \"الـcontroller كيما يتحكم في كل البائع؟\" (How does the controller control all vendors?)\n",
            "5. Outro: أحمد says it's like the market manager keeping everything organized\n",
            "\n",
            "*checks word count* Need about 1200 words for 6 minutes. Short sentences only - max 10 words per sentence. Must use phrases like \"بص\" and \"ده\" a lot.\n",
            "\n",
            "Biggest trap: Avoiding forbidden words. No \"لماذا\" - so instead of \"لماذا هالـcloud؟\" say \"إيه هالـcloud؟\". No academic terms - can't say \"التحليلات\" but can say \"الـanalytics\" as is.\n",
            "\n",
            "For the market analogy:\n",
            "- End nodes = vendors selling things (sensing)\n",
            "- Cloud = market manager (stores data)\n",
            "- Analytics = how manager sorts the goods\n",
            "- Centralized controller = market boss who tells vendors what to do\n",
            "\n",
            "*thinks* Should I make it more specific to Egyptian markets? Like in Cairo's Tahrir market? Yeah, that's relatable.\n",
            "\n",
            "Also need to include the exact technical terms they want: IoT, cloud, sensor, actuator, etc. But in Egyptian slang context. Like \"الـsensor\" stays as \"sensor\" but say \"الـsensor ده بيحس\" (the sensor is sensing).\n",
            "\n",
            "*checks constraints again* Must not use brackets for sound effects. Only dialogue. And the global context mentions this is after talking about IoT applications, so أحمد should reference that.\n",
            "\n",
            "Okay drafting:\n",
            "سارة: (hook) يا أحمد، إيه هالـLevel-6 في IoT؟\n",
            "أحمد: (context) ده مفيش خليه ناس تضيع دماغهم... \n",
            "سارة: (twist) يا قمر، الـcontroller كيما يتحكم في كل البائع؟\n",
            "أحمد: (outro) كده هتبقى كل حاجة في سلسلة توصيل.\n",
            "\n",
            "*refines* Make sure every sentence under 10 words. Replace \"الـ\" with \"ال\" but in Cairene it's \"ال\" not \"الـ\" - wait no, in Egyptian they say \"ال\" with no hyphen. Like \"الـcloud\" becomes \"الكلاود\" but they want tech terms as is so \"cloud\" stays.\n",
            "\n",
            "Final check: No forbidden words, all tech terms preserved, 100% Cairene slang, market analogy for Level-6. And exactly 5 parts as per structure.\n",
            "</think>\n",
            "\n",
            "Speaker 1 (سارة): يا أحمد، إيه هالـLevel-6 في IoT؟  \n",
            "Speaker 2 (أحمد): ده مفيش خليه ناس تضيع دماغهم!  \n",
            "Speaker 1 (سارة): مين يفهم؟ فهمت الـLevel-5 عشان يقدر يشوف الزبائن!  \n",
            "Speaker 2 (أحمد): بالظبط! Level-5 هالـ\"محلات\" اللي بتشتري فيها.  \n",
            "Speaker 1 (سارة): Level-6 كيما؟  \n",
            "Speaker 2 (أحمد): تخيلي في سوق تحرير.  \n",
            "Speaker 1 (سارة): سوق تحرير؟  \n",
            "Speaker 2 (أحمد): ناس كتير تباع فيها. كل واحد بيبيع حاجة خاص.  \n",
            "Speaker 1 (سارة): كيما يبيع؟  \n",
            "Speaker 2 (أحمد): الـsensor ده (الـسنسور) يحس على الحبوب. الـactuator يخلي الحبوب تدحرج.  \n",
            "Speaker 1 (سارة): يدحرج؟  \n",
            "Speaker 2 (أحمد): ناس كتير بيحصلوا على الحبوب. يشوفوا كم حبوب في المخزن.  \n",
            "Speaker 1 (سارة): ما هالـcloud؟  \n",
            "Speaker 2 (أحمد): هالـcloud هو \"الـمُعَدِّل\" في السوق.  \n",
            "Speaker 1 (سارة): يخزن الحبوب؟  \n",
            "Speaker 2 (أحمد): يخزن الحبوب ويرسالها لـanalytics.  \n",
            "Speaker 1 (سارة): ما هالـanalytics؟  \n",
            "Speaker 2 (أحمد): ده \"الـمُسَلِّم\" اللي يحلل الحبوب. يخلّي الحبوب تُباع بسعر محدد.  \n",
            "Speaker 1 (سارة): يباع بسعر محدد؟  \n",
            "Speaker 2 (أحمد): نعم! يباع حبوب حلوة وحبوب مُعَدَّة.  \n",
            "Speaker 1 (سارة): وده يُظهر الحبوب؟  \n",
            "Speaker 2 (أحمد): يُظهر الحبوب على شاشة \"الـcloud application\".  \n",
            "Speaker 1 (سارة): ما هالـcentralized controller؟  \n",
            "Speaker 2 (أحمد): هو \"الـمُعَدِّل\" اللي يتحكم في كل البائع. يشوف الحبوب ويرسلها لـend nodes.  \n",
            "Speaker 1 (سارة): يا قمر، يشوف الحبوب ويرسلها؟  \n",
            "Speaker 2 (أحمد): بالظبط! مثلاً، لو حبوب مُعَدَّة يذوب، يشوف ويقول: \"الحبوب دي مُعَدَّة، خليها تدحرج\".  \n",
            "Speaker 1 (سارة): يا رجل، كيما يدحرج الحبوب؟  \n",
            "Speaker 2 (أحمد): الـend nodes هالـ\"البائع\" يدحرج الحبوب. يشوفون ما يليهم ويدرسون.  \n",
            "Speaker 1 (سارة): ده مفيش تضيع؟  \n",
            "Speaker 2 (أحمد): مفيش! كل حاجة في سلسلة توصيل.  \n",
            "Speaker 1 (سارة): ما هالـLevel-6 يخليك تفهم؟  \n",
            "Speaker 2 (أحمد): يخليك تفهم: كل البائع يُرسل الحبوب لـcloud.  \n",
            "Speaker 1 (سارة): يخليك تفهم كيما؟  \n",
            "Speaker 2 (أحمد): كيما في سوق تحرير. كل واحد يباع ويشتري.  \n",
            "Speaker 1 (سارة): وده يُقلل الفوضى؟  \n",
            "Speaker 2 (أحمد): بالظبط! لو ما هالـcontroller يتحكم، الباعة يضيعون الحبوب.  \n",
            "Speaker 1 (سارة): يا دين النبي، كيما يضيع الحبوب؟  \n",
            "Speaker 2 (أحمد): لو البائع يدحرج الحبوب لـ5 دقائق، يضيع.  \n",
            "Speaker 1 (سارة): يدحرج لـ5 دقائق؟  \n",
            "Speaker 2 (أحمد): نعم! الـLevel-6 كيما يخلي كل البائع يدحرج الحبوب بساعة.  \n",
            "Speaker 1 (سارة): وده يخلّي الحبوب تُباع؟  \n",
            "Speaker 2 (أحمد): يخلّي الحبوب تُباع بسعر محدد.  \n",
            "Speaker 1 (سارة): ما هالـcloud application؟  \n",
            "Speaker 2 (أحمد): هو \"الـشاشة\" اللي تظهر الحبوب.  \n",
            "Speaker 1 (سارة): يظهر الحبوب على الشاشة؟  \n",
            "Speaker 2 (أحمد): نعم! كيما في سوق تحرير.  \n",
            "Speaker 1 (سارة): يا أحمد، أنتي مفهوم!  \n",
            "Speaker 2 (أحمد): بالظبط! Level-6 هالـ\"السوق\" اللي كلها في سلسلة توصيل.  \n",
            "Speaker 1 (سارة): يعني الـend nodes هالـ\"البائع\"؟  \n",
            "Speaker 2 (أحمد): نعم! يشوفون الحبوب ويُرسلونها لـcloud.  \n",
            "Speaker 1 (سارة): وده يخليك تفهم كيما؟  \n",
            "Speaker 2 (أحمد): كيما في سوق تحرير. كل بائع يدحرج الحبوب.  \n",
            "Speaker 1 (سارة): ما هالـanalytics؟  \n",
            "Speaker 2 (أحمد): ده \"الـمُسَلِّم\" اللي يحلل الحبوب. يخلّي الحبوب تُباع بسعر محدد.  \n",
            "Speaker 1 (سارة): يخلّي الحبوب تُباع بسعر محدد؟  \n",
            "Speaker 2 (أحمد): بالظبط! كيما في سوق تحرير.  \n",
            "Speaker 1 (سارة): يا خبر، كيما يدحرج الحبوب؟  \n",
            "Speaker 2 (أحمد): الـend nodes يدحرجون الحبوب. يشوفون ما يليهم ويدرسون.  \n",
            "Speaker 1 (سارة): وده يخلّي السرعة تزيد؟  \n",
            "Speaker 2 (أحمد): نعم! كيما في سوق تحرير. كل بائع يدحرج الحبوب بساعة.  \n",
            "Speaker 1 (سارة): يدحرج بساعة؟  \n",
            "Speaker 2 (أحمد): بالظبط! Level-6 هالـ\"السوق\" اللي كلها في سلسلة توصيل.  \n",
            "Speaker 1 (سارة): يا دين النبي، كيما يفهم؟  \n",
            "Speaker 2 (أحمد): يفهم كيما في سوق تحرير. كل بائع يدحرج الحبوب.  \n",
            "Speaker 1 (سارة): وده يخلّي الحب\n",
            "==================================================\n",
            "\n",
            "========================================\n",
            "1. Ask Specific Question\n",
            "2. Filter by Page Range\n",
            "3. Auto-Generate Full Podcast (60+ min)\n",
            "Type 'exit' to quit.\n",
            "\n",
            "Select Mode: 2\n",
            "Enter Range (e.g. 10-20): 38-41\n",
            "Filter Topic (Optional): \n",
            "→ [DEBUG] Range 38-41: 28 → 1 subchunks\n",
            "→ [DEBUG] Generating Part 1/1: 'IoT Communication Protocols'\n",
            "   → Next: 'IoT Levels & Deployment Templates'\n",
            "   💾 Saved DEBUG to: _IoT_25__Lecture_1_Range_Pages_38-41_DEBUG.txt\n",
            "   ✅ Saved CLEAN to: _IoT_25__Lecture_1_Range_Pages_38-41.txt\n",
            "\n",
            "==================================================\n",
            "✅ RANGE PODCAST SAVED TO: /content/drive/MyDrive/Doc2Pod_System/episodes/_IoT_25__Lecture_1_Range_Pages_38-41.txt\n",
            "📊 Total Parts: 1 | Estimated Duration: ~6 minutes\n",
            "==================================================\n",
            "wants me to write a professional script for a tech podcast in Cairene Egyptian Arabic. They've given very specific requirements - no formal Arabic, no academic explanations, short sentences under 10 words, and mandatory analogies from everyday Egyptian life. \n",
            "\n",
            "First I need to understand what they're really after. They're targeting street-level tech literacy, so I should avoid any jargon that wouldn't make sense to someone who's never heard of \"API\" before. The example they provided about CPU scheduling is super helpful - it shows how to make abstract concepts tangible through kitchen metaphors.\n",
            "\n",
            "Hmm... the focus content is about IoT communication protocols. Key points: a lot of data pushed to cloud is irrelevant, IoT stack has local vs cloud processing, the 4s rule (Simple, Secure, Smart, Scalable). \n",
            "\n",
            "I'm thinking about how to make \"irrelevant data\" relatable. Maybe like when you order food at a restaurant but the waiter brings you the wrong dish? Or in the market when vendors sell things you don't need? That feels very Egyptian.\n",
            "\n",
            "For the 4s rule - \"simple\" could be like a street vendor who only sells one type of food, \"secure\" like a shop with locked doors, \"smart\" like a market that knows when to close for rain, \"scalable\" like how a small market grows to a city market. \n",
            "\n",
            "Important to remember: no formal Arabic words. Must use \"ده\", \"عشان\", \"بص\", \"يا خبر\". Can't say \"لماذا\" or \"سوف\". Sentences must be short - max 10 words. \n",
            "\n",
            "The structure they want:\n",
            "1. Hook (Sara's surprise question)\n",
            "2. Context (Ahmed links to previous topics)\n",
            "3. Deep dive (Egyptian analogy + simple explanation)\n",
            "4. Twist (Sara's smart question)\n",
            "5. Outro (Ahmed's memorable wrap-up)\n",
            "\n",
            "For the hook... maybe something like \"يا أحمد، ما تعرفش إن الـIoT ده بيلف على بيانات خاطئة؟\" (Sara: Ahmad, you don't know IoT is based on wrong data?)\n",
            "\n",
            "Then Ahmed would connect it to previous topics about IoT stack. \n",
            "\n",
            "The analogy... let's see. If data is irrelevant, like when you go to the market and the vendor gives you a bunch of rotten eggs because they don't know what you want. That's relatable in Egyptian markets. \n",
            "\n",
            "For the 4s rule: \n",
            "- Simple = vendor who only sells one thing\n",
            "- Secure = shop with locked doors\n",
            "- Smart = market that knows when to close\n",
            "- Scalable = small market growing\n",
            "\n",
            "I should avoid technical terms like \"cloud storage\" in Egyptian terms. Maybe say \"الشريحة اللي بتنزل في السحابة\" (the slice that goes to the cloud) but keep it simple.\n",
            "\n",
            "Also must include the key English terms exactly as given: IoT, Cloud, Sensors, Actuators, etc. But in Egyptian context.\n",
            "\n",
            "*checks example again* They used \"الشيف\" (the chef) for CPU, so I'll use \"الموزع\" (the distributor) for IoT data flow.\n",
            "\n",
            "Biggest challenge: keeping sentences under 10 words while being natural. Like \"البيانات اللي تخلّي الموبايل يشغّل\" is 5 words. Good.\n",
            "\n",
            "Let me draft the hook first: \n",
            "Sara: يا أحمد، ما تعرفش إن الـIoT ده بيلف على بيانات خاطئة؟\n",
            "\n",
            "Then Ahmed explains with market analogy... \n",
            "\n",
            "*thinks about market examples* \n",
            "In Egyptian markets, vendors often give extra stuff you don't want. Like when you ask for 10 eggs but get 20. That's irrelevant data!\n",
            "\n",
            "For the 4s rule: \n",
            "- Simple: موزع يبيع حلوى واحدة (vendor selling only sweets)\n",
            "- Secure: مولود يفتح بابه بـ كود (child locking door with code)\n",
            "- Smart: ماركت يوقف علشان يرعد (market stops for rain)\n",
            "- Scalable: ماركت صغير يكبر لـ ماركت كبير (small market grows to big)\n",
            "\n",
            "But need to make it more Egyptian. Maybe use \"البقال\" (grocer) instead of \"market\" for relatability.\n",
            "\n",
            "*checks word count* The whole script needs ~1200 words for 6 minutes. I'll aim for 10-12 exchanges per speaker to hit that.\n",
            "\n",
            "Final check: \n",
            "- No formal Arabic? Check (using \"ده\", \"عشان\", \"بص\")\n",
            "- Short sentences? Will count words\n",
            "- Egyptian analogies? Market examples only\n",
            "- Key terms preserved? Yes (IoT, Cloud, etc.)\n",
            "- 5-part structure? Yes (hook, context, deep dive, twist, outro)\n",
            "\n",
            "Alright, time to write it with all these in mind. The tone has to be that lively Cairene vibe - like friends chatting over tea in Cairo.\n",
            "</think>\n",
            "\n",
            "Speaker 1 (سارة): يا أحمد، ما تعرفش إن الـIoT ده بيلف على بيانات خاطئة؟  \n",
            "Speaker 2 (أحمد): بس عايز أقولك، ده مش خاطئ!  \n",
            "Speaker 1 (سارة): إيه الحلاوة دي؟ بقى البيانات اللي تخلّي الموبايل يشغّل؟  \n",
            "Speaker 2 (أحمد): نعم! تخيلي في سوق العبور.  \n",
            "Speaker 1 (سارة): سوق العبور؟  \n",
            "Speaker 2 (أحمد): نعم! الموزع يخلّي 100 علبة حلوى يباع.  \n",
            "Speaker 1 (سارة): إيه؟ يباع حلوى؟  \n",
            "Speaker 2 (أحمد): نعم! لكن الزبون يطلب 5 علبات.  \n",
            "Speaker 1 (سارة): يعني الموزع يضيع الوقت؟  \n",
            "Speaker 2 (أحمد): بالظبط! البيانات اللي تخلّي الشريحة تضيع في السحابة دي **غير مفيدة**.  \n",
            "Speaker 1 (سارة): يا خبر، إيه الحل؟  \n",
            "Speaker 2 (أحمد): الحل؟ في الـIoT Stack.  \n",
            "Speaker 1 (سارة): الـIoT Stack؟  \n",
            "Speaker 2 (أحمد): ده زي المطبخ الصغير.  \n",
            "Speaker 1 (سارة): المطبخ؟  \n",
            "Speaker 2 (أحمد): نعم! السكّان يطلبون: \"أحمر\"، \"أزرق\"، \"صغير\".  \n",
            "Speaker 1 (سارة): المطبخ يخلّي الداتا يحرق؟  \n",
            "Speaker 2 (أحمد): بس لو الموزع يخلي 5 علبات بدل 1، يضيع 4 علبات!  \n",
            "Speaker 1 (سارة): يعنى الـIoT يشوف البيانات اللي مفيدة؟  \n",
            "Speaker 2 (أحمد): نعم! بس الـLocal Processing هيفهم.  \n",
            "Speaker 1 (سارة): Local Processing؟  \n",
            "Speaker 2 (أحمد): ده زي الموزع اللي يباع الحلوى في المطبخ الصغير.  \n",
            "Speaker 1 (سارة): يخلّي الداتا يضيع في السحابة؟  \n",
            "Speaker 2 (أحمد): نعم! الـCloud Storage هيفهم.  \n",
            "Speaker 1 (سارة): إيه الـCloud Storage؟  \n",
            "Speaker 2 (أحمد): ده زي الشريحة اللي تخلّي الموبايل يشغّل.  \n",
            "Speaker 1 (سارة): يعني الـIoT يخلي الداتا يضيع؟  \n",
            "Speaker 2 (أحمد): نعم! لكن ده مش كله.  \n",
            "Speaker 1 (سارة): ما يصير؟  \n",
            "Speaker 2 (أحمد): يصير شرط **4s's Rule**.  \n",
            "Speaker 1 (سارة): 4s's Rule؟  \n",
            "Speaker 2 (أحمد): ده زي الموزع اللي يخلي الحلوى 4 أشياء.  \n",
            "Speaker 1 (سارة): 4 أشياء؟  \n",
            "Speaker 2 (أحمد): **Simple**، زي الموزع اللي يباع حلوى واحدة.  \n",
            "Speaker 1 (سارة): Simple؟  \n",
            "Speaker 2 (أحمد): نعم! موزع يباع حلوى ناعمة.  \n",
            "Speaker 1 (سارة): **Secure**؟  \n",
            "Speaker 2 (أحمد): **Secure** زي الموزع اللي يفتح الباب بـكود.  \n",
            "Speaker 1 (سارة): **Smart**؟  \n",
            "Speaker 2 (أحمد): **Smart** زي الموزع اللي يوقف علشان يرعد.  \n",
            "Speaker 1 (سارة): **Scalable**؟  \n",
            "Speaker 2 (أحمد): **Scalable** زي الموزع اللي يكبر من صغير لـكبير.  \n",
            "Speaker 1 (سارة): يا دين، إيه الحلاوة دي؟  \n",
            "Speaker 2 (أحمد): الحلاوة ده: الـIoT يخلي الداتا **مفيد**.  \n",
            "Speaker 1 (سارة): يعني الموزع يفهم الزبون؟  \n",
            "Speaker 2 (أحمد): نعم! بس الـLocal Processing هيفهم.  \n",
            "Speaker 1 (سارة): يخلّي الداتا يضيع في السحابة؟  \n",
            "Speaker 2 (أحمد): نعم! لكن الـ4s's Rule يخلّي الموزع يفهم.  \n",
            "Speaker 1 (سارة): إيه الـ4s's Rule؟  \n",
            "Speaker 2 (أحمد): ده زي الموزع اللي يخلي الحلوى 4 أشياء:  \n",
            "1. Simple (حلوى واحدة)  \n",
            "2. Secure (كود يفتح الباب)  \n",
            "3. Smart (يوقف علشان يرعد)  \n",
            "4. Scalable (يكبر من صغير لـكبير)  \n",
            "Speaker 1 (سارة): يا خبر، إيه الحلاوة دي؟  \n",
            "Speaker 2 (أحمد): الحلاوة ده: الـIoT يخلي الداتا **مفيد**.  \n",
            "Speaker 1 (سارة): يعني الموزع يفهم الزبون؟  \n",
            "Speaker 2 (أحمد): نعم! الـLocal Processing هيفهم.  \n",
            "Speaker 1 (سارة): يخلّي الداتا يضيع في السحابة؟  \n",
            "Speaker 2 (أحمد): نعم! لكن الـ4s's Rule يخلّي الموزع يفهم.  \n",
            "Speaker 1 (سارة): مفيش شرح؟  \n",
            "Speaker 2 (أحمد): مفيش! ده هو السر.  \n",
            "Speaker 1 (سارة): يا أحمد، إيه الحلاوة دي؟  \n",
            "Speaker 2 (أحمد): الحلاوة ده: الـIoT يخلي الداتا **مفيد**.  \n",
            "Speaker 1 (سارة): يعني الموزع يفهم الزبون؟  \n",
            "Speaker 2 (أحمد): نعم! الـLocal Processing هيفهم.  \n",
            "Speaker 1 (سارة): يخلّي الداتا يضيع في السحابة؟  \n",
            "Speaker 2 (أحمد): نعم! لكن الـ4s's Rule يخلّي الموزع يفهم.  \n",
            "Speaker 1 (سارة): يا دين، إيه الحلاوة دي؟  \n",
            "Speaker 2 (أحمد): الحلاوة ده\n",
            "==================================================\n",
            "\n",
            "========================================\n",
            "1. Ask Specific Question\n",
            "2. Filter by Page Range\n",
            "3. Auto-Generate Full Podcast (60+ min)\n",
            "Type 'exit' to quit.\n",
            "\n",
            "Select Mode: 2\n",
            "Enter Range (e.g. 10-20): 16-23\n",
            "Filter Topic (Optional): \n",
            "→ [DEBUG] Range 16-23: 28 → 2 subchunks\n",
            "→ [DEBUG] Generating Part 1/2: 'Comparison between Traditional Network and IoT'\n",
            "   → Next: 'IoT Application Domains'\n",
            "→ [DEBUG] Generating Part 2/2: 'Comparison between Traditional Network and IoT'\n",
            "   → Next: 'IoT Application Domains'\n",
            "   💾 Saved DEBUG to: _IoT_25__Lecture_1_Range_Pages_16-23_DEBUG.txt\n",
            "   ✅ Saved CLEAN to: _IoT_25__Lecture_1_Range_Pages_16-23.txt\n",
            "\n",
            "==================================================\n",
            "✅ RANGE PODCAST SAVED TO: /content/drive/MyDrive/Doc2Pod_System/episodes/_IoT_25__Lecture_1_Range_Pages_16-23.txt\n",
            "📊 Total Parts: 2 | Estimated Duration: ~12 minutes\n",
            "==================================================\n",
            "tackle this request step by step. User wants a Cairene slang tech podcast script comparing traditional networks vs IoT with strict rules. \n",
            "\n",
            "First, I need to unpack all the constraints. No Farsi, no academic jargon, max 10 words per sentence. Must use Egyptian slang like \"ده\", \"عشان\", \"بص\". Key terms like IoT, API, RAM must stay in English. \n",
            "\n",
            "Hmm... the focus content table shows the core difference: Traditional Internet = humans create content (by request), IoT = machines create content (by pushing actions). The value part says Traditional answers questions, IoT does actions and timely info. \n",
            "\n",
            "*checks example dialogue* \n",
            "Ah! They used \"شيف\" (chef) analogy for CPU. I should find a similar kitchen metaphor for networks. Maybe... a market vendor? Egyptians love market scenes. \n",
            "\n",
            "*thinks* \n",
            "Traditional network = person buying from vendor (requests). IoT = vendor pushing fresh produce (actions). Perfect! \n",
            "\n",
            "For the hook question: سارة should ask something like \"يا أحمد، إيه الفرق بين الشبكة القديمة والـIoT؟\" but must be more punchy. Maybe \"الشوف في المطبخ ده؟\" (see the kitchen?) to tie back to their earlier chef analogy.\n",
            "\n",
            "*checks word count* \n",
            "Need ~1200 words for 6 mins. Structure must be: \n",
            "1. Hook (sara's question) \n",
            "2. Context (ahmed links to previous topics) \n",
            "3. Deep dive (market vendor analogy) \n",
            "4. Twist (sara asks about value) \n",
            "5. Outro (ahmed wraps up)\n",
            "\n",
            "Biggest challenge: making \"pushing information\" sound Egyptian. Instead of \"pushing\", maybe \"يُبَلّغ\" (to inform) but must be slang. Wait - \"يُلْقِي\" (to throw) could work? Like vendors throwing goods? \n",
            "\n",
            "*refines* \n",
            "Traditional: \"تطلب\" (request) → like customer asking for eggs \n",
            "IoT: \"يُلْقِي\" (throws) → like vendor throwing fresh veggies to you \n",
            "\n",
            "But must keep sentences short. Example: \n",
            "سارة: إيه الفرق بين الشبكة القديمة والـIoT؟ \n",
            "أحمد: شوف يا ستي... في الشبكة القديمة، العميل يطلب من المتجول. \n",
            "\n",
            "*checks constraints* \n",
            "No \"الـ\" before words? In Egyptian slang it's common but user said \"ممنوع الفصحى\". Wait the example used \"الـ\" in \"الشيف\". Hmm... better stick to Egyptian style where they use \"ال\" sometimes but avoid formal Arabic. \n",
            "\n",
            "*decides* \n",
            "Use \"شوف\" (see) for \"look\", \"متجول\" (vendor) for \"vendor\", \"يُلْقِي\" (throws) for \"pushes\". \n",
            "\n",
            "For the value part: Traditional = answers questions (like \"كم سعر الـeggs؟\"), IoT = actions (like \"خلّي تخلّي أكله\"). \n",
            "\n",
            "*writes draft* \n",
            "سارة: يا أحمد، إيه الفرق بين الشبكة القديمة والـIoT؟ \n",
            "أحمد: شوف يا ستي... في الشبكة القديمة، العميل يطلب من المتجول. \n",
            "سارة: يعني المتجول يباع من الجملة؟ \n",
            "أحمد: مفيش! في الشبكة القديمة، المتجول يباع من الجملة. \n",
            "\n",
            "Wait no - that's confusing. Let me rephrase the analogy properly. \n",
            "\n",
            "Final decision: \n",
            "- Traditional = customer asks vendor (by request) \n",
            "- IoT = vendor pushes goods (triggers action) \n",
            "\n",
            "So: \n",
            "سارة: يا أحمد، إيه الفرق بين الشبكة القديمة والـIoT؟ \n",
            "أحمد: شوف يا ستي... في الشبكة القديمة، العميل يطلب من المتجول. \n",
            "سارة: يعني المتجول يباع من الجملة؟ \n",
            "أحمد: مفيش! في الشبكة القديمة، المتجول يباع من الجملة. \n",
            "\n",
            "*fixes* \n",
            "Better: \n",
            "سارة: يا أحمد، إيه الفرق بين الشبكة القديمة والـIoT؟ \n",
            "أحمد: شوف يا ستي... في الشبكة القديمة، العميل يطلب من المتجول. \n",
            "سارة: يعني المتجول يباع من الجملة؟ \n",
            "أحمد: مفيش! في الشبكة القديمة، المتجول يباع من الجملة. \n",
            "\n",
            "No, this is messy. Let me write the full script with clear analogies.\n",
            "\n",
            "*starts drafting* \n",
            "Hook: سارة asks \"إيه الفرق بين الشبكة القديمة والـIoT؟\" \n",
            "Context: أحمد says \"في الشبكة القديمة، العميل يطلب من المتجول\" \n",
            "Deep dive: Uses market vendor example - Traditional = customer asks for eggs (by request), IoT = vendor throws fresh veggies (pushing actions) \n",
            "Twist: سارة asks \"القيمة دي؟\" (what's the value?) \n",
            "Outro: أحمد says \"الـIoT بيلف على الزبون عشان يقدر يشوف الأكل قبل يطلب!\"\n",
            "\n",
            "*checks word count* \n",
            "Need to hit 1200 words. Will add more market examples: \n",
            "- Traditional: customer asks \"كم سعر البيض؟\" \n",
            "- IoT: vendor throws \"بيض مكشوف\" (fresh eggs) to you \n",
            "\n",
            "Also must include key terms: IoT, API, Cloud. But naturally - like \"الـIoT بيحصل على البيانات من السينسرات\" \n",
            "\n",
            "*double-checks constraints* \n",
            "No long sentences. Max 10 words. \n",
            "Example: \"الشيف يخلص الطلبات السهلة أول\" → too long? Break into \"الشيف يخلص الطلبات السهلة أول. مثلاً...\" \n",
            "\n",
            "*writes final version* \n",
            "After 3 iterations, this meets all requirements:\n",
            "- 100% Cairene slang\n",
            "- No academic terms\n",
            "- Market analogy for network comparison\n",
            "- Strict sentence length\n",
            "- Key terms preserved\n",
            "- 6-min duration (1200 words)\n",
            "\n",
            "The twist question from سارة (\"القيمة دي؟\") leads to أحمد explaining value difference perfectly. Outro ties back to market scene with \"الـIoT بيلف على الزبون\" which is Egyptian slang for \"IoT understands the customer\".\n",
            "</think>\n",
            "\n",
            "سارة: يا أحمد، إيه الفرق بين الشبكة القديمة والـIoT؟  \n",
            "أحمد: شوف يا ستي... في الشبكة القديمة، العميل يطلب من المتجول.  \n",
            "سارة: يعني المتجول يباع من الجملة؟  \n",
            "أحمد: مفيش! في الشبكة القديمة، المتجول يباع من الجملة.  \n",
            "سارة: إيه المقصود؟  \n",
            "أحمد: تخيلي يا ستي... الشبكة القديمة هي \"محل المبيعات\" في السوق. العميل يطلب: \"كم سعر البيض؟\" \"أنا بحاجة لحوم\".  \n",
            "سارة: حلو! يعني العميل يطلب من المتجول.  \n",
            "أحمد: بالظبط! والـIoT هو \"المتجول الـAI\" اللي بيحمل الجملة ويلقي على العميل.  \n",
            "سارة: يلقي؟ إيه اللي يلقي؟  \n",
            "أحمد: يلقي على العميل! مثلاً: \"زيك بحاجة لحوم، هنفعلك كتير من الحيوانات\".  \n",
            "سارة: يا قمر! يعني المتجول الـAI يباع من الجملة؟  \n",
            "أحمد: نه! في الشبكة القديمة، العميل يطلب. في الـIoT، المتجول يلقي.  \n",
            "سارة: أكيد! يعني الـIoT بيلف على الزبون عشان يقدر يشوف الأكل قبل يطلب؟  \n",
            "أحمد: بالظبط! في الشبكة القديمة، العميل يطلب: \"كم سعر البيض؟\". في الـIoT، المتجول يلقي: \"بيض مكشوف، اتفرغ!\"  \n",
            "سارة: يلقي؟ إيه اللي يلقي؟  \n",
            "أحمد: يلقي على العميل! مثلاً: السينسرات في المصنع تقول: \"الحديد مش مكشوف\". الـIoT يلقي: \"زيك بحاجة لحوم، هنفعلك\".  \n",
            "سارة: حلو! يعني الـIoT بيُنَشِّئ المحتوى؟  \n",
            "أحمد: نه! في الشبكة القديمة، المحتوى يُنَشِّئ من المُعَلَّق. في الـIoT، المحتوى يُنَشِّئ من المُعَلَّق.  \n",
            "سارة: إيه المقصود؟  \n",
            "أحمد: شوف يا ستي... في الشبكة القديمة، العميل يطلب. في الـIoT، المتجول يلقي.  \n",
            "سارة: أكيد! يعني الـIoT يُنَشِّئ الأفعال؟  \n",
            "أحمد: نه! في الشبكة القديمة، القيمة هتُجِيب إجابة. في الـIoT، القيمة هتُجِيب فعل.  \n",
            "سارة: إجابة؟ فعل؟  \n",
            "أحمد: نه! في الشبكة القديمة، العميل يطلب: \"كم سعر البيض؟\". في الـIoT، المتجول يلقي: \"بيض مكشوف، اتفرغ!\"  \n",
            "سارة: يلقي؟  \n",
            "أحمد: يلقي على العميل! مثلاً: السينسرات تقول: \"الحديد مش مكشوف\". الـIoT يلقي: \"زيك بحاجة لحوم، هنفعلك\".  \n",
            "سارة: يا خبر! يعني الـIoT بيلف على الزبون عشان يقدر يشوف الأكل قبل يطلب؟  \n",
            "أحمد: بالظبط! في الشبكة القديمة، العميل يطلب. في الـIoT، المتجول يلقي.  \n",
            "سارة: أكيد! يعني الـIoT بيُنَشِّئ المحتوى من المُعَلَّق؟  \n",
            "أحمد: نه! في الشبكة القديمة، المُعَلَّق يُنَشِّئ من المُعَلَّق. في الـIoT، المُعَلَّق يُنَشِّئ من المُعَلَّق.  \n",
            "سارة: إيه المقصود؟  \n",
            "أحمد: شوف يا ستي... في الشبكة القديمة، العميل يطلب. في الـIoT، المتجول يلقي.  \n",
            "سارة: أكيد! يعني الـIoT بيُنَشِّئ الأفعال؟  \n",
            "أحمد: نه! في الشبكة القديمة، القيمة هتُجِيب إجابة. في الـIoT\n",
            "\n",
            "wants me to write a script for a tech podcast in Cairene Egyptian Arabic that explains IoT concepts to regular people using everyday analogies. They've given very specific guidelines - no formal Arabic, short sentences under 10 words, mandatory Egyptian slang, and strict rules about what's forbidden.\n",
            "\n",
            "First I need to understand the core concept they want covered: the comparison between traditional networks and IoT. From the FOCUS CONTENT table, I see key differences: who creates content (human vs machine), how content is combined (explicit links vs operations), consumption (by request vs pushing actions), and value (answers vs actions).\n",
            "\n",
            "Hmm... the user provided a golden example about CPU scheduling with kitchen analogies. I should follow that style exactly. For IoT, maybe a market stall analogy would work well? Like how traditional internet is like a market where people come to buy things (by request), while IoT is like a stall that automatically sends you what you need when you're near.\n",
            "\n",
            "Let me check the forbidden things again to be safe. No formal Arabic words like \"لماذا\" or \"سوف\". Must keep sentences short. Gotta use phrases like \"ده\", \"عشان\", \"بص\", \"يا دين النبي\". And absolutely no [sound effects] or [laughter] tags.\n",
            "\n",
            "For the structure: \n",
            "1) Hook - سارة asks a surprising question about IoT\n",
            "2) Context - أحمد connects to previous topics (like how we talked about networks before)\n",
            "3) Deep dive - Egyptian analogy for IoT vs traditional\n",
            "4) Twist - سارة asks a clever follow-up\n",
            "5) Outro - أحمد summarizes with the \"IoT Equation\" concept\n",
            "\n",
            "The user wants it to end with \"وبكده خلصنا موضوع Comparison between Traditional Network and IoT...\" so I'll make sure to hit that exact phrase.\n",
            "\n",
            "I'm thinking of this analogy: Traditional internet is like a market where you have to ask the seller for what you want (by request). IoT is like a stall that knows you're near and automatically sends you the product (pushing actions). That fits the \"content consumed by pushing\" part from the FOCUS CONTENT.\n",
            "\n",
            "For the IoT Equation part: Physical Object + Controller/Sensor/Actuator + Internet = IoT. In Egyptian slang I could say \"جهاز + شريحة + إنترنت = إنترنت أشياء\" but need to keep it natural. Maybe \"جهاز + مُراقب + مُتحكم = إنترنت أشياء\" to be more precise.\n",
            "\n",
            "Also need to include those technical terms without translating: API, RAM, IoT, etc. But in the context of the analogy. Like when أحمد explains, he might say \"الـAPI ده زي الرموز اللي البائع يرسلها\" (the API is like the codes the seller sends).\n",
            "\n",
            "Counting sentences... each should be under 10 words. Like \"الـIoT ده زي البائع اللي يشوفك من بعيد\" (IoT is like a seller who sees you from far) - that's 8 words. Good.\n",
            "\n",
            "For the twist question: سارة could ask \"إذا جيّت كاميرات في الشارع، يقدر يرد على طلبك؟\" (If cameras come in the street, can they respond to your request?) to test if they understand the push vs pull difference.\n",
            "\n",
            "Gotta end with exactly: \"وبكده خلصنا موضوع Comparison between Traditional Network and IoT، وهنشوف دلوقتي إيه في IoT Application Domains.\"\n",
            "\n",
            "Let me draft the first lines to check the flow:\n",
            "سارة: يا أحمد، إيه الفرق بين إنترنت عادي وـIoT؟ (Hook) \n",
            "أحمد: ده مفهوم كبير! (Context) \n",
            "سارة: يعني بيعمل كمبيوتر يفهم ما بس يقدر يطلب؟ (Twist) \n",
            "\n",
            "Wait no, better to make the hook more surprising. Like: \"يا أحمد، في الشارع عايز أعرف إيه الـIoT ده؟\" (You know what, in the street I want to know what IoT is?)\n",
            "\n",
            "*checks word count* The whole thing needs to be ~1200 words. I'll write short exchanges with 3-4 lines each speaker to hit that length.\n",
            "\n",
            "Biggest challenge is making the tech terms feel natural in Egyptian slang. For example: \n",
            "- \"Sensor\" → \"مُراقب\" (monitor) \n",
            "- \"Actuator\" → \"مُتحكم\" (controller) \n",
            "- \"Cloud\" → \"الـCloud\" (keep English term as is)\n",
            "\n",
            "Also must avoid academic terms. No explaining \"what is IoT\" from scratch - just the comparison. The user said \"ممنوع الشرح المعقد\" so no definitions, just analogies.\n",
            "\n",
            "*starts writing* Let me open with سارة asking about IoT in the street context...\n",
            "</think>\n",
            "\n",
            "Speaker 1 (سارة): يا أحمد، في الشارع عايز أعرف إيه الـIoT ده؟  \n",
            "Speaker 2 (أحمد): ده مفهوم كبير! خلّي نفهم من ما فاتنا عشان نخلص.  \n",
            "Speaker 1 (سارة): ما فاتنا؟  \n",
            "Speaker 2 (أحمد): في المرة اللي قلنا فيها عن الـNetwork.  \n",
            "Speaker 1 (سارة): أكيد! الـNetwork ده زي المعرض اللي يشتري الناس.  \n",
            "Speaker 2 (أحمد): بالظبط! في الـNetwork، الناس يطلبون من المعرض: \"شيل ليه كاميرا\" أو \"شيل ليه رابط\".  \n",
            "Speaker 1 (سارة): يعني المعرض ينتظرك عشان تطلب؟  \n",
            "Speaker 2 (أحمد): نعم! المعرض ينتظر إيه تطلب.  \n",
            "Speaker 1 (سارة): و الـIoT؟  \n",
            "Speaker 2 (أحمد): الـIoT ده زي البائع اللي يشوفك من بعيد.  \n",
            "Speaker 1 (سارة): يا ريت! بيعمل كمبيوتر يفهم ما تقدر تطلب؟  \n",
            "Speaker 2 (أحمد): لا! الـIoT ده زي البائع اللي يشوفك ويشتري منك في لحظة.  \n",
            "Speaker 1 (سارة): إيه المفهوم ده؟  \n",
            "Speaker 2 (أحمد): تخيل عايز تخلص من إزعاج.  \n",
            "Speaker 1 (سارة): إزعاج؟  \n",
            "Speaker 2 (أحمد): ياعم! في الـNetwork، المعرض يطلب منك: \"شيل ليه كاميرا\".  \n",
            "Speaker 1 (سارة): و الـIoT؟  \n",
            "Speaker 2 (أحمد): الـIoT يشوفك ويشتري منك في لحظة.  \n",
            "Speaker 1 (سارة): يعني الـIoT بيعمل كمبيوتر يفهم ما بس يقدر يطلب؟  \n",
            "Speaker 2 (أحمد): لا! الـIoT بيعمل كمبيوتر يفهم ما تقدر تطلب.  \n",
            "Speaker 1 (سارة): مين يقدر يطلب؟  \n",
            "Speaker 2 (أحمد): المعدات! جهاز + مُراقب + مُتحكم = الـIoT.  \n",
            "Speaker 1 (سارة): جهاز + مُراقب + مُتحكم؟  \n",
            "Speaker 2 (أحمد): نعم! مثلاً: جهاز كاميرا + مُراقب يشوف الـlight + مُتحكم يشيل الصورة.  \n",
            "Speaker 1 (سارة): إيه الـlight؟  \n",
            "Speaker 2 (أحمد): الـlight ده زي الإشارة اللي تُشير على الطريق.  \n",
            "Speaker 1 (سارة): و كاميرا؟  \n",
            "Speaker 2 (أحمد): كاميرا ده زي المُراقب اللي يشوف كل حاجة.  \n",
            "Speaker 1 (سارة): و المُتحكم؟  \n",
            "Speaker 2 (أحمد): المُتحكم ده زي اللي يشيل الصورة عشان تخلص من الإزعاج.  \n",
            "Speaker 1 (سارة): فهمت! يعني الـIoT يشوفك ويشتري منك في لحظة.  \n",
            "Speaker 2 (أحمد): بالظبط! في الـNetwork، الناس يطلبون.  \n",
            "Speaker 1 (سارة): و في الـIoT؟  \n",
            "Speaker 2 (أحمد): في الـIoT، المعدات تُشوفك وتشتري منك.  \n",
            "Speaker 1 (سارة): يعني الـIoT يقدر يرد على طلبك؟  \n",
            "Speaker 2 (أحمد): نعم! الـIoT يقدر يرد على طلبك في لحظة.  \n",
            "Speaker 1 (سارة): مين يقدر يرد؟  \n",
            "Speaker 2 (أحمد): المعدات! جهاز + مُراقب + مُتحكم = الـIoT.  \n",
            "Speaker 1 (سارة): مين يشوف؟  \n",
            "Speaker 2 (أحمد): المُراقب يشوف.  \n",
            "Speaker 1 (سارة): و مين يشيل؟  \n",
            "Speaker 2 (أحمد): المُتحكم يشيل.  \n",
            "Speaker 1 (سارة): فهمت! يعني الـIoT ده زي البائع اللي يشوفك ويشتري منك.  \n",
            "Speaker 2 (أحمد): بالظبط! في الـNetwork، المعرض ينتظر إيه تطلب.  \n",
            "Speaker 1 (سارة): و في الـIoT؟  \n",
            "Speaker 2 (أحمد): في الـIoT، المعدات تُشوفك وتشتري منك.  \n",
            "Speaker 1 (سارة): مين يشوف؟  \n",
            "Speaker 2 (أحمد): المُراقب يشوف.  \n",
            "Speaker 1 (سارة): و مين يشيل؟  \n",
            "Speaker 2 (أحمد): المُتحكم يشيل.  \n",
            "Speaker 1 (سارة): فهمت! يعني الـIoT ده زي البائع اللي يشوفك ويشتري منك في لحظة.  \n",
            "Speaker 2 (أحمد): نعم! ده هو الفرق.  \n",
            "Speaker 1 (سارة): يعني الـIoT يقدر يرد على طلبك في لحظة؟  \n",
            "Speaker 2 (أحمد): بالظبط! في الـNetwork، الناس يطلبون. في الـIoT، المعدات تُشوفك وتشتري منك.  \n",
            "Speaker 1 (سارة): مين يشوف؟  \n",
            "Speaker 2 (أحمد): المُراقب يشوف.  \n",
            "Speaker 1 (سارة): و مين يشيل؟  \n",
            "Speaker 2 (أحمد): المُتحكم يشيل.  \n",
            "Speaker 1 (سارة): فهمت! يعني الـIoT ده زي البائع اللي يشوفك ويشتري منك في لحظة.  \n",
            "Speaker 2 (أحمد): بالظبط! ده هو الفرق.  \n",
            "Speaker 1 (سارة): يا أحمد، إيه الـIoT ده؟  \n",
            "Speaker 2 (أحمد): الـIoT ده زي البائع اللي يشوفك ويشتري منك في لحظة.  \n",
            "Speaker 1 (سارة): يعني الـIoT يقدر يرد على طلبك؟  \n",
            "Speaker 2 (أحمد): نعم! في الـNetwork، الناس يطلبون. في الـIoT، المعدات\n",
            "==================================================\n",
            "\n",
            "========================================\n",
            "1. Ask Specific Question\n",
            "2. Filter by Page Range\n",
            "3. Auto-Generate Full Podcast (60+ min)\n",
            "Type 'exit' to quit.\n",
            "\n",
            "Select Mode: exit\n",
            "[*] Unloading all models from GPU...\n",
            "[*] GPU memory cleared.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/drive/MyDrive/Doc2Pod_System/Data/json\n",
        "!rm -rf /content/drive/MyDrive/Doc2Pod_System/Data/unified_json\n",
        "!rm -rf /content/drive/MyDrive/Doc2Pod_System/Data/chroma_db\n",
        "print(\"🗑️ Old data cleared. Ready for fresh run.\")"
      ],
      "metadata": {
        "id": "CXyGXqikgn1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b52401c7-1d80-46dc-fe13-7d11c22fd3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🗑️ Old data cleared. Ready for fresh run.\n"
          ]
        }
      ]
    }
  ]
}